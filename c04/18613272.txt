Semi-parametric maximum likelihood estimates for ROC curves of continuous-scale tests Summary In this paper, we propose a new semi-parametric maximum likelihood (ML) estimate of an ROC curve that satisfies the property of invariance of the ROC curve and is easy to compute. We show that our new estimator is n -consistent and has an asymptotically normal distribution. Our extensive simulation studies show the proposed method is efficient, robust, and simple to compute. Finally, we illustrate the application of the proposed estimator in a real data set.  1. Introduction When the response of a diagnostic test is continuous, its diagnostic accuracy is best represented by the receiver operating characteristic (ROC) curve [ 1 ]. Let F 1 and F 0 denote distribution functions of the test result Y 1 of a diseased subject and Y 0 of a non-diseased subject, respectively. Then, the ROC curve of the test can be written as (1) ROC ( u ) = 1 ? F 1 ( F 0 ? 1 ( 1 ? u ) ) , where F 0 ? 1 is the inverse function of F 0, and u is the false positive rate (FPR) corresponding to a cut-off point for positivity. It is well-known that the ROC curve of a test must be invariant to any monotone increasing transformation of test results, a fundamental property of an ROC curve. Hence, any sensible estimation methods should have this property. In the statistical literature, many parametric, semi-parametric, and non-parametric methods have been proposed for estimating an ROC curve. In general, pure parametric methods do not possess the invariance property; the empirical non-parametric and smoothing non-parametric methods have the property of invariance [ 2 , 3 ]. However, the jagged form of the empirical ROC curve estimator can result in underestimating the true ROC curve as the true ROC curve is a smooth function, and the intensive computation and challenging bandwidth selection of the smoothing non-parametric estimators may affect their application in practice. An intermediate strategy between pure parametric and non-parametric methods is a semi-parametric approach. The most commonly used semi-parametric procedure to estimate the ROC curve is to assume a parametric form for the ROC curve, but avoid making any additional parametric assumptions about the distributions of test results. This type of semi-parametric method has the property of invariance. In this paper, we focus on this type of semi-parametric method. We assume that the ROC curve has the parametric form, (2) ROC ( u ) = G ( ? 0 + ? 1 H ? 1 ( u ) ) , where G and H are some known cumulative distribution functions. The most common choice for G and H is the binormal form, G = H = ?, where ? is the cumulative distribution function of the standard normal random variable. Under the binormal model, several methods have been proposed by Metz et al. [ 4 ], Alonzo and Pepe [ 5 ], Pepe and Cai [ 6 ], Zou and Hall [ 7 ], and Cai and Moskowitz [ 8 ]. The first approach, proposed by Metz et al. [ 4 ] and denoted by MHS, is to first categorize continuous test data into ordinal-scale categorical data and then to apply the maximum likelihood method to estimating the parameters in the binormal model by assuming that the continuous variable can be approximated by a discrete variable with finite support points; that is, the continuous distribution function can be specified by finite parameters, which is difficult in practice. Furthermore, they use an ad hoc approach to reduce the number of the parameters, hence, their resulting estimate is no longer a ML estimate even though their likelihood is correct. The second approach, proposed by Alonzo and Pepe [ 5 ] and denoted by AP, is to estimate the ROC curve by using procedures for fitting generalized linear models to binary data. The third approach, proposed by Pepe and Cai [ 6 ] and denoted by PC, is to first write the ROC curve as the distribution of placement values and then to estimate the ROC curve by maximizing the pseudo likelihood function of the estimated placement values. None of the above three methods is a truly maximum likelihood (ML) estimator, and hence they do not possess the optimal property associated with ML estimators, for example, fully efficient. The fourth method, proposed by Zou and Hall [ 7 ] and denoted by ZH, is to use rank data to estimate the ROC curve by assuming semi-parametric distributions for test results of diseased and non-diseased subjects and using maximum likelihood algorithms. However, the likelihood function in the ZH method is a high-dimensional integral, and hence numerical methods include Monte Carlo are required to evaluate the likelihood. Recently, Cai and Moskowitz [ 8 ] have proposed a profile maximum likelihood approach from the raw data to estimate the ROC curve, denoted by CM; however, their computation algorithm requires choosing reasonable initial values for a large number of nuisance parameters, which may be difficult in practice when the sample size is large. In this paper, we propose a new profile maximum likelihood approach to estimate the ROC curve. Compared to the Cai and Moskowitz’ method, our method has a smaller number of nuisance parameters to estimate. Furthermore, our estimator can be computed by using an algorithm that is based on a recursive relationship among the nuisance parameters, without specifying initial values for a large number of nuisance parameters. Our estimator is n -consistent and has an asymptotically normal distribution, and our extensive simulation studies show the proposed method is efficient, robust, and simple to compute. Since the binormal model is the most commonly used form for an ROC curve, from now on we assume that the true ROC curve is defined by (3) ROC ( u ) = ? ( ? 0 + ? 1 ? ? 1 ( u ) ) , where ??1(·) is the inverse of the cumulative distribution of the standard normal distribution. Equivalently, we can derive model ( 3 ) by assuming that there exists an unknown monotone increasing function g (.) such that g ( Y 0) has the standard normal distribution and g ( Y 1) has a normal distribution with mean ? and standard deviation ? . Then, the resulting ROC curve satisfies model ( 3 ) with ? 0 = ? / ? and ? 1 = 1/ ? . The paper is organized as follows. In Section 2, we propose a semi-parametric maximum likelihood estimator of an ROC curve and an algorithm for computing it, and develop asymptotic properties for the resulting estimator. In Section 3, we perform simulation studies to asses efficiency and robustness of our estimator relative to the existing methods and to verify the validity of the asymptotic inferences in finite samples. In Section 4, we illustrate the application of our method in an example.  Discussion In this paper we have proposed a semi-parametric MLE for the ROC curve under the bi-normal ROC curve model ( 3 ). The estimator is asymptotically normal. The asymptotic results also hold for the more general specification of parametric ROC curve model given by ( 2 ), for example, when G and H are symmetric distributions and when H belongs to a location-scale family. Our simulation results have indicated that the proposed estimators also have good finite-sample properties and have similar efficiency and robustness as the CM, MHS, AP and ZH estimators with the proposed estimator is slightly better than all the other estimators considered here in numerical implementation or efficiency. Same with the CM and ZH estimators, our method is rank-based, the observations can be replaced by ranks. Hanley[ 15 ] has shown that the bi-normal ROC curve model for ordinal-scale tests enjoys a certain degree of robustness against departure from the bi-normality assumption. Our own simulation studies have also demonstrated this result. However, given limitations of any simulation study, we want to emphasize that it is important to check the assumption of the bi-normality in any application; for example one may use the graphical method suggested by Cai and Moskowitz[ 8 ] and illustrated in Section 4. If the ROC curve of a diagnostic test depends on a subject’s covariates, we need to model covariate effects on the ROC curves using a regression model. The most commonly used methods are direct regression models of covariates on ROC curves. For example, given the vector of covariates x , we can model the effect of x on the ROC curves by the following model, (14) ROC ( u , x ) = G ( ? 0 + ? 1 ? x + H ( u ) ) . For estimating such models, both the method of estimating equations and the quasi-likelihood method have been proposed by Alonzo and Pepe [ 5 ] and Pepe and Cai [ 6 ], respectively. As shown in this paper, without any covariates, our estimator slightly outperforms these two methods in the setting we considered. Hence, it may be worthwhile to extend our methods to the setting where the ROC curve depends on subject covariates. In the paper, the two biomarkers CA19-9 and CA125 were analyzed ‘marginally’, without recognition that each sample is really bivariate (two diagnostic tests on the same patients). Zou and Hall [ 16 ] and Metz, Herman and Roe [ 17 ] proposed methods to estimate ROC curve from paired samples. We will extend our method to the data with potential dependence in another paper.  Discussion In this paper we have proposed a semi-parametric MLE for the ROC curve under the bi-normal ROC curve model ( 3 ). The estimator is asymptotically normal. The asymptotic results also hold for the more general specification of parametric ROC curve model given by ( 2 ), for example, when G and H are symmetric distributions and when H belongs to a location-scale family. Our simulation results have indicated that the proposed estimators also have good finite-sample properties and have similar efficiency and robustness as the CM, MHS, AP and ZH estimators with the proposed estimator is slightly better than all the other estimators considered here in numerical implementation or efficiency. Same with the CM and ZH estimators, our method is rank-based, the observations can be replaced by ranks. Hanley[ 15 ] has shown that the bi-normal ROC curve model for ordinal-scale tests enjoys a certain degree of robustness against departure from the bi-normality assumption. Our own simulation studies have also demonstrated this result. However, given limitations of any simulation study, we want to emphasize that it is important to check the assumption of the bi-normality in any application; for example one may use the graphical method suggested by Cai and Moskowitz[ 8 ] and illustrated in Section 4. If the ROC curve of a diagnostic test depends on a subject’s covariates, we need to model covariate effects on the ROC curves using a regression model. The most commonly used methods are direct regression models of covariates on ROC curves. For example, given the vector of covariates x , we can model the effect of x on the ROC curves by the following model, (14) ROC ( u , x ) = G ( ? 0 + ? 1 ? x + H ( u ) ) . For estimating such models, both the method of estimating equations and the quasi-likelihood method have been proposed by Alonzo and Pepe [ 5 ] and Pepe and Cai [ 6 ], respectively. As shown in this paper, without any covariates, our estimator slightly outperforms these two methods in the setting we considered. Hence, it may be worthwhile to extend our methods to the setting where the ROC curve depends on subject covariates. In the paper, the two biomarkers CA19-9 and CA125 were analyzed ‘marginally’, without recognition that each sample is really bivariate (two diagnostic tests on the same patients). Zou and Hall [ 16 ] and Metz, Herman and Roe [ 17 ] proposed methods to estimate ROC curve from paired samples. We will extend our method to the data with potential dependence in another paper.  Figures and Tables Figure 1 The distribution of ASE for the estimated ROC curve from the binormal simulated model in Section 3.1 over the 500 replications. Figure 2 The diseased data are from a mixture of two normal distributions, but modeled with the binormal model when n 0 = n 1 = 100. (A) The average of the estimated ROC curves; (B) the distribution of ASE for the estimated ROC curves over the 500 replications. Figure 3 The diseased data are from a mixture of two normal distributions, but modeled with the binormal model when n 0 = n 1 = 200. (A) The average of the estimated ROC curves; (B) the distribution of ASE for the estimated ROC curves over the 500 replications. Figure 4 Estimated ROC curves of CA19-9 in the pancreatic cancer data set. Figure 5 Estimated ROC curves of CA125 in the pancreatic cancer data set. Table 1 Estimates of ( ? 0, ? 1) compared with their actual values over the 500 replications for the binormal simulated data with high AUC in section 3.1. ? 0 = 2/1.2 ? 1 = 1/1.2 n 0 n 1 Method Bias SD RMSE Bias SD RMSE SRMSE 100 100 ZL 0.038 0.209 0.212 0.012 0.137 0.137 0.349 CM 0.074 0.213 0.226 0.043 0.141 0.148 0.373 MHS 0.002 0.212 0.212 ?0.033 0.142 0.146 0.358 AP 0.025 0.225 0.226 0.041 0.164 0.169 0.395 PC ?0.105 0.169 0.199 ?0.163 0.088 0.185 0.384 200 100 ZL 0.028 0.180 0.182 0.009 0.113 0.113 0.295 CM 0.039 0.184 0.188 0.022 0.115 0.117 0.305 MHS 0.022 0.208 0.209 ?0.014 0.142 0.143 0.352 AP 0.027 0.191 0.193 0.034 0.131 0.136 0.328 PC ?0.105 0.142 0.177 ?0.129 0.092 0.158 0.335 200 200 ZL 0.016 0.140 0.141 0.002 0.093 0.093 0.234 CM 0.024 0.142 0.144 0.012 0.094 0.095 0.239 MHS ?0.009 0.137 0.137 ?0.014 0.102 0.103 0.240 AP 0.009 0.144 0.145 0.017 0.103 0.104 0.249 PC ?0.108 0.123 0.164 ?0.132 0.087 0.158 0.322 Table 2 Estimates of ( ? 0, ? 1) compared with their actual values over the 500 replications for the binormal simulated data with low AUC in section 3.1. ? 0 = 1/1 ? 1 = 1/1 n 0 n 1 Method Bias SD RMSE Bias SD RMSE SRMSE 100 100 ZL 0.025 0.166 0.168 0.003 0.124 0.124 0.292 CM 0.031 0.168 0.171 0.021 0.125 0.126 0.298 200 100 ZL 0.009 0.134 0.134 0.006 0.102 0.102 0.236 CM 0.017 0.137 0.138 0.017 0.103 0.105 0.243 200 200 ZL 0.008 0.111 0.111 ?0.001 0.082 0.082 0.193 CM 0.015 0.112 0.113 0.011 0.083 0.084 0.197 ? 0 = 0.5/1 ? 1 = 1/1 n 0 n 1 Method Bias SD RMSE Bias SD RMSE SRMSE 100 100 ZL 0.025 0.151 0.153 0.012 0.115 0.116 0.269 CM 0.023 0.152 0.153 0.024 0.111 0.114 0.267 200 100 ZL 0.005 0.122 0.122 0.021 0.095 0.097 0.219 CM 0.010 0.121 0.121 0.020 0.096 0.098 0.219 200 200 ZL 0.004 0.100 0.100 0.004 0.075 0.075 0.175 CM 0.010 0.099 0.100 0.013 0.075 0.076 0.176 Table 3 Average( SE ave ) and standard deviation ( SE std ) of the standard error estimator over the 500 replications for the binormal simulated data with high AUC in Section 3.1 ? 0 = 2/1.2 ? 1 = 1/1.2 n 0 n 1 SD SE ave ( SE std ) Coverage SD SE ave ( SE std ) Coverage 50 100 0.230 0.226(0.049) 0.939 0.160 0.161(0.043) 0.917 100 100 0.209 0.202(0.040) 0.920 0.137 0.133(0.031) 0.922 200 100 0.180 0.186(0.035) 0.931 0.113 0.113(0.024) 0.933 200 200 0.140 0.140(0.020) 0.947 0.093 0.091(0.015) 0.929 Table 4 Average( SE ave ) and standard deviation ( SE std ) of the standard error estimator over the 500 replications for the mixture normal data in Section 3.2 ? 0 ? 1 n 0 n 1 k * SD SE ave ( SE std ) SD SE ave ( SE std ) 50 50 3 0.239 0.244(0.034) 0.159 0.167(0.036) 100 100 3 0.164 0.168(0.016) 0.111 0.113(0.018) 100 100 2 0.155 0.161(0.014) 0.097 0.105(0.015) 200 200 2 0.106 0.112(0.006) 0.068 0.071(0.007) * where k is the number of terms in the mixture of normals for the diseased data. Table 5 Estimates of ( ? 0, ? 1) for CA19-9 and CA125 as diagnostic markers of pancreatic cancer CA19-9 CA125 method ?? 0( SD ) ?? 1( SD ) ?? 0( SD ) ?? 1( SD ) ZL 1.192(0.158) 0.431(0.081) 0.7277(0.1858) 1.005(0.1309) MHS 1.177(0.160) 0.399(0.082) 0.7240(0.185) 1.001(0.137) CM 1.235(0.129) 0.480(0.074) 0.7605(0.234 ) 1.0648(0.154) AP 1.142(0.153) 0.468(0.110) 0.7594(0.251 ) 1.1295(0.255) PC 1.343(0.192) 0.490(0.040) 0.6180(0.202) 0.8421( 0.139)  Figures and Tables Figure 1 The distribution of ASE for the estimated ROC curve from the binormal simulated model in Section 3.1 over the 500 replications. Figure 2 The diseased data are from a mixture of two normal distributions, but modeled with the binormal model when n 0 = n 1 = 100. (A) The average of the estimated ROC curves; (B) the distribution of ASE for the estimated ROC curves over the 500 replications. Figure 3 The diseased data are from a mixture of two normal distributions, but modeled with the binormal model when n 0 = n 1 = 200. (A) The average of the estimated ROC curves; (B) the distribution of ASE for the estimated ROC curves over the 500 replications. Figure 4 Estimated ROC curves of CA19-9 in the pancreatic cancer data set. Figure 5 Estimated ROC curves of CA125 in the pancreatic cancer data set. Table 1 Estimates of ( ? 0, ? 1) compared with their actual values over the 500 replications for the binormal simulated data with high AUC in section 3.1. ? 0 = 2/1.2 ? 1 = 1/1.2 n 0 n 1 Method Bias SD RMSE Bias SD RMSE SRMSE 100 100 ZL 0.038 0.209 0.212 0.012 0.137 0.137 0.349 CM 0.074 0.213 0.226 0.043 0.141 0.148 0.373 MHS 0.002 0.212 0.212 ?0.033 0.142 0.146 0.358 AP 0.025 0.225 0.226 0.041 0.164 0.169 0.395 PC ?0.105 0.169 0.199 ?0.163 0.088 0.185 0.384 200 100 ZL 0.028 0.180 0.182 0.009 0.113 0.113 0.295 CM 0.039 0.184 0.188 0.022 0.115 0.117 0.305 MHS 0.022 0.208 0.209 ?0.014 0.142 0.143 0.352 AP 0.027 0.191 0.193 0.034 0.131 0.136 0.328 PC ?0.105 0.142 0.177 ?0.129 0.092 0.158 0.335 200 200 ZL 0.016 0.140 0.141 0.002 0.093 0.093 0.234 CM 0.024 0.142 0.144 0.012 0.094 0.095 0.239 MHS ?0.009 0.137 0.137 ?0.014 0.102 0.103 0.240 AP 0.009 0.144 0.145 0.017 0.103 0.104 0.249 PC ?0.108 0.123 0.164 ?0.132 0.087 0.158 0.322 Table 2 Estimates of ( ? 0, ? 1) compared with their actual values over the 500 replications for the binormal simulated data with low AUC in section 3.1. ? 0 = 1/1 ? 1 = 1/1 n 0 n 1 Method Bias SD RMSE Bias SD RMSE SRMSE 100 100 ZL 0.025 0.166 0.168 0.003 0.124 0.124 0.292 CM 0.031 0.168 0.171 0.021 0.125 0.126 0.298 200 100 ZL 0.009 0.134 0.134 0.006 0.102 0.102 0.236 CM 0.017 0.137 0.138 0.017 0.103 0.105 0.243 200 200 ZL 0.008 0.111 0.111 ?0.001 0.082 0.082 0.193 CM 0.015 0.112 0.113 0.011 0.083 0.084 0.197 ? 0 = 0.5/1 ? 1 = 1/1 n 0 n 1 Method Bias SD RMSE Bias SD RMSE SRMSE 100 100 ZL 0.025 0.151 0.153 0.012 0.115 0.116 0.269 CM 0.023 0.152 0.153 0.024 0.111 0.114 0.267 200 100 ZL 0.005 0.122 0.122 0.021 0.095 0.097 0.219 CM 0.010 0.121 0.121 0.020 0.096 0.098 0.219 200 200 ZL 0.004 0.100 0.100 0.004 0.075 0.075 0.175 CM 0.010 0.099 0.100 0.013 0.075 0.076 0.176 Table 3 Average( SE ave ) and standard deviation ( SE std ) of the standard error estimator over the 500 replications for the binormal simulated data with high AUC in Section 3.1 ? 0 = 2/1.2 ? 1 = 1/1.2 n 0 n 1 SD SE ave ( SE std ) Coverage SD SE ave ( SE std ) Coverage 50 100 0.230 0.226(0.049) 0.939 0.160 0.161(0.043) 0.917 100 100 0.209 0.202(0.040) 0.920 0.137 0.133(0.031) 0.922 200 100 0.180 0.186(0.035) 0.931 0.113 0.113(0.024) 0.933 200 200 0.140 0.140(0.020) 0.947 0.093 0.091(0.015) 0.929 Table 4 Average( SE ave ) and standard deviation ( SE std ) of the standard error estimator over the 500 replications for the mixture normal data in Section 3.2 ? 0 ? 1 n 0 n 1 k * SD SE ave ( SE std ) SD SE ave ( SE std ) 50 50 3 0.239 0.244(0.034) 0.159 0.167(0.036) 100 100 3 0.164 0.168(0.016) 0.111 0.113(0.018) 100 100 2 0.155 0.161(0.014) 0.097 0.105(0.015) 200 200 2 0.106 0.112(0.006) 0.068 0.071(0.007) * where k is the number of terms in the mixture of normals for the diseased data. Table 5 Estimates of ( ? 0, ? 1) for CA19-9 and CA125 as diagnostic markers of pancreatic cancer CA19-9 CA125 method ?? 0( SD ) ?? 1( SD ) ?? 0( SD ) ?? 1( SD ) ZL 1.192(0.158) 0.431(0.081) 0.7277(0.1858) 1.005(0.1309) MHS 1.177(0.160) 0.399(0.082) 0.7240(0.185) 1.001(0.137) CM 1.235(0.129) 0.480(0.074) 0.7605(0.234 ) 1.0648(0.154) AP 1.142(0.153) 0.468(0.110) 0.7594(0.251 ) 1.1295(0.255) PC 1.343(0.192) 0.490(0.040) 0.6180(0.202) 0.8421( 0.139)  2. Semi-parametric maximum likelihood estimate Data available for making inferences consist of a random sample of size n 1 from the diseased population with the unknown cumulative distribution function F 1, { Y 1 j , j = 1, ···, n 1}, and a random sample of size n 0 from the non-diseased population, { Y 0 i , i = 1 , ··· , n 0}, with the unknown cumulative distribution function F 0. Denote n = n 0 + n 1. Let f 0 and f 1 be the density functions of F 0 and F 1, respectively. Then, the likelihood function of observations Y 0 i , i = 1 , ···, n 0, and Y 1 j , j = 1 , ···, n 1, is given by (4) L = ? i = 1 n 0 f 0 ( Y 0 i ) ? j = 1 n 1 f 1 ( Y 1 j ) . Under model ( 3 ), we know that there exists a unknown increasing and differentiable function g (.) such that g ( Y 0) has the standard normal distribution and g ( Y 1) has a normal distribution with mean ? and standard deviation ? . Denote ? ( x ) to be the standard normal density function, therefore, we have that f 0( y ) = ? ( g ( y )) g ?( y ) and f 1( y ) = ? (? ? 0 + ? 1 g ( y )) ? 1 g ?( y ). Hence we can write the likelihood function ( 4 ) as (5) L = ? i = 1 n 0 ? ( g ( Y 0 i ) ) g ? ( Y 0 i ) ? j = 1 n 1 ? ( ? ? 0 + ? 1 g ( Y 1 j ) ) ? 1 g ? ( Y 1 j ) . Consequently, the ML estimation of the ROC curve parameters ? 0 and ? 1 requires simultaneous estimation of the unknown function g . Denote dF ( x ) = F ( x )? F ( x ?), where “?” represents the left limit. Our approach to estimating ? 0, ? 1 and g is based on the nonparametric maximum likelihood approach [ 9 , 10 , 11 , 12 ], which seek to maximize the function L? given by L ? = ? i = 1 n 0 ? ( g ( Y 0 i ) ) d g ( Y 0 i ) ? j = 1 n 1 ? ( ? ? 0 + ? 1 g ( Y 1 j ) ) ? 1 d g ( Y 1 j ) ; that is, (6) L ? = ? i = 1 n 0 { ? ( g ( Y 0 i ) ) ? ? ( g ( Y 0 i ? ) ) } ? j = 1 n 1 { ? ( ? ? 0 + ? 1 g ( Y 1 j ) ) ? ? ( ? ? 0 + ? 1 g ( Y 1 j ? ) ) } . Denote the distinct ordered test results from the combined sample, Y 0 i ’s and Y 1 j ’s, by Y ( 1 ) ? < ? < Y ( I n ? ? 1 ) ? , where I n ? ? 1 is the number of distinct values among Y 0 i ’s and Y 1 j ’s. Therefore we can write the likelihood function ( 6 ) as follows: (7) L ? = ? r = 1 I n ? ? 1 ( ? ( g ( Y ( r ) ? ) ) ? ? ( g ( Y ( r ) ? ? ) ) ) k r ? ( ? ( ? ? 0 + ? 1 g ( Y ( r ) ? ) ) ? ? ( ? ? 0 + ? 1 g ( Y ( r ) ? ? ) ) ) ? r ? , where frequency counts k r ? = # { Y 0 i = Y ( r ) ? , i = 1 , ? , n 0 } and ? r ? = # { Y 1 j = Y ( r ) ? , j = 1 , ? , n 1 } , corresponding to non-diseased and diseased subjects at distinct ordered test results. Let ? = {all monotone increasing functions on (??, ?). Denote Y ( 0 ) ? = ? ? and Y ( I n ? ) ? = + ? . Since ? is monotonic and ? 1 > 0, to maximize L? , we need to make the g ( Y ( r ) ? ) as large, and the g ( Y ( r ) ? ? ) as small. In addition, because g is monotonic and ? ? ? + ? d ? ( g ( y ) ) = 1 , hence, any g ? ? that maximizes L? must satisfy g ( y ) = g ( Y ( r ? 1 ) ? ) , if Y ( r ? 1 ) ? ? y < Y ( r ) ? for r = 1 , ? , I n ? . Hence the maximum likelihood estimate of g , denoted by ? , has to be a discrete function that only jumps at observations Y ( 1 ) ? < ? < Y ( I n ? ? 1 ) ? . With C r ? = g ( Y ( r ) ? ) , C 0 ? = ? ? , and C I n ? ? = + ? , we can write ( 7 ) as (8) L n ( ? , g ) = ? r = 1 I n ? ( ? ( C r ? ) ? ? ( C r ? 1 ? ) ) k r ? ( ? ( ? ? 0 + ? 1 C r ? ) ? ? ( ? ? 0 + ? 1 C r ? 1 ? ) ) ? r ? when g = ? . Therefore the estimation of ROC curve parameters ? 0 and ? 1, which are of primary interest, requires simultaneous estimation of the I n ? ? 1 number of nuisance parameters, C 1 ? , ? , C I n ? ? 1 ? . Using the same idea as in Metz et al. [ 4 ], we note that some of the jump points of ? , Y ( r ) ? ’s, can be ignored for estimating ? 0 and ? 1, which means we can obtain the estimates of ? 0 and ? 1 with fewer nuisance parameters. We state the results in Conclusion 1 below. Denote D ( Y ( r ) ? ) = { 2 if k r ? > 0 and ? r ? > 0 1 if k r ? > 0 and ? r ? = 0 0 if k r ? = 0 and ? r ? > 0 and ? = { Y ( r ) ? : D ( Y ( r ) ? ) = D ( Y ( r + 1 ) ? ) ? 1 , 1 ? r ? I n ? ? 2 } . Each jump point in ? has the same diseased status as its next contiguous jump point. Here, ? includes all jump points of a contiguous sequence with the same diseased status except the last point in the sequence. Conclusion 1 The maximum likelihood estimates of ? 0 and ? 1 can be determined by some estimating equations that don’t depend on those nuisance parameters C r ? = g ( Y ( r ) ? ) for which Y ( r ) ? belongs to ?. See Appendix A.1 for a proof of Conclusion 1. A practical consequence of the conclusion is that we can ignore the jump points in ? for estimating ? 0 and ? 1. After deleting the points in ?, we denote the remaining jump points of ? by Y (1) < ··· < Y ( In?1) and let C r = g ( Y ( r )) for 1 ? r ? I n ? 1, C 0 = ?? and C In = +?. The MLE of ? = ( ? 0 , ? 1) T and C = ( C 1 , ··· , C In?1 ) T can be obtained by maximizing (9) L n ( ? , g ) = ? r = 1 I n ( ? ( C r ) ? ? ( C r ? 1 ) ) k r ( ? ( ? ? 0 + ? 1 C r ) ? ? ( ? ? 0 + ? 1 C r ? 1 ) ) ? r , which is essentially ( 8 ) with I n ? replaced by I n . Here, for 2 ? r ? I n ? 1, k r = #{ Y ( r ?1) < Y 0 i ? Y( r ), i = 1, ···, n 0} and ? r = #{Y( r ?1) < Y1 j ?Y( r ), j = 1, ···, n 1}, k 1 = #{Y0 i ?Y(1), i = 1, ···, n 0}, ? 1 = #{Y1 j ? Y(1); j = 1, ···, n 1}, k In = #{Y0 i < Y( In?1) , i = 1, ···, n 0}, and ? In = #{Y1 j < Y( In?1) , j = 1, ···, n 1}. To obtain the estimator of ? , in the paper, we propose a two-stage iterative procedure, alternating the parametric and nonparametric estimation steps. Our idea for the nonparametric estimate is from Kvam and Samaniego [ 11 ]. Given ? , we can find the estimator of C by maximizing the likelihood function ( 9 ) with respect to C . The estimator of C must satisfy the following ( I n ? 1) score equations: (10) ? log { L n ( ? , g ) } ? C 1 = k 1 ? ( C 1 ) ? ( C 1 ) ? k 2 ? ( C 1 ) ? ( C 2 ) ? ? ( C 1 ) + ? 1 ? 1 ? ( ? ? 0 + ? 1 C 1 ) ? ( ? ? 0 + ? 1 C 1 ) ? ? 1 ? 2 ? ( ? ? 0 + ? 1 C 1 ) ? ( ? ? 0 + ? 1 C 2 ) ? ? ( ? ? 0 + ? 1 C 1 ) = 0 , ? log { L n ( ? , g ) } ? C r = k r ? ( C r ) ? ( C r ) ? ? ( C r ? 1 ) ? k r + 1 ? ( C r ) ? ( C r + 1 ) ? ? ( C r ) + ? 1 ? r ? ( ? ? 0 + ? 1 C r ) ? ( ? ? 0 + ? 1 C r ) ? ? ( ? ? 0 + ? 1 C r ? 1 ) ? ? 1 ? r + 1 ? ( ? ? 0 + ? 1 C r ) ? ( ? ? 0 + ? 1 C r + 1 ) ? ? ( ? ? 0 + ? 1 C r ) = 0 , 2 ? r ? I n ? 2 , ? log { L n ( ? , g ) } ? C I n ? 1 = k I n ? 1 ? ( C I n ? 1 ) ? ( C I n ? 1 ) ? ? ( C I n ? 2 ) ? k I n ? ( C I n ? 1 ) 1 ? ? ( C I n ? 1 ) + ? 1 ? I n ? 1 ? ( ? ? 0 + ? 1 C I n ? 1 ) ? ( ? ? 0 + ? 1 C I n ? 1 ) ? ? ( ? ? 0 + ? 1 C I n ? 2 ) ? ? 1 ? I n ? ( ? ? 0 + ? 1 C I n ? 1 ) 1 ? ? ( ? ? 0 + ? 1 C I n ? 1 ) = 0. Inspection of ( 10 ) shows that finding the estimator of C in a closed form is a challenge. Hence, an iterative algorithm is required. However, the standard Newton-Raphson iteration requires inversion of an ( I n ? 1) × ( I n ? 1) matrix, and this computation can become a problem if I n is large. But the solution to the likelihood equations can be easily obtained if an initial estimate of C 1 is given. Note that ? rk r = 0, for 1 ? r ? I n ; ? r? r +1 = 0 and k rk r +1 = 0 for 1 ? r ? I n ? 1. Suppose that we have selected an initial value of C 1, ? 1. Then from the first equation of ( 10 ), we obtain an estimate, ? 2, of C 2, C ? 2 = { ? 0 ? 1 + 1 ? 1 ? ? 1 ( ? ( ? ? 0 + ? 1 C ? 1 ) + ? 1 ? 2 ? ( ? ? 0 + ? 1 C ? 1 ) ? ( C ? 1 ) k 1 ? ( C ? 1 ) ) if k 2 = 0 ? ? 1 ( ? ( C ? 1 ) + k 2 ? ( ? ? 0 + ? 1 C ? 1 ) ? ( C ? 1 ) ? 1 ? 1 ? ( ? ? 0 + ? 1 C ? 1 ) ) if ? 2 = 0 . For r = 2, ···, I n ? 2, using the latest estimates, ? r ?1 and ? r , of ? r ?1 and C r , we solve the r th equation of ( 10 ) to obtain the following estimate of C r +1: C ? r + 1 = { ? 0 ? 1 + 1 ? 1 ? ? 1 ( ? ( ? ? 0 + ? 1 C ? r ) + ? 1 ? r + 1 ? ( ? ? 0 + ? 1 C ? r ) ( ? ( C ? r ) ? ? ( C ? r ? 1 ) ) k r ? ( C ? r ) ) if k r + 1 = 0 ? ? 1 ( ? ( C ? r ) + k r + 1 ? ( C ? r ) ( ? ( ? ? 0 + ? 1 C ? r ) ? ? ( ? ? 0 + ? 1 C ? r ? 1 ) ) ? 1 ? r ? ( ? ? 0 + ? 1 C ? r ) ) if ? r + 1 = 0 . Hence, given the initially chosen value of C 1, ? 1, we can obtain the estimates, C 2,…, ? In?1 , of C 2,…, C In?1 by solving the first I n ? 2 equations in ( 10 ). Now we are left to check whether those estimates also satisfy the last equation in ( 10 ), (11) ? ( C ? I n ? 2 , C ? I n ? 1 ) = 0 , where ? ( C I n ? 2 , C I n ? 1 ) = ? ? C I n ? 1 log { L n ( ? , g ) } . If ?( ? In?2 , ? In?1 ) = 0, the estimates, ? r , r = 1,…, I n ? 1, are the unique solution to Equation (10) . If ?( ? In?2 , ? In?1 ) ? 0, we need to update the initially chosen value estimate, ? 1, and repeat the whole estimation process until the last equation in ( 10 ) is satisfied. Let ? 0 be the true value of ? and g 0 be the true function of g . Denote C r 0 = g 0( Y ( r )). In the following Conclusion 2, we establish the relationship between C 1 and ?( C In?2 , C In?1 ) to help in updating the initially chosen value, ? 1. We provide a proof for Conclusion 2 in Appendix A.2 . Conclusion 2 Let ? n = ? 0 + o p (1). For any initial chosen value ? 1 of C 1, we let ? 2,…, ? In?1 be the corresponding solution to the first ( I n ? 2) equations in ( 10 ) and ? be the corresponding function for g . Then, when n is large enough, if ? 1 < C 10, then ? r < C r 0 for r = 2, ···, I n ? 1, and ? ( C ? I n ? 2 , C ? I n ? 1 ) = ? ? C I n ? 1 log { L n ( ? , g ) } ? g = g ? , ? = ? n < 0 ; if ? 1 > C 10, then ? r > C r 0 for r = 2, ···, I n ? 1, and ? ( C ? I n ? 2 , C ? I n ? 1 ) = ? ? C I n ? 1 log { L n ( ? , g ) } ? g = g ? , ? = ? n > 0. The results of Conclusion 2 provide a mechanism for updating the initially chosen value ? 1. If ?( ? In?2 , ? In?1 ) < 0, we should increase our initially chosen value, ? 1. On the other hand, if ?( ? In?2 , ? In?1 ) > 0, we should decrease our initially chosen value, ? 1. Given C , we can estimate ? by maximizing ( 9 ). We next outline the two-stage iterative procedure for estimating ? and C . Step 1. We combine data from the diseased and non-diseased samples and order test results in the combined sample, replace each test result by its true disease status. As a result, we create a sequence of disease statuses for the combined sample. Denote the number of different sequences with the same consecutive disease status by I n . Then, count the number of elements in each sequence, denoted by k = { k 1 , ? , k I n ? ? r = 1 I n k r = n 0 } for non-diseased subjects and ? = { ? 1 , ? , ? I n ? ? s = 1 I n ? s = n 1 } for diseased subjects. For example, if we have data {5.38, 2.1, 4.5} for non-diseased subjects and {12.5, 10.4, 16.8, 5.1, 13.5} for diseased subjects, the ordered test results in the combined sample are {2.1, 4.5, 5.1, 5.38, 10.4, 12.5, 13.5, 16.8}, and their corresponding disease statuses are { no, no, di, no, di, di, di, di }, where no and di indicate a non-diseased and diseased subject, respectively. Thus, in the above notation, we have I n = 4 and k 1 = 2, k 2 = 0, k 3 = 1, k 4 = 0 and ? 1 = 0, ? 2 = 1, ? 3 = 0, ? 4 = 4. Step 2. Given values of ? 0, ? 1, we estimate C 1 , ···, C In?1 by solving ( 10 ). Step 3. Given estimates of C 1 , ···, C In?1 , we estimate ? 0 and ? 1 by maximizing ( 9 ) respect to ? 0 and ? 1. Step 4. Repeat Steps 2 and 3 until two successive values for ( ? 0, ? 1, C 1, ···, C In?1 ) converge. Denote the convergent values of the iterate by ?? 0, ?? 1, ? 1, ···, ? In?1 . Step 5. The estimator ? , which is a discrete function that only jumps at observations Y ( 1 ) ? < ? < Y ( I n ? ? 1 ) ? , can be obtained by noting that for a sequence of M contiguous jump points which only involve non-diseased subjects, we have (12) k r ? ? ( C r ? ) ? ? ( C r ? 1 ? ) = ? = k r + M ? 1 ? ? ( C r + M ? 1 ? ) ? ? ( C r + M ? 2 ? ) = ? j = r r + M ? 1 k j ? ? ( C r + M ? 1 ? ) ? ? ( C r ? 1 ? ) . Since estimation of C r ? 1 ? and C r + M ? 1 ? has been obtained from Step 4, C ^ r ? can be obtained by the equality of the first and the last terms in the ( 12 ), and then, C ^ r + 1 ? can be obtained by the equality of the second and the last terms in the ( 12 ) and so on. Similarly we can estimate values of g at the jump points only involving diseased subjects by noting that for a sequence of M contiguous jump points that only involves diseased subjects, we have ? r ? ? ( ? ? D r ? ) ? ? ( ? ? D r ? 1 ? ) = ? = ? r + M ? 1 ? ? ( ? ? D r + M ? 1 ? ) ? ? ( ? ? D r + M ? 2 ? ) = ? j = r r + M ? 1 ? j ? ? ( ? ? D r + M ? 1 ? ) ? ? ( ? ? D r ? 1 ? ) , where D r ? = ( ? 1 , C r ? ) ? . Our final estimate of ? is actually a profile likelihood estimate, which maximizes the profile likelihood for ? given by P L ( ? ) = L n ( ? , g ^ ( ? ) ) , where ? ( ? ) maximizes the likelihood ? n ( ?, g ) for a fixed value of ? . This estimator is a function of the test values only through their ranks. Using the results on the properties of maximum profile likelihood estimates derived by Murphy and Van der Varrt[ 13 ], we can show that ?? is fully efficient and has the following asymptotic distribution result: n 1 / 2 ( ? ^ ? ? 0 ) ? N ( 0 , ? 0 ) , where ? 0 = lim n ? ? { ? ? 2 log L n ( ? , g ) n ? ? ? ? ? + ( ? 2 log L n ( ? , g ) n ? ? ? C ? ) × ( ? 2 log L n ( ? , g ) n ? C ? C ? ) ? 1 ( ? 2 log L n ( ? , g ) n ? C ? ? ? ) } ? 1 ? ? = ? 0 , g = g 0 . Based on the estimates of ? 0 and ? 1, we can estimate the ROC curve by ROC ^ ( u ) = ? ( ? ^ 0 + ? ^ 1 ? ? 1 ( u ) ) . Using the Taylor series expansion and the asymptotically normal result of ?? , we have the following asymptotic distribution result for the estimated ROC curve: n 1 / 2 ( ROC ^ ( u ) ? ROC ( u ) ) ? N ( 0 , ? R 2 ) , where ? R 2 = ? 2 ( ? 00 + ? 10 ? ? 1 ( u ) ) ( 1 ? ? 1 ( u ) ) ? ? 0 ( 1 ? ? 1 ( u ) ) , ? 00 and ? 10 are the true values of ? 0 and ? 1, respectively.  Conclusion 1 The maximum likelihood estimates of ? 0 and ? 1 can be determined by some estimating equations that don’t depend on those nuisance parameters C r ? = g ( Y ( r ) ? ) for which Y ( r ) ? belongs to ?. See Appendix A.1 for a proof of Conclusion 1. A practical consequence of the conclusion is that we can ignore the jump points in ? for estimating ? 0 and ? 1. After deleting the points in ?, we denote the remaining jump points of ? by Y (1) < ··· < Y ( In?1) and let C r = g ( Y ( r )) for 1 ? r ? I n ? 1, C 0 = ?? and C In = +?. The MLE of ? = ( ? 0 , ? 1) T and C = ( C 1 , ··· , C In?1 ) T can be obtained by maximizing (9) L n ( ? , g ) = ? r = 1 I n ( ? ( C r ) ? ? ( C r ? 1 ) ) k r ( ? ( ? ? 0 + ? 1 C r ) ? ? ( ? ? 0 + ? 1 C r ? 1 ) ) ? r , which is essentially ( 8 ) with I n ? replaced by I n . Here, for 2 ? r ? I n ? 1, k r = #{ Y ( r ?1) < Y 0 i ? Y( r ), i = 1, ···, n 0} and ? r = #{Y( r ?1) < Y1 j ?Y( r ), j = 1, ···, n 1}, k 1 = #{Y0 i ?Y(1), i = 1, ···, n 0}, ? 1 = #{Y1 j ? Y(1); j = 1, ···, n 1}, k In = #{Y0 i < Y( In?1) , i = 1, ···, n 0}, and ? In = #{Y1 j < Y( In?1) , j = 1, ···, n 1}. To obtain the estimator of ? , in the paper, we propose a two-stage iterative procedure, alternating the parametric and nonparametric estimation steps. Our idea for the nonparametric estimate is from Kvam and Samaniego [ 11 ]. Given ? , we can find the estimator of C by maximizing the likelihood function ( 9 ) with respect to C . The estimator of C must satisfy the following ( I n ? 1) score equations: (10) ? log { L n ( ? , g ) } ? C 1 = k 1 ? ( C 1 ) ? ( C 1 ) ? k 2 ? ( C 1 ) ? ( C 2 ) ? ? ( C 1 ) + ? 1 ? 1 ? ( ? ? 0 + ? 1 C 1 ) ? ( ? ? 0 + ? 1 C 1 ) ? ? 1 ? 2 ? ( ? ? 0 + ? 1 C 1 ) ? ( ? ? 0 + ? 1 C 2 ) ? ? ( ? ? 0 + ? 1 C 1 ) = 0 , ? log { L n ( ? , g ) } ? C r = k r ? ( C r ) ? ( C r ) ? ? ( C r ? 1 ) ? k r + 1 ? ( C r ) ? ( C r + 1 ) ? ? ( C r ) + ? 1 ? r ? ( ? ? 0 + ? 1 C r ) ? ( ? ? 0 + ? 1 C r ) ? ? ( ? ? 0 + ? 1 C r ? 1 ) ? ? 1 ? r + 1 ? ( ? ? 0 + ? 1 C r ) ? ( ? ? 0 + ? 1 C r + 1 ) ? ? ( ? ? 0 + ? 1 C r ) = 0 , 2 ? r ? I n ? 2 , ? log { L n ( ? , g ) } ? C I n ? 1 = k I n ? 1 ? ( C I n ? 1 ) ? ( C I n ? 1 ) ? ? ( C I n ? 2 ) ? k I n ? ( C I n ? 1 ) 1 ? ? ( C I n ? 1 ) + ? 1 ? I n ? 1 ? ( ? ? 0 + ? 1 C I n ? 1 ) ? ( ? ? 0 + ? 1 C I n ? 1 ) ? ? ( ? ? 0 + ? 1 C I n ? 2 ) ? ? 1 ? I n ? ( ? ? 0 + ? 1 C I n ? 1 ) 1 ? ? ( ? ? 0 + ? 1 C I n ? 1 ) = 0. Inspection of ( 10 ) shows that finding the estimator of C in a closed form is a challenge. Hence, an iterative algorithm is required. However, the standard Newton-Raphson iteration requires inversion of an ( I n ? 1) × ( I n ? 1) matrix, and this computation can become a problem if I n is large. But the solution to the likelihood equations can be easily obtained if an initial estimate of C 1 is given. Note that ? rk r = 0, for 1 ? r ? I n ; ? r? r +1 = 0 and k rk r +1 = 0 for 1 ? r ? I n ? 1. Suppose that we have selected an initial value of C 1, ? 1. Then from the first equation of ( 10 ), we obtain an estimate, ? 2, of C 2, C ? 2 = { ? 0 ? 1 + 1 ? 1 ? ? 1 ( ? ( ? ? 0 + ? 1 C ? 1 ) + ? 1 ? 2 ? ( ? ? 0 + ? 1 C ? 1 ) ? ( C ? 1 ) k 1 ? ( C ? 1 ) ) if k 2 = 0 ? ? 1 ( ? ( C ? 1 ) + k 2 ? ( ? ? 0 + ? 1 C ? 1 ) ? ( C ? 1 ) ? 1 ? 1 ? ( ? ? 0 + ? 1 C ? 1 ) ) if ? 2 = 0 . For r = 2, ···, I n ? 2, using the latest estimates, ? r ?1 and ? r , of ? r ?1 and C r , we solve the r th equation of ( 10 ) to obtain the following estimate of C r +1: C ? r + 1 = { ? 0 ? 1 + 1 ? 1 ? ? 1 ( ? ( ? ? 0 + ? 1 C ? r ) + ? 1 ? r + 1 ? ( ? ? 0 + ? 1 C ? r ) ( ? ( C ? r ) ? ? ( C ? r ? 1 ) ) k r ? ( C ? r ) ) if k r + 1 = 0 ? ? 1 ( ? ( C ? r ) + k r + 1 ? ( C ? r ) ( ? ( ? ? 0 + ? 1 C ? r ) ? ? ( ? ? 0 + ? 1 C ? r ? 1 ) ) ? 1 ? r ? ( ? ? 0 + ? 1 C ? r ) ) if ? r + 1 = 0 . Hence, given the initially chosen value of C 1, ? 1, we can obtain the estimates, C 2,…, ? In?1 , of C 2,…, C In?1 by solving the first I n ? 2 equations in ( 10 ). Now we are left to check whether those estimates also satisfy the last equation in ( 10 ), (11) ? ( C ? I n ? 2 , C ? I n ? 1 ) = 0 , where ? ( C I n ? 2 , C I n ? 1 ) = ? ? C I n ? 1 log { L n ( ? , g ) } . If ?( ? In?2 , ? In?1 ) = 0, the estimates, ? r , r = 1,…, I n ? 1, are the unique solution to Equation (10) . If ?( ? In?2 , ? In?1 ) ? 0, we need to update the initially chosen value estimate, ? 1, and repeat the whole estimation process until the last equation in ( 10 ) is satisfied. Let ? 0 be the true value of ? and g 0 be the true function of g . Denote C r 0 = g 0( Y ( r )). In the following Conclusion 2, we establish the relationship between C 1 and ?( C In?2 , C In?1 ) to help in updating the initially chosen value, ? 1. We provide a proof for Conclusion 2 in Appendix A.2 .  Conclusion 2 Let ? n = ? 0 + o p (1). For any initial chosen value ? 1 of C 1, we let ? 2,…, ? In?1 be the corresponding solution to the first ( I n ? 2) equations in ( 10 ) and ? be the corresponding function for g . Then, when n is large enough, if ? 1 < C 10, then ? r < C r 0 for r = 2, ···, I n ? 1, and ? ( C ? I n ? 2 , C ? I n ? 1 ) = ? ? C I n ? 1 log { L n ( ? , g ) } ? g = g ? , ? = ? n < 0 ; if ? 1 > C 10, then ? r > C r 0 for r = 2, ···, I n ? 1, and ? ( C ? I n ? 2 , C ? I n ? 1 ) = ? ? C I n ? 1 log { L n ( ? , g ) } ? g = g ? , ? = ? n > 0. The results of Conclusion 2 provide a mechanism for updating the initially chosen value ? 1. If ?( ? In?2 , ? In?1 ) < 0, we should increase our initially chosen value, ? 1. On the other hand, if ?( ? In?2 , ? In?1 ) > 0, we should decrease our initially chosen value, ? 1. Given C , we can estimate ? by maximizing ( 9 ). We next outline the two-stage iterative procedure for estimating ? and C . Step 1. We combine data from the diseased and non-diseased samples and order test results in the combined sample, replace each test result by its true disease status. As a result, we create a sequence of disease statuses for the combined sample. Denote the number of different sequences with the same consecutive disease status by I n . Then, count the number of elements in each sequence, denoted by k = { k 1 , ? , k I n ? ? r = 1 I n k r = n 0 } for non-diseased subjects and ? = { ? 1 , ? , ? I n ? ? s = 1 I n ? s = n 1 } for diseased subjects. For example, if we have data {5.38, 2.1, 4.5} for non-diseased subjects and {12.5, 10.4, 16.8, 5.1, 13.5} for diseased subjects, the ordered test results in the combined sample are {2.1, 4.5, 5.1, 5.38, 10.4, 12.5, 13.5, 16.8}, and their corresponding disease statuses are { no, no, di, no, di, di, di, di }, where no and di indicate a non-diseased and diseased subject, respectively. Thus, in the above notation, we have I n = 4 and k 1 = 2, k 2 = 0, k 3 = 1, k 4 = 0 and ? 1 = 0, ? 2 = 1, ? 3 = 0, ? 4 = 4. Step 2. Given values of ? 0, ? 1, we estimate C 1 , ···, C In?1 by solving ( 10 ). Step 3. Given estimates of C 1 , ···, C In?1 , we estimate ? 0 and ? 1 by maximizing ( 9 ) respect to ? 0 and ? 1. Step 4. Repeat Steps 2 and 3 until two successive values for ( ? 0, ? 1, C 1, ···, C In?1 ) converge. Denote the convergent values of the iterate by ?? 0, ?? 1, ? 1, ···, ? In?1 . Step 5. The estimator ? , which is a discrete function that only jumps at observations Y ( 1 ) ? < ? < Y ( I n ? ? 1 ) ? , can be obtained by noting that for a sequence of M contiguous jump points which only involve non-diseased subjects, we have (12) k r ? ? ( C r ? ) ? ? ( C r ? 1 ? ) = ? = k r + M ? 1 ? ? ( C r + M ? 1 ? ) ? ? ( C r + M ? 2 ? ) = ? j = r r + M ? 1 k j ? ? ( C r + M ? 1 ? ) ? ? ( C r ? 1 ? ) . Since estimation of C r ? 1 ? and C r + M ? 1 ? has been obtained from Step 4, C ^ r ? can be obtained by the equality of the first and the last terms in the ( 12 ), and then, C ^ r + 1 ? can be obtained by the equality of the second and the last terms in the ( 12 ) and so on. Similarly we can estimate values of g at the jump points only involving diseased subjects by noting that for a sequence of M contiguous jump points that only involves diseased subjects, we have ? r ? ? ( ? ? D r ? ) ? ? ( ? ? D r ? 1 ? ) = ? = ? r + M ? 1 ? ? ( ? ? D r + M ? 1 ? ) ? ? ( ? ? D r + M ? 2 ? ) = ? j = r r + M ? 1 ? j ? ? ( ? ? D r + M ? 1 ? ) ? ? ( ? ? D r ? 1 ? ) , where D r ? = ( ? 1 , C r ? ) ? . Our final estimate of ? is actually a profile likelihood estimate, which maximizes the profile likelihood for ? given by P L ( ? ) = L n ( ? , g ^ ( ? ) ) , where ? ( ? ) maximizes the likelihood ? n ( ?, g ) for a fixed value of ? . This estimator is a function of the test values only through their ranks. Using the results on the properties of maximum profile likelihood estimates derived by Murphy and Van der Varrt[ 13 ], we can show that ?? is fully efficient and has the following asymptotic distribution result: n 1 / 2 ( ? ^ ? ? 0 ) ? N ( 0 , ? 0 ) , where ? 0 = lim n ? ? { ? ? 2 log L n ( ? , g ) n ? ? ? ? ? + ( ? 2 log L n ( ? , g ) n ? ? ? C ? ) × ( ? 2 log L n ( ? , g ) n ? C ? C ? ) ? 1 ( ? 2 log L n ( ? , g ) n ? C ? ? ? ) } ? 1 ? ? = ? 0 , g = g 0 . Based on the estimates of ? 0 and ? 1, we can estimate the ROC curve by ROC ^ ( u ) = ? ( ? ^ 0 + ? ^ 1 ? ? 1 ( u ) ) . Using the Taylor series expansion and the asymptotically normal result of ?? , we have the following asymptotic distribution result for the estimated ROC curve: n 1 / 2 ( ROC ^ ( u ) ? ROC ( u ) ) ? N ( 0 , ? R 2 ) , where ? R 2 = ? 2 ( ? 00 + ? 10 ? ? 1 ( u ) ) ( 1 ? ? 1 ( u ) ) ? ? 0 ( 1 ? ? 1 ( u ) ) , ? 00 and ? 10 are the true values of ? 0 and ? 1, respectively.  3. Simulation studies In this section we conduct several simulation studies to (1) investigate the efficiency of the proposed estimator by comparing with the existing estimators, (2) assess the robustness of the proposed estimator against the departure from the binormal model, and (3) evaluate the accuracy of the asymptotic variance estimator of the proposed estimator in finite sample sizes. 3.1 Efficiency Since a valid program for the ZH method is no longer available and their Monte Carlo computation is complicated, we will not include the ZH estimator in our simulation study but will investigate the performance of the ZH estimator by using the estimates from Zou and Hall [ 16 ] and from Zou’s dissertation in our examples. In this section we investigate the statistical efficiency of the five methods: the proposed method, CM, MHS, AP and PC methods for estimating ? 0 and ? 1 in the binormal model and for estimating the corresponding ROC curve by numerical studies. We use the root of mean squared error (RMSE) to measure the performance of the various estimators for ? 0 and ? 1 and the sum of RMSEs (SRMSE) for ? 0 and ? 1 as an overall performance measure. We evaluate the performance of an estimator ROC ^ ( · ) for the ROC curve using the average square errors (ASE), defined by (13) ASE = 1 n grid ? k = 1 n grid { ROC ^ ( u k ) ? ROC ( u k ) } 2 , where { u k, k = 1, ···, n grid } are the grid points at which the functions ROC (·) are estimated. In the simulation studies, we choose n grid = 100 and u k ’s to be uniformly distributed over (0, 1). We choose 500 simulations for each scenario. Data for non-diseased subjects are generated from the standard normal distribution, and data for diseased subjects are generated from N (2, 1.44); hence the area under the ROC curve (AUC) is 0.9. We choose sizes of the diseased and non-diseased samples to be both equal and unequal numbers, ( n 0, n 1) = {(100, 100), (200, 100), (200, 200)}, to investigate the effect of the sample sizes on the performance of the estimates. The results are displayed in Table 1 and Figure 1 . Table 1 gives bias, SD, RMSE and SRMSE of the resulting estimators for ? 0 and ? 1 by the five methods. From Table 1 we see that in all cases, our estimator has the smallest SRMSE. Specifically, our estimator consistently has smaller bias, standard error, and RMSE than the CM estimator due to a smaller number of nuisance parameters to estimate: the number of the nuisance parameters are 50.82, 68.33 and 101.704 on average with SD = 7.17, 8.01 and 9.97, respectively in the proposed approach, and 200, 300 and 400 in the CM method for the case with ( n 0, n 1) = (100, 100), (200, 100) and (200, 200), respectively; Although the PC can have the smallest variance, its bias is also large and can even be larger than its variance, which means that the bias is significant and could not be ignored; the AP estimator is less biased than the PC estimator but has a larger variance than the PC estimator. Table 1 also show that all the estimators are improved when n 0 or n 1 increases. Figure 1 depicts the distribution of the estimated ASEs for the ROC curve over the 500 replications for each method. The proposed estimator and the CM estimator have comparable ASE, which is smaller than the other methods. The performance of the estimators MHS and AP is close to that of the proposed one in this setting. The PC estimator has larger ASE than the other estimators. Further simulation study (not reported here) shows that when the accuracy of a diagnostic test is not too high or the sample size is large so that I n can be large, the computation algorithm in the MHS method, which collapses too many jump points, will lose some information. Since the number of the nuisance parameters increase with the AUC decreasing for the proposed method, the AUC can affect the comparison of the performance of the proposed approach and the CM method. Therefore, we also conduct additional simulation studies with smaller AUCs. We generate data for non-diseased subjects still from the standard nrmal distribution, but data for diseased subjects from N(1,1) and N(0.5,1), resulting in the areas under the ROC curve (AUC) of 0.76 and 0.64, respectively. Table 2 gives bias, SD, RMSE and SRMSE of the resulting estimators for ? 0 and ? 1 by the proposed method and the CM method. From the result in Table 2 , we see that SRMSEs of our method are less than or equal to those from the CM; hence, our method may be a little bit better than the CM, or at a minimum, comparable to the CM for the case with low AUC. In summary, the CM, MHS, and AP estimators have similar efficiency as the proposed estimator with the proposed estimator being slightly better in terms of SRMSEs in Tables 1 and 2 . The AUC may affect the performance of the proposed approach and the CM method, because the number of different sequences with the same consecutive disease status, I n , decreases with the AUC increasing, hence the number of the parameters in our method decreases with the AUC increasing, while the number of the parameters in the CM is still n + 2 regardless the AUC increasing or decreasing. 3.2 Robustness In the subsection, we compare robustness of the five methods to the departure from the binormal assumption. It may be reasonable to expect a transformation to result in approximately normal data for non-diseased subjects, but since the population of diseased subjects is often a mixture of subpopulations of subjects in different stages of the disease/infection, it seems much more reasonable to expect that transformation would result in a mixture of normals rather than a single normal for diseased subjects. So, to investigate the robustness of the binormal model, we simulate test responses of non-diseased subjects from N (0, 1), but test responses of diseased subjects from the mixture of two normal distributions N (1.2, 1.22), and N (2.2, 1.52), with the corresponding mixing proportions of 1/2 and 1/2. We set ( n 0, n 1) = {(100, 100), (200, 200)} to investigate the effect of the sample sizes on the performance of the estimates. Figures 2(A) and 3(A) plot the average of the estimated ROC curves over the 500 replications for each method when the sample sizes are (100, 100) and (200, 200), respectively. The proposed estimator has the smallest ASE and hence is the most robust estimate among the five ones considered here. The CM, MHS and AP also have good robustness properties. The PC estimator has larger bias. Figures 2(B) and 3(B) depict the distribution of the ASE for the estimated ROC curves over the 500 replications for each method when the sample sizes are (100, 100) and (200, 200), respectively. The AP estimator has better ASE than the PC estimator, which means the AP estimator is more robust than the PC estimator. We also conduct numerical studies with a larger number of the components in a normal mixture. That is, we generate test results of non-diseased subjects from the standard normal distribution but test results of diseased subjects from a mixture of three normal distributions N (1.2, 1.22), N (2.2, 1.52) and N (2.2, 1) with the corresponding mixing proportions of 1/3, 1/3, and 1/3. The results (not reported here) are similar to those in Figures 2 and 3 except that the PC estimator seems to have the largest bias and ASE, suggesting that the robustness of the PC estimator may decrease as the number of components in normal mixtures increases. In summary, the CM, MHS, and AP estimators have similar robustness as the proposed estimators with the proposed estimator to be slightly better. 3.3 Asymptotic inference in finite sample Finally, we assess the accuracy of the variance estimate formula given in Section 2 in finite sample sizes. We investigate the performance of the variance estimate formula using the simulated data in Sections 3.1 and 3.2. Based on 500 simulated data sets, we obtain 500 estimates of ?? 0 and ?? 1 and their corresponding standard deviation estimates using the proposed method. From the estimates of ? 0 and ? 1, we form the empirical standard deviations, denoted by SD, which can be regarded as an approximation to the true standard deviations. We denote the average and the standard deviation of 500 estimated standard errors for the estimated ?? 0 and ?? 1 by SE ave and SE std , which summarize the overall performance of the standard error formula. We report our results in Tables 3 and 4 for the simulated binormal and mixture normal data in Sections 3.1 and 3.2, respectively. Our standard error estimators are very close to the “true” sample standard errors. The empirical CI coverage probabilities are close to their nominal levels 0.95.  3.1 Efficiency Since a valid program for the ZH method is no longer available and their Monte Carlo computation is complicated, we will not include the ZH estimator in our simulation study but will investigate the performance of the ZH estimator by using the estimates from Zou and Hall [ 16 ] and from Zou’s dissertation in our examples. In this section we investigate the statistical efficiency of the five methods: the proposed method, CM, MHS, AP and PC methods for estimating ? 0 and ? 1 in the binormal model and for estimating the corresponding ROC curve by numerical studies. We use the root of mean squared error (RMSE) to measure the performance of the various estimators for ? 0 and ? 1 and the sum of RMSEs (SRMSE) for ? 0 and ? 1 as an overall performance measure. We evaluate the performance of an estimator ROC ^ ( · ) for the ROC curve using the average square errors (ASE), defined by (13) ASE = 1 n grid ? k = 1 n grid { ROC ^ ( u k ) ? ROC ( u k ) } 2 , where { u k, k = 1, ···, n grid } are the grid points at which the functions ROC (·) are estimated. In the simulation studies, we choose n grid = 100 and u k ’s to be uniformly distributed over (0, 1). We choose 500 simulations for each scenario. Data for non-diseased subjects are generated from the standard normal distribution, and data for diseased subjects are generated from N (2, 1.44); hence the area under the ROC curve (AUC) is 0.9. We choose sizes of the diseased and non-diseased samples to be both equal and unequal numbers, ( n 0, n 1) = {(100, 100), (200, 100), (200, 200)}, to investigate the effect of the sample sizes on the performance of the estimates. The results are displayed in Table 1 and Figure 1 . Table 1 gives bias, SD, RMSE and SRMSE of the resulting estimators for ? 0 and ? 1 by the five methods. From Table 1 we see that in all cases, our estimator has the smallest SRMSE. Specifically, our estimator consistently has smaller bias, standard error, and RMSE than the CM estimator due to a smaller number of nuisance parameters to estimate: the number of the nuisance parameters are 50.82, 68.33 and 101.704 on average with SD = 7.17, 8.01 and 9.97, respectively in the proposed approach, and 200, 300 and 400 in the CM method for the case with ( n 0, n 1) = (100, 100), (200, 100) and (200, 200), respectively; Although the PC can have the smallest variance, its bias is also large and can even be larger than its variance, which means that the bias is significant and could not be ignored; the AP estimator is less biased than the PC estimator but has a larger variance than the PC estimator. Table 1 also show that all the estimators are improved when n 0 or n 1 increases. Figure 1 depicts the distribution of the estimated ASEs for the ROC curve over the 500 replications for each method. The proposed estimator and the CM estimator have comparable ASE, which is smaller than the other methods. The performance of the estimators MHS and AP is close to that of the proposed one in this setting. The PC estimator has larger ASE than the other estimators. Further simulation study (not reported here) shows that when the accuracy of a diagnostic test is not too high or the sample size is large so that I n can be large, the computation algorithm in the MHS method, which collapses too many jump points, will lose some information. Since the number of the nuisance parameters increase with the AUC decreasing for the proposed method, the AUC can affect the comparison of the performance of the proposed approach and the CM method. Therefore, we also conduct additional simulation studies with smaller AUCs. We generate data for non-diseased subjects still from the standard nrmal distribution, but data for diseased subjects from N(1,1) and N(0.5,1), resulting in the areas under the ROC curve (AUC) of 0.76 and 0.64, respectively. Table 2 gives bias, SD, RMSE and SRMSE of the resulting estimators for ? 0 and ? 1 by the proposed method and the CM method. From the result in Table 2 , we see that SRMSEs of our method are less than or equal to those from the CM; hence, our method may be a little bit better than the CM, or at a minimum, comparable to the CM for the case with low AUC. In summary, the CM, MHS, and AP estimators have similar efficiency as the proposed estimator with the proposed estimator being slightly better in terms of SRMSEs in Tables 1 and 2 . The AUC may affect the performance of the proposed approach and the CM method, because the number of different sequences with the same consecutive disease status, I n , decreases with the AUC increasing, hence the number of the parameters in our method decreases with the AUC increasing, while the number of the parameters in the CM is still n + 2 regardless the AUC increasing or decreasing.  3.2 Robustness In the subsection, we compare robustness of the five methods to the departure from the binormal assumption. It may be reasonable to expect a transformation to result in approximately normal data for non-diseased subjects, but since the population of diseased subjects is often a mixture of subpopulations of subjects in different stages of the disease/infection, it seems much more reasonable to expect that transformation would result in a mixture of normals rather than a single normal for diseased subjects. So, to investigate the robustness of the binormal model, we simulate test responses of non-diseased subjects from N (0, 1), but test responses of diseased subjects from the mixture of two normal distributions N (1.2, 1.22), and N (2.2, 1.52), with the corresponding mixing proportions of 1/2 and 1/2. We set ( n 0, n 1) = {(100, 100), (200, 200)} to investigate the effect of the sample sizes on the performance of the estimates. Figures 2(A) and 3(A) plot the average of the estimated ROC curves over the 500 replications for each method when the sample sizes are (100, 100) and (200, 200), respectively. The proposed estimator has the smallest ASE and hence is the most robust estimate among the five ones considered here. The CM, MHS and AP also have good robustness properties. The PC estimator has larger bias. Figures 2(B) and 3(B) depict the distribution of the ASE for the estimated ROC curves over the 500 replications for each method when the sample sizes are (100, 100) and (200, 200), respectively. The AP estimator has better ASE than the PC estimator, which means the AP estimator is more robust than the PC estimator. We also conduct numerical studies with a larger number of the components in a normal mixture. That is, we generate test results of non-diseased subjects from the standard normal distribution but test results of diseased subjects from a mixture of three normal distributions N (1.2, 1.22), N (2.2, 1.52) and N (2.2, 1) with the corresponding mixing proportions of 1/3, 1/3, and 1/3. The results (not reported here) are similar to those in Figures 2 and 3 except that the PC estimator seems to have the largest bias and ASE, suggesting that the robustness of the PC estimator may decrease as the number of components in normal mixtures increases. In summary, the CM, MHS, and AP estimators have similar robustness as the proposed estimators with the proposed estimator to be slightly better.  3.3 Asymptotic inference in finite sample Finally, we assess the accuracy of the variance estimate formula given in Section 2 in finite sample sizes. We investigate the performance of the variance estimate formula using the simulated data in Sections 3.1 and 3.2. Based on 500 simulated data sets, we obtain 500 estimates of ?? 0 and ?? 1 and their corresponding standard deviation estimates using the proposed method. From the estimates of ? 0 and ? 1, we form the empirical standard deviations, denoted by SD, which can be regarded as an approximation to the true standard deviations. We denote the average and the standard deviation of 500 estimated standard errors for the estimated ?? 0 and ?? 1 by SE ave and SE std , which summarize the overall performance of the standard error formula. We report our results in Tables 3 and 4 for the simulated binormal and mixture normal data in Sections 3.1 and 3.2, respectively. Our standard error estimators are very close to the “true” sample standard errors. The empirical CI coverage probabilities are close to their nominal levels 0.95.  4. An example We illustrate the application of our newly proposed method in an example on the accuracy of biomarkers for detecting pancreatic cancer [ 14 ]. This study examined two biomarkers, the antigenic determinant, designated as CA125, and carbohydrate antigen designated as CA19-9. The data consist of 51 measurements on subjects free of disease and 90 measurements on diseased subjects using the two biomarkers. Here, we used the two biomarkers to illustrate the application of our methodology. Although the binormal ROC model ( 3 ) may be robust, as shown in the simulation study, it is also useful to assess whether model ( 3 ) is appropriate for the data before we make inferences on the ROC curves of the CA125 and the CA19-9 using the binormal model. Here, we present a graphical method, used by Cai and Moskowitz [ 8 ], to test model ( 3 ). Figure 4(a) and 5(a) plot the empirical ROC curve, the maximum likelihood estimate of the ROC curve and its 95% pointwise confidence intervals (denoted CI in Figure 4(a) and 5(a) ) for CA19-9 and CA125, respectively, showing no obvious difference between the empirical ROC curve and the estimated ROC curve based on the binormal model. So, the binormal model is reasonable for the two biomarkers. Table 5 lists the estimates for the coefficients ? 0 and ? 1, and Figure 4(b) and Figure 5(b) plot the estimated ROC curves using the six methods for CA19-9 and CA125, respectively. Here, ZH’s parameter estimates were taken from Zou and Hall [ 7 ] and Zou’s Ph.D dissertation. Note that the parameters ( ? and ? ) in Zou and Hall [ 7 ] are related to our parameters, ? 0 and ? 1 in the following way: ? 0 = ? / ? , ? 1 = 1/ ? . From Table 5 , we can see that the ZL, CM, AP, MHS and ZH estimates are quite similar. The PC estimator is a little different from the others. The result is consistent with the simulation, which shows that the PC estimator may be biased.  A.1 Proof of Conclusion 1 Let ? n ( ? , g ) = 1 n log L n ( ? , g ) , where L n ( ?, g ) is defined by ( 8 ). Denote C ? = ( C 1 ? , ? , C I n ? ? 1 ? ) ? , C r ? = g ( Y ( r ) ? ) , and Y ( 1 ) ? < ? < Y ( I n ? ? 1 ) ? to be distinct ordered test results of Y 0 i , i = 1, ···, n 0 and Y 1 j , j = 1, ···, n 1. It can be shown that the MLE of ? and C * must satisfy the following equations: (15) ? ? n ( ? , g ) ? C r ? = 1 n ( k r ? ? ( C r ? ) ? ? ( C r ? 1 ? ) ? k r + 1 ? ? ( C r + 1 ? ) ? ? ( C r ? ) ) ? ( C r ? ) + 1 n ( ? r ? ? ( ? ? D r ? ) ? ? ( ? ? D r ? 1 ? ) ? ? r + 1 ? ? ( ? ? D r + 1 ? ) ? ? ( ? ? D r ? ) ) ? 1 ? ( ? ? D r ? ) = 0 , for 1 ? r ? I n ? ? 1 , and (16) ? ? n ( ? , g ) ? ? = 1 n ? r = 2 I n ? ? 1 ? r ? ? ( ? ? D r ? ) D r ? ? ? ( ? ? D r ? 1 ? ) D r ? 1 ? ? ( ? ? D r ? ) ? ? ( ? ? D r ? 1 ? ) + 1 n ? 1 ? ? ( ? ? D 1 ? ) D 1 ? ? ( ? ? D 1 ? ) ? 1 n ? I n ? ? ? ( ? ? D I n ? ? 1 ? ) D I n ? ? 1 ? 1 ? ? ( ? ? D I n ? ? 1 ? ) = 0 , where k r ? = # { Y 0 i = Y ( r ) ? , i = 1 , ? , n 0 } and ? r ? = # { Y 1 j = Y ( r ) ? , j = 1 , ? , n 1 } . If both Y ( r ) ? and Y ( r + 1 ) ? correspond to non-diseased subjects, then ? r ? = ? r + 1 ? = 0 , k r ? < 0 and k r + 1 ? < 0 . Hence, rom ( 15 ), we have k r ? ? ( C r ? ) ? ? ( C r ? 1 ? ) = k r + 1 ? ? ( C r + 1 ? ) ? ? ( C r ? ) . Extending this argument to a sequence of M contiguous jump points which only involve non-diseased subjects, we have k r ? ? ( C r ? ) ? ? ( C r ? 1 ? ) = ? = k r + M ? 1 ? ? ( C r + M ? 1 ? ) ? ? ( C r + M ? 2 ? ) , which is equal to ? j = r r + M ? 1 k j ? ? ( C r + M ? 1 ? ) ? ? ( C r ? 1 ? ) . Similar arguments indicate that for a sequence of M contiguous jump points which only involves diseased subjects, we have ? r ? ? ( ? ? D r ? ) ? ? ( ? ? D r ? 1 ? ) = ? = ? r + M ? 1 ? ? ( ? ? D r + M ? 1 ? ) ? ? ( ? ? D r + M ? 2 ? ) , which is equal to ? j = r r + M ? 1 ? j ? ? ( ? ? D r + M ? 1 ? ) ? ? ( ? ? D r ? 1 ? ) . Therefore, if we denote Y (1) < ··· < Y ( In? 1) to be the last point of contiguous jump points with same disease status, and C r = g ( Y ( r )), r = 1, ···, I n ? 1, for 1 ? r ? I n ? 1, we can write ( 15 ) and ( 16 ) as (17) ? ? n ( ? , g ) ? C r = 1 n ( k r ? ( C r ) ? ? ( C r ? 1 ) ? k r + 1 ? ( C r + 1 ) ? ? ( C r ) ) ? ( C r ) + 1 n ( ? r ? ( ? ? D r ) ? ? ( ? ? D r ? 1 ) ? ? r + 1 ? ( ? ? D r + 1 ) ? ? ( ? ? D r ) ) ? 1 ? ( ? ? D r ) = 0 , and (18) ? ? n ( ? , g ) ? ? = 1 n ? r = 2 I n ? 1 ? r ? ( ? ? D r ) D r ? ? ( ? ? D r ? 1 ) D r ? 1 ? ( ? ? D r ) ? ? ( ? ? D r ? 1 ) + 1 n ? 1 ? ( ? ? D 1 ) D 1 ? ( ? ? D 1 ) ? 1 n ? I n ? ( ? ? D I n ? 1 ) D I n ? 1 1 ? ? ( ? ? D I n ? 1 ) = 0 , respectively, where k r and ? r are defined in Section 2. Note that ( 17 ) and ( 18 ) do not depend on the nuisance parameters C r ? = g ( Y ( r ) ? ) 's with Y ( r ) ? ? ? . Hence Conclusion 1 follows.  A.2 Proof of Conclusion 2 Let ? 1 = C 10 + ? for any ? < 0 and ? 2, ···, ? In? 1 be the solution to the first I n ? 2 score equations in ( 10 ) given C 1 = ? 1 and ? is the corresponding function for g . Define ?? r = ?( ? r ) for r = 1, ···, I n ? 1. Let ?? In be the solution to the following equation: G n ( x ) ? k I n ? 1 ? ( C ? I n ? 1 ) ? ( C ? I n ? 1 ) ? ? ( C ? I n ? 2 ) ? k I n ? ( C ? I n ? 1 ) x ? ? ( C ? I n ? 1 ) + ? 1 ? I n ? 1 ? ( ? ? D ? I n ? 1 ) ? ( ? ? D ? I n ? 1 ) ? ? ( ? ? D ? I n ? 2 ) ? ? 1 ? I n ? ( ? ? D ? I n ? 1 ) x ? ? ( ? ? D ? I n ? 1 ) = 0. Since (19) k r n ? ( 1 ? b 0 ) [ ? ( C r 0 ) ? ? ( C r ? 1 , 0 ) ] = o p ( 1 ) and (20) ? r n ? b 0 [ ? ( ? 0 ? D r 0 ) ? ? ( ? 0 ? D r ? 1 , 0 ) ] = o p ( 1 ) , for 1 ? r ? I n , we have (21) G n ( x ) ? g n ( x ) = o p ( 1 ) , where (22) g n ( x ) = ( 1 ? b 0 ) ? ( C ? I n ? 1 ) [ ? ( C I n ? 1 , 0 ) ? ? ( C I n ? 2 , 0 ) ? ( C ? I n ? 1 ) ? ? ( C ? I n ? 2 ) ? 1 ? ? ( C I n ? 1 , 0 ) x ? ? ( C ? I n ? 1 ) ] + b 0 ? 1 ? ( ? ? D ? I n ? 1 ) [ ? ( ? ? D I n ? 1 , 0 ) ? ? ( ? ? D I n ? 2 , 0 ) ? ( ? ? D ? I n ? 1 ) ? ? ( ? ? D ? I n ? 2 ) ? 1 ? ? ( ? ? D I n ? 1 , 0 ) x ? ? ( ? ? D ? I n ? 1 ) ] . Since G n (?? In ) = 0, we have (23) g n ( ? ? I n ) = o p ( 1 ) . Furthermore, we have, 1 n ? ? C I n ? 1 log { L n ( ? , g ) } ? g = g ? = ( 1 ? b 0 ) ? ( C ? I n ? 1 ) [ ? ( C I n ? 1 , 0 ) ? ? ( C I n ? 2 , 0 ) ? ( C ? I n ? 1 ) ? ? ( C ? I n ? 2 ) ? 1 ? ? ( C I n ? 1 , 0 ) 1 ? ? ( C ? I n ? 1 ) ] + b 0 ? 1 ? ( ? ? D ? I n ? 1 ) [ ? ( ? ? D I n ? 1 , 0 ) ? ? ( ? ? D I n ? 2 , 0 ) ? ( ? ? D ? I n ? 1 ) ? ? ( ? ? D ? I n ? 2 ) ? 1 ? ? ( ? ? D I n ? 1 , 0 ) 1 ? ? ( ? ? D ? I n ? 1 ) ] + o p ( 1 ) = g n ( 1 ) + o p ( 1 ) = g n ( ? ( C I n , 0 ) ) + o p ( 1 ) , Hence, if the assumption that (24) ? ? r > ? ( C r 0 ) holds for r = I n , by ( 23 ) and the fact that g n ( x ) is a strict increasing function of x , we obtain 1 n ? ? C I n ? 1 log { L n ( ? , g ) } ? g = g ? < 0 for sufficient large ? , and hence the second part of Conclusion 2 follows. Now we prove the assumption ( 24 ) holds for r = 2, ···, I n . We use the inductive method to prove ( 24 ). The inductive method relies on I n ? 1 steps. The first step consists of an conclusion for r = 2. From ( 10 ), we see that ? 2 satisfies (25) G 1 ( x ) = 1 n ? ? C 1 log { L n ( ? , g ) } ? C 1 = C ? 1 , C 2 = x = k 1 n ? ( C ? 1 ) ? ( C ? 1 ) ? k 2 n ? ( C ? 1 ) ? ( x ) ? ? ( C ? 1 ) + ? 1 ? 1 n ? ( ? ? D ? 1 ) ? ( ? ? D ? 1 ) ? ? 1 ? 2 n ? ( ? ? D ? 1 ) ? ( ? ? x ? ) ? ? ( ? ? D ? 1 ) = 0. By ( 19 ) and ( 20 ), we have (26) G 1 ( x ) ? g 1 ( x ) = o p ( 1 ) , where g 1 ( x ) = ( 1 ? b 0 ) ? ( C ? 1 ) { ? ( C 10 ) ? ( C ? 1 ) ? ? ( C 20 ) ? ? ( C 10 ) ? ( x ) ? ? ( C ? 1 ) } + b 0 ? 1 ? ( ? ? D ? 1 ) { ? ( ? ? D 10 ) ? ( ? ? D ? 1 ) ? ? ( ? ? D 20 ) ? ? ( ? ? D 10 ) ? ( ? ? x ? ) ? ? ( ? ? D ? 1 ) } , Thus by ( 25 ) and ( 26 ), we have g 1( ? 2) = o p (1). Since ? 1 < C 10, g 1( C 20) < 0. Note that g 1( C 2) is an increasing function of C 2. Hence C ? 2 < C 20 , and ( 24 ) holds for r = 2. The step j consists of showing that the inequality ( 24 ) is true for r = j + 1 if the inequality ( 24 ) holds when r = 1, …, j . Using the same argument as before with r = 2, we can prove that ( 24 ) holds for r = j + 1 given ?? r < ?( C r 0), r = 2, ···, j . Hence the inequality ( 24 ) holds for r ? I n . Using the same argument as before with ? 1 = C 10 + ? , we can obtain the first part of Conclusion 2. 