Design and analysis issues in genome-wide somatic mutation studies of cancer The availability of the human genome sequence and progress in sequencing and bioinformatic technologies have enabled genome-wide investigation of somatic mutations in human cancers. This article briefly reviews challenges arising in the statistical analysis of mutational data of this kind. A first challenge is that of designing studies that efficiently allocate sequencing resources. We show that this can be addressed by two-stage designs and demonstrate via simulations that even relatively small studies can produce lists of candidate cancer genes that are highly informative for future research efforts. A second challenge is to distinguish mutated genes that are selected for by cancer (drivers) from mutated genes that have no role in the development of cancer and simply happened to mutate (passengers). We suggest that this question is best approached as a classification problem and discuss some of the difficulties of more traditional testing-based approaches. A third challenge is to identify biologic processes affected by the driver genes. This can be pursued by gene set analyses. These can reliably identify functional groups and pathways that are enriched for mutated genes even when the individual genes involved in those pathways or sets are not mutated at sufficient frequencies to provide conclusive evidence as drivers.  Introduction Genome-wide somatic mutation studies The discovery of genes mutated in human cancers has provided key insights into the mechanisms underlying tumorigenesis and has proven useful for the design of targeted therapeutic approaches [ 1 ]. Recently, the availability of the human genome sequence and progress in sequencing and bioinformatic technologies have enabled genome-wide investigation of somatic mutations in human cancers [ 2 , 3 ]. These studies exemplify an emerging trend that includes other large-scale sequencing efforts of cancer genomes [ 4 ]. Analysis focuses on the comparison between the sequences found in tumor samples and those of the originating normal tissues. The goal of this comparison is to identify regions of the genome that differ frequently enough to warrant further investigation of potential causal mechanisms. So far this comparison has focused primarily on coding sequences of well-annotated genes. Passengers and drivers Cancer arises as the result of successive clonal expansions driven by cells that acquire a selective advantage through mutations. Generally, alterations are the result of errors that arise during the process of DNA replication during cellular expansion. These errors are associated with mistakes during DNA polymerization or with external agents, such as carcinogens, and may or may not provide a selective advantage to the affected cell. As a result, before it undergoes a new mutation that provides a selective advantage, a cell will typically accumulate other alterations that are neutral with respect to selection. Mutations that are disadvantageous may also occur, but these will selected against during tumorigenesis and will not be present in clonal expansions of tumor cells. Genome-wide somatic mutation studies will therefore identify two types of mutations: the “drivers” – those providing a selective advantage–and the “passengers”–those neutral to the selection process [ 5 ]. Genes capable of harboring driver mutations are referred to as “driver genes.” Similarly, genes that are not driver genes are referred to as “passenger genes.” One of the major goals of the analysis of data from genome-wide somatic mutation studies is the ranking of genes based on the likelihood that they may be drivers. Mountains and hills If one represents likely driver genes as relief features on a map, the resulting landscapes will contain a small number of major mountains, representing genes that are mutated in the majority of cancers, and a much larger number of hills, representing the genes that are mutated at relatively low frequency. This general genomic landscape is a common feature of both breast and colorectal tumors [ 3 ]. So far, cancer research has focused on the gene mountains. The ability to analyze the sequence of virtually all protein-encoding genes in cancers has shown that the vast majority of mutations in cancers, including many that are highly likely to be drivers, do not occur in such mountains, emphasizing the heterogeneity and complexity of human neoplasia. This new view of cancer is consistent with the idea that a large number of mutations, each associated with a small fitness advantage, drive tumor progression [ 6 , 7 ]. But while the number of potential driver genes is large, changes appear to occur in a more limited number of “driver” pathways [ 1 , 4 , 8 – 11 ]. This landscape has important implications for the statistical design and analysis of genome-wide studies of somatic mutations in cancer.  Genome-wide somatic mutation studies The discovery of genes mutated in human cancers has provided key insights into the mechanisms underlying tumorigenesis and has proven useful for the design of targeted therapeutic approaches [ 1 ]. Recently, the availability of the human genome sequence and progress in sequencing and bioinformatic technologies have enabled genome-wide investigation of somatic mutations in human cancers [ 2 , 3 ]. These studies exemplify an emerging trend that includes other large-scale sequencing efforts of cancer genomes [ 4 ]. Analysis focuses on the comparison between the sequences found in tumor samples and those of the originating normal tissues. The goal of this comparison is to identify regions of the genome that differ frequently enough to warrant further investigation of potential causal mechanisms. So far this comparison has focused primarily on coding sequences of well-annotated genes.  Passengers and drivers Cancer arises as the result of successive clonal expansions driven by cells that acquire a selective advantage through mutations. Generally, alterations are the result of errors that arise during the process of DNA replication during cellular expansion. These errors are associated with mistakes during DNA polymerization or with external agents, such as carcinogens, and may or may not provide a selective advantage to the affected cell. As a result, before it undergoes a new mutation that provides a selective advantage, a cell will typically accumulate other alterations that are neutral with respect to selection. Mutations that are disadvantageous may also occur, but these will selected against during tumorigenesis and will not be present in clonal expansions of tumor cells. Genome-wide somatic mutation studies will therefore identify two types of mutations: the “drivers” – those providing a selective advantage–and the “passengers”–those neutral to the selection process [ 5 ]. Genes capable of harboring driver mutations are referred to as “driver genes.” Similarly, genes that are not driver genes are referred to as “passenger genes.” One of the major goals of the analysis of data from genome-wide somatic mutation studies is the ranking of genes based on the likelihood that they may be drivers.  Mountains and hills If one represents likely driver genes as relief features on a map, the resulting landscapes will contain a small number of major mountains, representing genes that are mutated in the majority of cancers, and a much larger number of hills, representing the genes that are mutated at relatively low frequency. This general genomic landscape is a common feature of both breast and colorectal tumors [ 3 ]. So far, cancer research has focused on the gene mountains. The ability to analyze the sequence of virtually all protein-encoding genes in cancers has shown that the vast majority of mutations in cancers, including many that are highly likely to be drivers, do not occur in such mountains, emphasizing the heterogeneity and complexity of human neoplasia. This new view of cancer is consistent with the idea that a large number of mutations, each associated with a small fitness advantage, drive tumor progression [ 6 , 7 ]. But while the number of potential driver genes is large, changes appear to occur in a more limited number of “driver” pathways [ 1 , 4 , 8 – 11 ]. This landscape has important implications for the statistical design and analysis of genome-wide studies of somatic mutations in cancer.  Design Choice of tumor samples The successive bottlenecks that characterize the evolution of a tumor are driven by mutations that tend to occur at different stages–mutations of certain pathways are typically important earlier on, while others are more likely to occur at a later stage. For example, in colorectal cancer, mutations that are associated with adenoma formation are typically different from those that contribute to the progression of those adenomas to carcinomas. Therefore, initial studies whose primary goal is to efficiently identify the largest number of drivers with the fewest samples have concentrated on advanced disease samples. This is because neoplasia is a dynamic process and advanced lesions harbor all the driver mutations present in earlier in that lesion, though the converse is not true. The identification of mutations in advanced lesions also provides the opportunity to determine the timing of these alterations during tumorigenesis, by examining earlier lesions from the same patients [ 12 ]. Prior to undertaking extensive sequence analysis, our group tested whether 300 known mutations and polymorphisms in a panel of 100 colorectal cancers could be detected using the final algorithms described in [ 3 ]. The sensitivity for detecting these mutations was 100%. Challenges arise from contamination of samples with surrounding nonneoplastic tissue and heterogeneity within tumors. Non-tumor-cell contamination can substantially reduce the sensitivity of sequencing analysis. It was for exactly this reason that all the cases we analyzed were cell lines or xenografts: the only human DNA in these samples is derived from the cancers. In our approach, we only describe clonal mutations, that is, those present in the vast majority (if not all) of the neoplastic cells within the specimen. As discussed in detail in [ 12 ], such mutations are the most important for driving the tumorigenic process. Another important consideration has been the exclusion of samples with such widespread genetic alterations that the information provided is minimal. For example, in their genome-wide mutation analysis of colorectal cancer Sjöblom et al. [ 2 ] excluded samples with mismatch repair mutations. An important goal of future studies should be that of characterizing from an epidemiological standpoint the frequency of tumors wherein a given gene or pathway plays the role of a driver. This will require different designs, larger sample sizes, and consideration of the patient population to which the estimated frequencies should be applied. Multistage sampling Despite recent progress in sequencing technologies, genome-wide analysis of somatic mutations in cancer remains a major undertaking. Time and cost considerations should be a factor in determining the scope of a study and the sample sizes. Significant gains in efficiency can be achieved by multistage approaches, in which an initial “discovery” phase is performed first on a genome-wide scale, followed by a “validation” phase in which genes that emerge as candidates from the discovery phase are evaluated in additional samples. For example Sjöblom et al. [ 2 ] performed a genome-wide analysis of all the genes in the CCDS database on 11 samples, followed by analysis of all the genes that were mutated at least once in 24 additional samples. Wood et al. [ 3 ] adopted a similar design, integrated by a third phase with the goal of providing a more accurate estimate of mutation frequencies on a yet smaller set of genes. In the Wood study about 4% of the genes in colon cancer and about 5% in breast cancer were found to be mutated in the discovery stage and thus sequenced in the validation stage. Simulation of mutation analysis data To facilitate design and analysis of mutation studies, we developed software to perform in silico experiments that exactly replicate the experimental procedure. They represent mutations found in a hypothetical genome with a known composition of driver and passenger genes. It is reasonable to assume that the likelihood of a random mutation will apply to individual nucleotides and that the precise base that is mutated as well as its neighbors is important in evaluating the probability of a mutational event. We will refer to this as the mutation’s “context.” Therefore, each gene’s probability of accumulating a random mutation will depend on its size and nucleotide composition. Also, in real experiments, if quality control criteria are applied to sequencing results, the number of nucleotides successfully sequenced is generally less than 100%. The actual fraction, or “coverage,” should be a consideration. In the simulation presented here we considered each gene in turn and simulated, for each nucleotide context, the number of mutations from a binomial distribution with success probability equal to either (a) the context-specific passenger rate or (b) a randomly selected rate, higher than the passenger rate. These rates were drawn from a distribution of mountains and hills that mimicked what was observed in real experiments. To generate mutations in driver genes, we used the empirically observed rates of the 160 genes found to be mutated in colorectal cancers in both the discovery and the validation screen of Wood et al. [ 3 ]. The number of available nucleotides in each context was based on the RefSeq database. For the binomial calculation, the gene sizes were adjusted using the proportion of nucleotides successfully sequenced in Wood et al. [ 3 ] for that particular gene and by the number of samples available in the discovery screen. We then considered all genes for which at least one mutation was generated, and repeated the process with samples to simulate the validation screen. The software used for the simulations presented here is available as part of a package called CancerMutationAnalysis [ 3 ]. Users can specify passenger and driver rates, sample sizes, gene sizes and composition, gene-specific counts of successfully sequenced nucleotides, and other variables. Sensitivity and positive predictive values in one and two-stage designs Using this tool, we assessed the trade-offs associated with choosing the sample sizes in one- and two-stage studies. To concisely capture the effectiveness of a specific choice, we focus on the properties of lists composed of the top T most promising genes, where “most promising” is defined in terms of the likelihood ratio test [ 13 ] for the null hypothesis that the gene is mutated at the same rate as the passenger mutation rate. We report the sensitivity–the proportion of genes included in the top T among all drivers, and the positive predictive value (PPV)– the proportion of drivers among the top T genes. The sensitivity is related to statistical power, but it is not the same for two reasons: it is a probability across a set of genes, rather than a probability for a single gene over multiple experiments, and the driver mutations rates are allowed to vary. Fig. 1 illustrates results for lists composed of the top 300 genes. Data are simulated assuming that there are 1000 drivers in the genome. Both the sensitivity and the PPV reach their maximum values of 0.3 and 1.0 at relatively small sample sizes. Even a relatively small experiment with 10 discovery and 20 validation samples has a PPV in excess of 75%. When the list size is 150, similar to Wood et al., the PPV of a study with 10 discovery and 20 validation samples is 98%. The passenger rates used in Fig. 1 correspond to the intermediate scenario of Wood et al. [ 3 ]. At higher rates the PPV and sensitivity are lower, though even small studies remain informative. For example, the PPV of a study with 10 discovery and 20 validation samples remains around 70%. An important assumption in this analysis is that the passenger rates are the same across genes and samples. If these rates were actually to vary across genes, larger samples would be required to achieve similar performance. Studies of optimal two-stage genotyping in population-based association studies using SNPs have suggested that two-stage designs halve the cost for a given power in that context [ 14 ]. The analyses presented here suggest that in mutation analysis studies the gains are likely to be comparable. For example, from Fig. 1 , the sensitivity of a study with 20 discovery samples and no validation (that is, a one-stage study) is comparable to that of a study with 10 discovery and 20 validation samples, while the sequencing effort involved is approximately 55% of the original effort, assuming that about 5% of the genes included in the discovery screen will be sequenced in the validation screen. Finally, the distribution of driver rates used in the simulations presented in Fig. 1 covers a broad range. We also examined the ability of a study to identify the larger hills or “major drivers.” We assume there are 150 major drivers and their rates are drawn from the distribution of the top 20 candidate colorectal cancer genes in Wood et al. [ 3 ]. The sensitivity of the list of top 150 genes in a study with 10 discovery and 20 validation samples is 59% and the PPV is 58%. A sensitivity of 80% is achieved by studies with 30 discovery and 60 validation samples, and a sensitivity of 83% with 40 discovery and 60 validation samples.  Choice of tumor samples The successive bottlenecks that characterize the evolution of a tumor are driven by mutations that tend to occur at different stages–mutations of certain pathways are typically important earlier on, while others are more likely to occur at a later stage. For example, in colorectal cancer, mutations that are associated with adenoma formation are typically different from those that contribute to the progression of those adenomas to carcinomas. Therefore, initial studies whose primary goal is to efficiently identify the largest number of drivers with the fewest samples have concentrated on advanced disease samples. This is because neoplasia is a dynamic process and advanced lesions harbor all the driver mutations present in earlier in that lesion, though the converse is not true. The identification of mutations in advanced lesions also provides the opportunity to determine the timing of these alterations during tumorigenesis, by examining earlier lesions from the same patients [ 12 ]. Prior to undertaking extensive sequence analysis, our group tested whether 300 known mutations and polymorphisms in a panel of 100 colorectal cancers could be detected using the final algorithms described in [ 3 ]. The sensitivity for detecting these mutations was 100%. Challenges arise from contamination of samples with surrounding nonneoplastic tissue and heterogeneity within tumors. Non-tumor-cell contamination can substantially reduce the sensitivity of sequencing analysis. It was for exactly this reason that all the cases we analyzed were cell lines or xenografts: the only human DNA in these samples is derived from the cancers. In our approach, we only describe clonal mutations, that is, those present in the vast majority (if not all) of the neoplastic cells within the specimen. As discussed in detail in [ 12 ], such mutations are the most important for driving the tumorigenic process. Another important consideration has been the exclusion of samples with such widespread genetic alterations that the information provided is minimal. For example, in their genome-wide mutation analysis of colorectal cancer Sjöblom et al. [ 2 ] excluded samples with mismatch repair mutations. An important goal of future studies should be that of characterizing from an epidemiological standpoint the frequency of tumors wherein a given gene or pathway plays the role of a driver. This will require different designs, larger sample sizes, and consideration of the patient population to which the estimated frequencies should be applied.  Multistage sampling Despite recent progress in sequencing technologies, genome-wide analysis of somatic mutations in cancer remains a major undertaking. Time and cost considerations should be a factor in determining the scope of a study and the sample sizes. Significant gains in efficiency can be achieved by multistage approaches, in which an initial “discovery” phase is performed first on a genome-wide scale, followed by a “validation” phase in which genes that emerge as candidates from the discovery phase are evaluated in additional samples. For example Sjöblom et al. [ 2 ] performed a genome-wide analysis of all the genes in the CCDS database on 11 samples, followed by analysis of all the genes that were mutated at least once in 24 additional samples. Wood et al. [ 3 ] adopted a similar design, integrated by a third phase with the goal of providing a more accurate estimate of mutation frequencies on a yet smaller set of genes. In the Wood study about 4% of the genes in colon cancer and about 5% in breast cancer were found to be mutated in the discovery stage and thus sequenced in the validation stage.  Simulation of mutation analysis data To facilitate design and analysis of mutation studies, we developed software to perform in silico experiments that exactly replicate the experimental procedure. They represent mutations found in a hypothetical genome with a known composition of driver and passenger genes. It is reasonable to assume that the likelihood of a random mutation will apply to individual nucleotides and that the precise base that is mutated as well as its neighbors is important in evaluating the probability of a mutational event. We will refer to this as the mutation’s “context.” Therefore, each gene’s probability of accumulating a random mutation will depend on its size and nucleotide composition. Also, in real experiments, if quality control criteria are applied to sequencing results, the number of nucleotides successfully sequenced is generally less than 100%. The actual fraction, or “coverage,” should be a consideration. In the simulation presented here we considered each gene in turn and simulated, for each nucleotide context, the number of mutations from a binomial distribution with success probability equal to either (a) the context-specific passenger rate or (b) a randomly selected rate, higher than the passenger rate. These rates were drawn from a distribution of mountains and hills that mimicked what was observed in real experiments. To generate mutations in driver genes, we used the empirically observed rates of the 160 genes found to be mutated in colorectal cancers in both the discovery and the validation screen of Wood et al. [ 3 ]. The number of available nucleotides in each context was based on the RefSeq database. For the binomial calculation, the gene sizes were adjusted using the proportion of nucleotides successfully sequenced in Wood et al. [ 3 ] for that particular gene and by the number of samples available in the discovery screen. We then considered all genes for which at least one mutation was generated, and repeated the process with samples to simulate the validation screen. The software used for the simulations presented here is available as part of a package called CancerMutationAnalysis [ 3 ]. Users can specify passenger and driver rates, sample sizes, gene sizes and composition, gene-specific counts of successfully sequenced nucleotides, and other variables.  Sensitivity and positive predictive values in one and two-stage designs Using this tool, we assessed the trade-offs associated with choosing the sample sizes in one- and two-stage studies. To concisely capture the effectiveness of a specific choice, we focus on the properties of lists composed of the top T most promising genes, where “most promising” is defined in terms of the likelihood ratio test [ 13 ] for the null hypothesis that the gene is mutated at the same rate as the passenger mutation rate. We report the sensitivity–the proportion of genes included in the top T among all drivers, and the positive predictive value (PPV)– the proportion of drivers among the top T genes. The sensitivity is related to statistical power, but it is not the same for two reasons: it is a probability across a set of genes, rather than a probability for a single gene over multiple experiments, and the driver mutations rates are allowed to vary. Fig. 1 illustrates results for lists composed of the top 300 genes. Data are simulated assuming that there are 1000 drivers in the genome. Both the sensitivity and the PPV reach their maximum values of 0.3 and 1.0 at relatively small sample sizes. Even a relatively small experiment with 10 discovery and 20 validation samples has a PPV in excess of 75%. When the list size is 150, similar to Wood et al., the PPV of a study with 10 discovery and 20 validation samples is 98%. The passenger rates used in Fig. 1 correspond to the intermediate scenario of Wood et al. [ 3 ]. At higher rates the PPV and sensitivity are lower, though even small studies remain informative. For example, the PPV of a study with 10 discovery and 20 validation samples remains around 70%. An important assumption in this analysis is that the passenger rates are the same across genes and samples. If these rates were actually to vary across genes, larger samples would be required to achieve similar performance. Studies of optimal two-stage genotyping in population-based association studies using SNPs have suggested that two-stage designs halve the cost for a given power in that context [ 14 ]. The analyses presented here suggest that in mutation analysis studies the gains are likely to be comparable. For example, from Fig. 1 , the sensitivity of a study with 20 discovery samples and no validation (that is, a one-stage study) is comparable to that of a study with 10 discovery and 20 validation samples, while the sequencing effort involved is approximately 55% of the original effort, assuming that about 5% of the genes included in the discovery screen will be sequenced in the validation screen. Finally, the distribution of driver rates used in the simulations presented in Fig. 1 covers a broad range. We also examined the ability of a study to identify the larger hills or “major drivers.” We assume there are 150 major drivers and their rates are drawn from the distribution of the top 20 candidate colorectal cancer genes in Wood et al. [ 3 ]. The sensitivity of the list of top 150 genes in a study with 10 discovery and 20 validation samples is 59% and the PPV is 58%. A sensitivity of 80% is achieved by studies with 30 discovery and 60 validation samples, and a sensitivity of 83% with 40 discovery and 60 validation samples.  Analysis Goals The overarching goal of data analysis in somatic mutation studies of cancer is to prioritize the research that follows. Two tasks are especially important: to provide quantitative measures useful for ranking the genes that are most worthy of further investigation, and to point to pathways or other gene classes whose analysis may reveal important mechanistic evidence or suggest therapeutic approaches. In this section we review statistical challenges related to these two tasks. Passenger mutation rates An important role in statistical analyses is played by the rate at which passenger mutations appear in cancer samples. This is a difficult quantity to estimate empirically, because the rate refers to hypothetical cell populations that underwent the same mutagenic exposures and clonal bottlenecks as a real cancer, but where those bottlenecks occurred for reasons other than selection. Wood et al. [ 3 ] approximated this situation by studying portions of the genomes of cancers that are a priori highly unlikely to harbor regions whose mutation would provide an advantage. In this way they obtained a lower bound for the passenger rates. Independently, estimates of the passenger mutation rates were also obtained through the quantification of synonymous missense mutations. As synonymous changes are expected not to be selected for or against as strongly during tumorigenesis, such changes can be used as a tool to approximate passenger mutation rates. The analysis of synonymous mutations provided two estimates of the nonsynonymous (NS) mutation rate. One estimate was based on the ratio of nonsynonymous to synonymous mutations in the human germline determined from the HapMap project, and was considered to be a minimum because the ratio of nonsynonymous to synonymous coding region mutations may be higher in the germline than in tumors because of greater negative selection for NS mutations in the germline. An additional estimate was derived by calculating the expected ratio of non-synonymous to synonymous changes after accounting for codon usage of RefSeq genes and the different mutation spectra observed in colorectal and breast cancers. This estimate was considered a maximum because it does not take into account the fact that nonsynonymous mutations that retard cell growth will be selected against during tumorigenesis. The fraction of such nonsynonymous alterations that retard cell growth may be quite large, as studies in yeast suggest that alterations of up to 40% of protein coding genes can lead to quantitative growth defects [ 15 ]. Passenger rates vary considerably from tumor to tumor, undoubtedly determined by their intrinsic mutability and the number of generations and bottlenecks through which they have evolved. Sorting drivers from passengers To prioritize future studies it is useful to assign, to each of the genes in which mutations are found a score that captures whether it is more plausibly a driver or a passenger. Statistically, this question can be formulated, as a first approximation, as that of classifying genes by whether they have mutation rates higher than the passenger rate. A useful framework for this analysis is that of classification: in our case, classification of genes into passengers and drivers. Probabilistic classification is especially useful, as it provides for each gene a probability of being a driver. Wood et al. [ 3 ], for example, use an empirical Bayesian approach adapted from Efron et al. [ 16 ] to derive these probabilities. The key feature underlying this approach is the in silico generation of a study identical to the one performed, except that all mutations occur at the passenger rates; i.e., there are no driver genes. For each gene a score is then computed for both the observed and in silico data. The distribution of these scores in the real experiment is then analyzed as a mixture of passengers’ scores, drawn from the distribution generated in silico , and drivers’ scores, drawn from a different and unknown distribution. For each gene, the probability of belonging to each of these two mixture components provides the classification probability. Alternative approaches proceed by testing for each gene the null hypothesis that the mutation rate is the same as the passengers rate. One challenge in this context is to devise an appropriate multiple testing adjustment. Traditional frequentist approaches have serious limitations. First, when data are collected in a two-stage approach, only genes that harbored, say, at least one mutation in the discovery screen is analyzed in the validation screen. As a result of this, P values are very computationally-intensive to evaluate. Second, P values will be 1 for all genes in which no mutations are found. This makes it impossible to provide adjustments that account for the size and coverage of those genes, which constitute the vast majority. This can lead to an excessive multiple testing correction of the P value calculations and an underestimate of the number of genes mutated at higher than passenger rates. Gene sets A third challenge is to identify biologic processes affected by the driver genes. To address this question, their putative roles based on sequence similarity, membership in known functional groups and pathways, and potential interactions with other proteins can be examined. These analyses can reliably identify functional groups and pathways that are enriched for mutated genes, even when the individual genes involved in those pathways are not mutated sufficiently often to provide conclusive evidence. Statistically, the goal is the evaluation of a set of genes as a single candidate driver. A simple approach along these lines is to consider an entire functional gene set as a pool of nucleotides at risk of somatic mutations and apply the same techniques used for individual genes directly to the whole pool [ 11 ]. This is a sensitive approach and is easy to implement. Possible drawbacks include an excessive emphasis on sets that include a single gene mutated at very high frequency and a lack of consideration of the sizes of the genes in which mutations were and were not found. Alternatively, genes can be sorted by a score that reflects the likelihood of being mutated at rates higher than the passenger rates, and a test can be used to compare the scores inside and outside functional gene sets, similarly to what was previously used for microarray expression analysis [ 17 – 19 ]. Gene set analysis can also be complemented by approaches that use natural language processing techniques to search the PubMed database for relationships between genes, highlighting additional candidate associations [ 20 ].  Goals The overarching goal of data analysis in somatic mutation studies of cancer is to prioritize the research that follows. Two tasks are especially important: to provide quantitative measures useful for ranking the genes that are most worthy of further investigation, and to point to pathways or other gene classes whose analysis may reveal important mechanistic evidence or suggest therapeutic approaches. In this section we review statistical challenges related to these two tasks.  Passenger mutation rates An important role in statistical analyses is played by the rate at which passenger mutations appear in cancer samples. This is a difficult quantity to estimate empirically, because the rate refers to hypothetical cell populations that underwent the same mutagenic exposures and clonal bottlenecks as a real cancer, but where those bottlenecks occurred for reasons other than selection. Wood et al. [ 3 ] approximated this situation by studying portions of the genomes of cancers that are a priori highly unlikely to harbor regions whose mutation would provide an advantage. In this way they obtained a lower bound for the passenger rates. Independently, estimates of the passenger mutation rates were also obtained through the quantification of synonymous missense mutations. As synonymous changes are expected not to be selected for or against as strongly during tumorigenesis, such changes can be used as a tool to approximate passenger mutation rates. The analysis of synonymous mutations provided two estimates of the nonsynonymous (NS) mutation rate. One estimate was based on the ratio of nonsynonymous to synonymous mutations in the human germline determined from the HapMap project, and was considered to be a minimum because the ratio of nonsynonymous to synonymous coding region mutations may be higher in the germline than in tumors because of greater negative selection for NS mutations in the germline. An additional estimate was derived by calculating the expected ratio of non-synonymous to synonymous changes after accounting for codon usage of RefSeq genes and the different mutation spectra observed in colorectal and breast cancers. This estimate was considered a maximum because it does not take into account the fact that nonsynonymous mutations that retard cell growth will be selected against during tumorigenesis. The fraction of such nonsynonymous alterations that retard cell growth may be quite large, as studies in yeast suggest that alterations of up to 40% of protein coding genes can lead to quantitative growth defects [ 15 ]. Passenger rates vary considerably from tumor to tumor, undoubtedly determined by their intrinsic mutability and the number of generations and bottlenecks through which they have evolved.  Sorting drivers from passengers To prioritize future studies it is useful to assign, to each of the genes in which mutations are found a score that captures whether it is more plausibly a driver or a passenger. Statistically, this question can be formulated, as a first approximation, as that of classifying genes by whether they have mutation rates higher than the passenger rate. A useful framework for this analysis is that of classification: in our case, classification of genes into passengers and drivers. Probabilistic classification is especially useful, as it provides for each gene a probability of being a driver. Wood et al. [ 3 ], for example, use an empirical Bayesian approach adapted from Efron et al. [ 16 ] to derive these probabilities. The key feature underlying this approach is the in silico generation of a study identical to the one performed, except that all mutations occur at the passenger rates; i.e., there are no driver genes. For each gene a score is then computed for both the observed and in silico data. The distribution of these scores in the real experiment is then analyzed as a mixture of passengers’ scores, drawn from the distribution generated in silico , and drivers’ scores, drawn from a different and unknown distribution. For each gene, the probability of belonging to each of these two mixture components provides the classification probability. Alternative approaches proceed by testing for each gene the null hypothesis that the mutation rate is the same as the passengers rate. One challenge in this context is to devise an appropriate multiple testing adjustment. Traditional frequentist approaches have serious limitations. First, when data are collected in a two-stage approach, only genes that harbored, say, at least one mutation in the discovery screen is analyzed in the validation screen. As a result of this, P values are very computationally-intensive to evaluate. Second, P values will be 1 for all genes in which no mutations are found. This makes it impossible to provide adjustments that account for the size and coverage of those genes, which constitute the vast majority. This can lead to an excessive multiple testing correction of the P value calculations and an underestimate of the number of genes mutated at higher than passenger rates.  Gene sets A third challenge is to identify biologic processes affected by the driver genes. To address this question, their putative roles based on sequence similarity, membership in known functional groups and pathways, and potential interactions with other proteins can be examined. These analyses can reliably identify functional groups and pathways that are enriched for mutated genes, even when the individual genes involved in those pathways are not mutated sufficiently often to provide conclusive evidence. Statistically, the goal is the evaluation of a set of genes as a single candidate driver. A simple approach along these lines is to consider an entire functional gene set as a pool of nucleotides at risk of somatic mutations and apply the same techniques used for individual genes directly to the whole pool [ 11 ]. This is a sensitive approach and is easy to implement. Possible drawbacks include an excessive emphasis on sets that include a single gene mutated at very high frequency and a lack of consideration of the sizes of the genes in which mutations were and were not found. Alternatively, genes can be sorted by a score that reflects the likelihood of being mutated at rates higher than the passenger rates, and a test can be used to compare the scores inside and outside functional gene sets, similarly to what was previously used for microarray expression analysis [ 17 – 19 ]. Gene set analysis can also be complemented by approaches that use natural language processing techniques to search the PubMed database for relationships between genes, highlighting additional candidate associations [ 20 ].  Conclusion We have briefly reviewed the main analysis challenges arising in genome-wide studies of somatic mutations in cancer. We showed via simulations that even with relatively small sample sizes, two-stage designs can be highly informative for future studies, and briefly reviewed the lessons we learned about such analyses from the efforts of Sjöblom et al. [ 2 ] and Wood et al. [ 3 ]. In statistical analyses of mutation frequency alone, the drivers are equated to the genes that are mutated at higher frequencies than the passengers. This is not the same as being a true cancer gene. The former can be precisely defined and investigated using cancer genome sequencing studies. The latter, while interpretable in many ways, implies some additional independent validation of causality. We believe that sequencing data can, at best, only point to candidates worthy of further study. The points presented here are applicable to studies employing the new generations of high-throughput massively parallel sequencing technologies, as they are similar to the classic Sanger sequencing methods that formed the bases for the current analysis. However, along with the promise that these new technologies offer, they also present unique challenges. For example, the above-cited studies were only possible because of the efficient and proven strategies for eliminating technical false positives that have been developed over the 30-year history of Sanger sequencing. Similar strategies will have to be developed for these new approaches. Additionally, all of the leading new technologies rely on digital sequencing (i.e., single molecule sequencing), which will both simplify and complicate mutational analyses. Such digital approaches require a significant oversampling to ensure that both alleles of a diploid sample are assessed in order to avoid technical false negatives. At the same time, the digital nature and required oversampling of these new approaches may allow application of an unprecedented statistical rigor to the evaluation of sequencing data.  Figure Fig. 1 Sensitivity (left) and positive predictive value (right) of alternative sample sizes. The black continuous line represents a single-stage design, while the dotted lines represent two-stage designs with different validation sample sizes (20, 40, or 60). Because we considered lists of the top 300 genes, and simulated data assuming that there are 1000 drivers in the genome, the sensitivity can be at most 0.3. 