A rank-based sample size method for multiple outcomes in clinical trials SUMMARY O’Brien introduced a rank-sum-type global statistical test to summarize treatment’s effect on multiple outcomes and to determine whether a treatment is better than others. This paper presents a sample size computation method for clinical trial design with multiple primary outcomes, and O’Brien’s test or its modified test is used for the primary analysis. A new measure, the global treatment effect (GTE), is introduced to summarize treatment’s efficacy from multiple primary outcomes. Computation of the GTE under various settings is provided. Sample size methods are presented based on prespecified GTE both when pilot data are available and when no pilot data are available. The optimal randomization ratio is given for both cases. We compare our sample size method with the Bonferroni adjustment for multiple tests. Since ranks are used in our derivation, sample size formulas derived here are invariant to any monotone transformation of the data and are robust to outliers and skewed distributions. When all outcomes are binary, we show how sample size is affected by the success probabilities of outcomes. Simulation shows that these sample size formulas provide good control of type I error and statistical power. An application to a Parkinson’s disease clinical trial design is demonstrated. Splus codes to compute sample size and the test statistic are provided.  1. INTRODUCTION Sample size computation is an important component in clinical trial design. When a single outcome is used as a primary outcome, the computation of sample size has been well studied in the literature [ 1 ]. For clinical studies where it is difficult to obtain a single summary score for the treatment comparison, multiple outcomes are usually studied jointly. This is true, for example, in Parkinson’s disease (PD) clinical trials, when the objective is to identify a neuroprotective treatment that can slow or stop PD progression, and no single outcome is sufficient to capture PD disability in all its aspects, e.g. motor and nonmotor functions, cognition, and drug complications. Furthermore, a treatment may be considered beneficial if it shows improvement in most outcome measures. This work was motivated by the following challenges in clinical trial designs when the goal is to identify a better (or nonfutile) treatment. First, it is often unrealistic to characterize a joint parametric distribution of multiple primary outcomes, even when all marginal parametric distributions of single outcomes are known. Second, since outcomes are often measured in different scales and may be of different types (continuous, binary, or ordered categorical outcomes), it can be difficult to summarize a treatment’s global effect across different outcomes parametrically. Finally, if outcomes have quite skewed distributions, models based on outcome means are not robust to outliers. The aim of this paper is to present sample size computation formulas for the design of clinical trials using nonparametric techniques to cope with these challenges. Suppose that we wish to compute sample size for a future clinical trial that compares two groups using K primary outcomes. Throughout the paper, we assume that all outcomes are coded in the way that larger observations correspond to better medical conditions. We use capital letter X i v ( o ) (or X iv ) to denote the v th random variable in the i th group in a pilot (or the future) study and small letter X i , j v ( o ) (or x i,jv ) to denote the corresponding realization of X i v ( o ) (or X iv ) from the j th subject in the i th group, v =1, …, K ; i =1,2. Brunner et al. [ 2 ] have formulated hypotheses for this setting as H 0 : p v = P ( X 1 v [ t d b ] X 2 v ) + 1 2 P ( X 1 v = X 2 v ) = 1 2 v =1, …, K , and characterize this as the multivariate Behrens–Fisher problem. The advantage of using p v as a measure of treatment’s effect on the v th outcome was discussed in [ 3 - 5 ]. In clinical trials, a weighted average of p v with weights representing the relative importance of the outcomes could be of interest to investigators in assessing a treatment’s global effect on multiple outcomes. In this paper, we confine our attention to cases when the goal is to test whether a treatment is preferred to another. We thus formulate the one-sided hypotheses of the nonparametric problem as (1) H 0 : ? ? = ? v = 1 K ? v ? K ? 0 , H 1 : ? ? [ m v g ] 0 where ? v = 2 p v ? 1 Since exchanging the labeling of ‘group 1’ and ‘group 2’ will result in a change of sign in ? ? , we can confine our attention to problem ( 1 ) with statistical power controlled at a given ? ? a = ? v = 1 K ? v a ? K [ m v g ] 0 . Sample size for a two-sided problem can be derived using parallel methods. Note that ? v = P ( X 1 v [ t d b ] X 2 v ) ? P ( X 1 v [ m v g ] X 2 v ) . We define ? ? as the global treatment effect (GTE) on all K outcomes and ? v as the treatment effect on the v th outcome. This GTE is interpretable even if different outcomes are measured in different scales. O’Brien [ 6 ] introduced a simple rank-sum-type global procedure for testing problem ( 1 ) to summarize a treatment’s global effect across different outcomes and to answer questions like ‘Should we give this treatment to patients?’ O’Brien’s test has been used extensively in clinical research in neurologic diseases, HIV, cancer, health services research, psychiatric diseases, and autoimmune diseases. In spite of its wide applications, sample size computation method using O’Brien’s test in clinical trial design has not been developed. This paper provides simple analytic sample size computation method when O’Brien’s rank-sum test or its modified test [ 7 ] is used for clinical trial primary analysis. Although equal weights for ? v s are used in ( 1 ), results in this paper can be extended to cases when other prespecified weights are chosen. When all outcomes are normally distributed, Tang et al. [ 8 ] discussed how to compute sample sizes in group-sequential designs when outcome means ? 1, …, ? K are related through ? v = ?? v for known positive numbers ? 1, …, ? K when testing H 0: ? =0 vs H 1: ? >0. Whitehead [ 9 ] derived a sample size computation formula for univariate ordered categorical outcome under the assumption of proportional odds. If all categories are equiprobable, the required sample size decreases as the number of categories increases. The limiting case is the sample size from the Wilcoxon–Mann–Whitney test where a full ranking of outcome values was achieved. For multivariate outcomes, Rochon [ 10 ] presented a table of minimum sample size for binary outcomes when a GEE procedure is used for data analysis. We will show that, when all outcomes are binary, the sample sizes based on Rochon’s GEE method and ours are driven by outcomes with success probabilities close to 0.5. In this paper, using O’Brien’s rank-sum-type test or its modified test [ 7 ], we present sample size computation for problem ( 1 ) when the goal is to identify a beneficial (or nonfutile) treatment using multiple primary outcomes. Outcomes can be continuous, discrete, and a mixture of continuous and discrete random variables. We will control type I error rate, ? , at the null hypothesis specified by ( 1 ) and power, (1? ? ), for a given alternative GTE value ? ? a [ m v g ] 0 . Methods to choose ? ? a are discussed in Section 2. We derive sample size expressions for rank-sum-type test and its modified test both when no historical data are available (Section 3) and when some historical data are available (Section 4). We compare our sample size formula with Noether’s result [ 11 ] for a univariate outcome in Section 5. In many nonparametric tests, since the null hypothesis often assumes that the groups have a common distribution, we show a reduction in sample size under this more restricted null assumption in Section 6. For multiple outcomes, Section 7 compares rank-sum-type test with the Bonferroni adjustment both in sample size and in scientific questions to be addressed. When all outcomes are binary, Section 8 examines how sample sizes in both Rochon’s formula [ 10 ] and our formula are affected by outcomes whose success probabilities are close to 0.5. Simulation in Section 9 shows that sample size derived from this paper gives good control of type I error and statistical power even for moderate sample sizes. Finally, an application to a clinical trial design is demonstrated in Section 10.  2. DETERMINATION OF <inline-formula><mml:math display="inline" id="M12" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>?</mml:mi><mml:mo stretchy="false">?</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> FROM PRIOR DATA OR LITERATURE The definition of GTE, ? ? , is similar to Kendall’s ? . Both of them take values between ?1 and 1. Kendall’s ? measures the degree of similarity between two groups, whereas GTE measures the degree of dissimilarity between two groups. When ? ? = 0 , there is no global preference between groups 1 and 2. When ? ? = ? 1 , group 1 is preferred the most. When ? ? = 1 , group 2 is preferred the most. Larger positive ? ? corresponds to a higher degree of group 2 preference. The selection of a parameter value ? ? a as a ‘clinically meaningful treatment difference’ for the control of statistical power depends in practice on many factors including considerations of scientific rationale, budget, pilot data, or some other source of information. When no pilot data are available, investigators sometimes choose this clinically meaningful treatment difference value using a value suggested in the literature. In this section, we discuss how to incorporate available treatment information when choosing a reasonable ? ? a value for the sample size computation. Since ? ? a is an average of the GTEs from single outcomes ? 1 a , …, ? Ka , we need to discuss only the case when K =1 without a loss of generality. We thus use ? a to denote ? ? a and drop the subscript v in X i v ( o ) . When some pilot data are available with sample size m i in the i th group ( i =1,2), an unbiased estimate of ? ( o ) = P ( X 1 ( o ) [ t d b ] X 2 ( o ) ) ? P ( X 1 ( o ) [ m v g ] X 2 ( o ) ) is given by ? ^ = ( 1 ? m 1 m 2 ) { 2 ? j = 1 m 2 R 2 j ( o ) ? m 2 ( m 1 + m 2 + 1 ) } where R 2 j ( o ) is the rank of the observation from the j th subject in group 2. Based on an investigator’s goal of the study, a value of ? a might be generated from ? ^ , but the cautious of Kraemer et al. [ 12 ] regarding pilot study data generally should be noted. Treatment difference is often expressed in terms of means and standard deviations using normal approximation or through summary statistics using other parametric approximation. The remainder of this section provides computational formulas or numerical values of ? ( o ) when some parametric assumptions to the distributions of X 1 ( o ) and X 2 ( o ) are made. Investigators can choose ? a using ? ( o ) as reference. Note that such a parametric approximation is used only to help investigators select a reasonable ? a value. This is fundamentally different from making a parametric assumption in the joint distribution of the multiple outcomes for the derivation of the test statistic and sample size computation. In the literature, a monotone increasing transformation (e.g. log-transformation or square-root transformation) is sometimes applied to the data to obtain a better parametric approximation, and summary statistics are reported using the transformed data. Since GTE is invariant to any monotone increasing transformation g of the data, we do not need to distinguish between distributional assumptions of ( X 1 ( o ) , X 2 ( o ) ) and ( g ( X 1 ( o ) ) , g ( X 2 ( o ) ) ) for the computation of ? ( o ). The advantage of using GTE to measure treatment difference is that, even if different monotone transformations have been applied to different outcomes in the literature, we can still calculate and interpret GTE. If both X 1 ( o ) and X 2 ( o ) have symmetric distributions with identical means, then GTE ? ( o )=0. For other cases, we discuss continuous outcomes and discrete outcomes separately: If X i ( o ) has a normal distribution with density function f i ( x ) = ( 1 ? 2 ? ? i 2 ) e ? ( x ? ? i ) 2 ? ( 2 ? i 2 ) then ? ( o ) = 2 ? ( ( ? 2 ? ? 1 ) ? ? 1 2 + ? 2 2 ) ? 1 . If X i ( o ) has an exponential distribution with density function f i ( x )= ? i e? ? ix I ( x >0), then ? ( o )=( ? 1? ? 2)/( ? 1+ ? 2). When X i ( o ) has a continuous but skewed distribution, its distribution sometimes can be approximated by a Gamma distribution. The density of a Gamma( ?,? ) distribution is f ( x )= ? ? ? x ? ?1e? x/? I ( x >0)/?( ? ). Suppose that X i ~Gamma( ? i,? ) with a common scale parameter but different shape parameters. We consider the cases when ? =0.5 or 2, ? 1 ranging from 0.5 to 10 and ? 2/ ? 1 ranging from 0.3 to 0.8. These parameters are chosen to capture different shapes of the density function. The corresponding ? ( o ) values are given in Table I . If X i ( o ) is continuous with finite domain, one can apply a monotone transformation to confine its support to interval [0,1]. A Beta( ?,? ) distribution with density function f ( x )= x ? ?1(1? x )1? ? ?( ? + ? )/{?( ? )?( ? )} can be used to approximate a continuous distribution defined in interval [0,1]. When ? = ? , f ( x ) has a symmetric shape. Function f ( x ) evolves from U-shape when ? = ? =0.5 to bell shape when ? = ? =2.0. It is skewed to the right when ? < ? and skewed to the left when ? > ? . Since X ~Beta( ? , ? ) is equivalent to 1? X ~Beta( ? , ? ), w.l.o.g., we consider only the case when X i ( o ) ~ Beta ( ? i , ? i ) with ? 1< ? 1. Table I also lists values of ? ( o ) for different combinations of ? 1, ? 1, ? 2, and ? 2. If X i ( o ) is binary such that X i ( o ) ~ Bernoulli ( p i ) with P ( X i ( o ) = 1 ) = p i , then ? ( o )= p 2? p 1. If X i ( o ) is discrete and is approximated by a geometric distribution: X i ( o ) ~ Geometric ( p i ) with P ( X i ( o ) = x ) = p i ( 1 ? p i ) x ? 1 ( x = 1 , 2 , … ) , then ? ( o )=( p 1? p 2)/( p 1+ p 2? p 1 p 2). Suppose that X i ( o ) has a Poisson distribution: P ( X i ( o ) = x ) = ? i x e ? ? i ? x !. When ? increases, Poisson( ? ) approaches to a normal distribution. When ? ?10, it resembles the bell-shaped distribution. Table I lists ? ( o ) values when ? 1=0.25,0.5,1,3,6,10 and ? 2/ ? 1=0.3,0.5,0.7,0.9,0.95. If ? 2> ? 1, we can switch the roles of X 1 and X 2 and then apply Table I . To switch back the roles of X 1 ( o ) and X 2 ( o ) , we can simply change the sign of ? ( o ). The sign of ? ( o ) is also consistent with the sign of mean change, the sign median difference, and the stochastic ordering. More specifically, when both X 1 ( o ) and X 2 ( o ) are from the same exponential family with probability distribution functions f ( x )=exp[ ? ix ? b ( ? i )? a ( x )] ( i =1,2), respectively, for some convex function b (·) and continuous function a (·), then ? ( o )>0 if and only if E [ X 2 ( o ) ] ? E [ X 1 ( o ) ] [ m v g ] 0 . As pointed out by one of our reviewers, prior data may guide what to expect for a difference, but it does not tell what is ‘clinically’ meaningful. In application, one might incorporate GTE computed from pilot data with information from clinical resources when determining a clinically meaningful ? ? a value, but overall this is a clinical assessment.  3. SAMPLE SIZE ESTIMATE WHEN NO HISTORICAL DATA ARE AVAILABLE Suppose that ( x ij 1, …, x ijK ) will be the future observation from the j th subject in the i th group, i =1,2; j =1, …, n i . For each i , it is assumed that {( x ij 1, …, x ijK ), j =1, …, n i } are independent identically distributed realizations of a random vector X i =( X i 1, …, X iK ). Denote N = n 1+ n 2, F i u ( t ) = P ( X i u [ t d b ] t ) + 1 2 P ( X i u = t ) , ? v = P ( X 1 v < X 2 v )? P ( X 1 v > X 2 v ), and ? =( ? 1, …, ? K )T. Throughout this paper, we impose the regularity conditions var{ F 1 v ( X 2 v )}>0 and var{ F 2 v ( X 1 v )}>0 ( v =1, …, K ) to rule out degenerate distributions and redundant parameters. Let r 0= n 2/ n 1 be a pre-specified (known) randomization ratio (0< r 0<?) in the future study, R ijv be the rank of x ijv among { x 11 v , …, x 1 n 1 v , …, x 21 v , …, x 1 n 2 v }, R ? i = ? j = 1 n i ? v = 1 K R i j v ? n i be the mean rank sum in group i , ? ^ i 2 be the sample variance of rank sums { ? v = 1 K R i j v , j = 1 , … , n i } , and ? ^ p 2 be the pooled sample variance of rank sums in the two groups. Then, O’Brien’s rank-sum-type test statistic can be expressed as T 1 = R ? 2 ? R ? 1 ? ^ p 1 ? n 1 + 1 ? n 2 or T 2 = R ? 2 ? R ? 1 ? ^ 1 2 ? n 1 + ? ^ 2 2 ? n 2 respectively, when treating two samples with equal or unequal variance. If F 1 and F 2 are not equal under H 0, Huang et al. [ 7 ] proposed to modify T 1 and T 2 by T 1 a = R ? 2 ? R ? 1 ? ^ p h ^ 1 ( 1 ? n 1 + 1 ? n 2 ) or T 2 a = R ? 2 ? R ? 1 h ^ 2 ( ? ^ 1 2 ? n 1 + ? ^ 2 2 ? n 2 ) where h ^ 1 and h ^ 2 are consistent estimators of h 1 = ? u = 1 k ? v = 1 k ( 1 + r 0 ) 2 ( r 0 a u v + b u v ) ? u = 1 k ? v = 1 k [ e u v + ( b u v + 2 f u v ) r 0 + ( a u v + 2 q u v ) r 0 2 + p u v r 0 3 ] and h 2 = ? u = 1 k ? v = 1 k ( 1 + r 0 ) 2 ( r 0 a u v + b u v ) ? u = 1 k ? v = 1 k [ b u v + ( e u v + 2 q u v ) r 0 + ( p u v + 2 f u v ) r 0 2 + a u v r 0 3 ] respectively, where a uv =cov{ F 2 u ( X 1 u ), F 2 v ( X 1 v )}, b uv =cov{ F 1 u ( X 2 u ), F 1 v ( X 2 v )}, e uv =cov{ F 1 u ( X 1 u ), F 1 v ( X 1 v )}, f uv =cov{ F 1 u ( X 1 u ), F 2 v ( X 1 u )}, p uv =cov{ F 2 u ( X 2 u ), F 2 v ( X 2 v ) and q uv =cov{ F 2 u ( X 2 u ), F 1 v ( X 2 v )}. Let ? ( x, y )= I [( x < y ) ? I [( x > y )], where indicator I [ E ] is defined by I [ E ]=1 if event E is true, and I [ E ]=0 otherwise. Using similar method in Theorem 1 of [ 7 ], we can show that distributions of T i ? h i , T 1 a and T 2 a converge, as N increases, to a normal distribution with mean K ? ? N ? ( 2 J T ? J ) and variance 1, where J is a K -dimensional vector with all its elements equal to one (2) ? = N ( n 2 ? 1 ) n 1 n 2 A + N ( n 1 ? 1 ) n 1 n 2 B + N 4 n 1 n 2 C Here A, B , and C are K × K covariance matrices with ( u,v ) elements given by a uv, b uv , and c uv =cov{ ? ( X 1 u , X 2 u ), ? ( X 1 v , X 2 v )}, respectively. A proof of ( 2 ) is available from the authors. Another asymptotically equivalent test that avoids the computation of h 1 or h 2 is to use the following test statistic: (3) Z = N n 1 n 2 J T ? ^ J { 1 n 1 R ? 1 ? 1 n 2 R ? 1 ? ( n 2 ? n 1 ) ( N + 1 ) 2 n 1 n 2 } where ? ^ is an unbiased estimate of ?. Computation of matrix ? ^ is discussed in Remark 4. Statistic Z has the same asymptotic distribution as T i ? h i , T 1 a , and T 2 a . One advantage of using Z is that it does not need to check whether two groups have the same variance. To facilitate implementation, Splus code to compute Z , ? ^ , h ^ 1 , and h ^ 2 is provided in Appendix C . Sample size generally depends on A, B , and C evaluated at ? ? = ? v = 1 K ? v 0 ? K = 0 and ? ? = ? ? a = ? v = 1 K ? v a ? K . We consider alternatives where ? a =( ? 1 a , …, ? Ka ) does not differ too much from ? 0=( ? 10, …, ? K 0). In this case, it will often be appropriate to assume that A, B , and C are held constant for the derivation of sample size. We thus make this assumption throughout this paper. This method of dealing with covariances was first suggested by Noether [ 11 ] and is commonly employed in nonparametric applications. For moderate-to-large sample size N , ? in ( 2 ) can be approximated by ((1+ r 0)/ r 0)( r 0 A + B ). When A and B are known, the required total sample size N to control type I error rate, ? , at the null hypothesis of ( 1 ) and power, (1? ? ), at a given alternative GTE ? ? a = ? v = 1 K ? v a ? K can be approximated by (4) N = 4 ( 1 + r 0 ) K 2 ? ? a 2 r 0 ( z ? + z ? ) 2 J T ( r 0 A + B ) J where z ? and z ? are the (1? ? )th and (1? ? )th percentiles, respectively, of the standard normal distribution. When A and B are unknown and no pilot data are available to estimate them, one can use an upper bound of J T( r 0 A + B ) J . If we can find a relatively small upper bound ? 2 for the diagonal elements of A and B , the off-diagonal elements of A and B will be upper bounded by ?? 2 for some 0< ? ?1. When no such ? 2 value is available, one can use ? 2 = ( 1 ? min ( 1 ? v ? K ) ? v a 2 ) ? 4 (a proof is given in Appendix A ). On the basis of Taylor’s expansion, one can approximate ? by an upper bound of {cor( X iu, X iv ), i =1,2; u ? v ; u,v =1, …, K } found in the literature, such as papers that report similar measures. Simulation in Section 9 shows that this approximation results in a slightly conservative estimate of sample size. In cases when no such of information on ? is available, one can always use the most conservative upper bound ? =1. Since lim N ?? J T? J /[( N 2/ n 1 n 2) ? 2 K {( K ?1)] ? +1}]?1, we can use a more conservative estimate of the total sample size: (5) N = 4 { ? ? ? a } 2 { ? + 1 K ( 1 ? ? ) } ( 1 + r 0 ) 2 r 0 ( Z ? + Z ? ) 2 The quantity ( ? ? a ? ? ) ? 2 { ? + ( 1 ? ? ) ? K } is an analogue the ‘effect size’ in parametric models. To see this, let D v = F 1 v ( X 2 v )? F 2 v ( X 1 v ) and D = ? v = 1 K D v ? K . Then, D v is a random measure of treatment difference in the v th outcome. Under the alternative ? v = ? va ( v =1, …, K ), we have E ( D v )= ? va (a difference between two areas under the curve), E ( D ) = ? ? a , and var( D )?2 ? 2{ ? +(1? ? )/ K }. Quantity ( ? ? a ? ? ) ? 2 { ? + ( 1 ? ? ) ? K } is a lower bound of E ( D ) ? var ( D ) and thus a measure of treatment difference we can detect with the given sample size. Since limited information of A and B is available in this case, the total sample size N in ( 5 ) depends on r 0 through (1+ r 0)2/ r 0. The optimal randomization ratio to achieve the smallest total sample size N is r 0=1.  4. SAMPLE SIZE ESTIMATE WHEN SOME HISTORICAL DATA ARE AVAILABLE Let { ( x i j 1 ( o ) , … , x i j K ( o ) ) : j = 1 , … , m i } be random observations from the i th group in a pilot study, i =1,2. Define F i u ( o ) ( t ) = P ( X i u ( o ) [ t d b ] t ) + 1 2 P ( X i u ( o ) = t ) ; R i ( x 3 ? 1 , j v ( o ) ) is the rank of x 3 ? i , j v ( o ) among { x 3 ? i , j v ( o ) , x i 1 v ( o ) , … , x i m i v ( o ) } ; R ? i ( x 3 ? i , v ( o ) ) = ( 1 ? m 3 ? i ) ? j = 1 m 3 ? i R i ( x 3 ? i , j v ( o ) ) ; ? ? v ( o ) = ( 1 ? m 1 m 2 ) ? i = 1 m 1 ? j = 1 m 2 ? ( x 1 i u ( o ) , x 2 j u ( o ) ) ; S 3 ? i , u v = ( 1 ? m 3 ? i ) ? j = 1 m 3 ? i { R i ( x 3 ? i , j u ( o ) ) ? R ? i ( x 3 ? i , u ( o ) ) } { R i ( x 3 ? i , j v ( o ) ) ? R ? i ( x 3 ? i , v ( o ) ) } S 3 u v = ( 1 ? m 1 m 2 ) ? i = 1 m 1 { ? ( x 1 i u ( o ) , x 2 i u ( o ) ) ? ? ? u ( o ) } { ? ( x 1 i v ( o ) , x 2 j v ( o ) ? ? ? v ( o ) ) } ; d 1 = m 1 m 2 r 0 ( m 1 ? 1 ) ( m 2 ? 1 ) ; d 2 = ( z ? + z ? ) 2 ? ( K 2 ? ? a 2 ) ; S 1, S 2, and S 3 are K × K matrices with ( u,v ) elements s 1 uv , s 2 uv , and s 3 uv , respectively. If the pilot data are used to determine the alternative ? a =( ? 1 a , …, ? Ka ) values, it will be reasonable to assume that correlations between the pilot data and the future data at ? a are associated. The following theorem gives an unbiased estimate of ? when ? = ? a using the pilot data. Theorem 1 Let ( X i 1 ( o ) , … , X i k ( o ) ) and ( X i 1, …, X iK ) represent random vectors of the i th group in a pilot study and the future study, respectively. Observations { ( x i j 1 ( o ) , … , x i j K ( o ) ) : j = 1 , … , m i } are independent identically distributed realizations of ( X i 1 ( o ) , … , X i K ( o ) ) , i = 1 , 2 . Suppose that covariance matrices between the pilot data and the future data when ? = ? a =( ? 1 a , …, ? Ka ) are associated through the following: (6) cov { F i u ( o ) ( X j u ( o ) ) , F i v ( o ) ( X j v ( o ) ) } = cov [ { F i u ( X j v ) , F i v ( X j v ) } ? ? a ] , i ? j , i , j = 1 , 2 cov { ? ( X 1 u ( o ) , X 2 u ( o ) ) , ? ( X 1 v ( o ) , X 2 v ( o ) ) } = cov [ { ? ( X 1 u , X 2 u ) , ? ( X 1 v , X 2 v ) } ? ? a ] Let ? 1 = ( 4 m 1 + 4 m 1 2 r 0 ) S 1 + ( 4 m 2 2 + 4 m 2 r 0 ) S 2 ? ( m 1 m 2 2 + m 1 2 m 2 r 0 ) S 3 and ? 2 = 4 m 1 2 S 1 + 4 m 2 2 S 2 ? m 1 2 m 2 2 S 3 . Then an unbiased estimate of ? under ? = ? a is given by (7) ? ^ = 1 + r 0 4 d 1 ( ? 1 ? ? 2 1 n 1 ) A proof of this theorem is given in Appendix B . Requirement ( 6 ) applies to many situations. For example, it applies to the commonly used assumption that future data relate to pilot data through a location-scale transformation, that is, when there exist two (possibly unknown) constants ? 1 and ? 2 such that { ? 1 ( X i u ( o ) ? ? 2 ) , ? 1 ( X i v ( o ) ? ? 2 ) , ? 1 ( X i k ( o ) ? ? 2 ) } has the same distribution as { X iu, X iv, X ik }. Furthermore, it applies to all cases when there exists some (possibly unknown) monotonic increasing function g such that { g ( X i u ( o ) ) , g ( X i v ( o ) ) , g ( X i k ( o ) ) } has the same distribution as { X iu, X iv, X ik } ( i =1,2; u,v,k =1, …, K ). The function g can be introduced by the improvement of medical care techniques (that could result in a reduction in variation) or the change in clinical practice over time (that could result in a shift in outcome means). Define E ~ = 1 + r 0 d 1 { m 1 ( 1 + m 1 r 0 ? m 1 n 1 ) S 1 + m 2 ( m 2 + r 0 ? m 2 n 1 ) s 2 + m 1 2 m 2 2 4 n 1 S 3 } Then ? ~ = ? ^ + ( ( 1 + r 0 ) ? 4 d 1 ) ( m 1 m 2 2 + m 1 2 m 2 r 0 ) S 3 . When m 1 and m 2 increase such that m 1/ m 2 goes to a positive constant, the difference ? ~ ? ? ^ is of order O (1/ m 1). Let ? i be the sum of all K 2 elements in ? i , i =1,2. Replacing ((1+ r 0)/ r 0)( A + r 0 B ) in ( 4 ) by ? ^ in ( 7 ) gives a total sample size estimation: (8) N = ( 1 + r 0 ) d 2 ? 1 2 d 1 { 1 + 1 ? 4 d 1 ? 2 d 2 ? 1 2 } If, instead, when ? in ( 4 ) is replaced by ? ~ , we obtain a more conservative estimate of the sample size: (9) N = ( 1 + r 0 ) d 2 d 3 2 d 1 . { 1 + 1 ? 4 d 1 ? 2 d 2 d 3 2 } where d 3= ? 1+ m 1 m 2( m 2+ m 1 r 0) J T S 3 J > ? 1. Remark 1 Let M = m 1+ m 2. Formulas ( 8 ) and ( 9 ) are derived under the assumption that M/N = o ( 1 ) or N is at least the same magnitude as M , which is reasonable in real applications since data from a smaller pilot study are often used for the design of a future larger clinical trial. On the other hand, if M is much larger than N , conducting a new clinical trial for the sample patient population will not be considered necessary. We can also express ? ^ in Theorem 1 as ? ^ = ( 1 + r 0 ) { m 1 ( n 2 ? 1 ) + n 1 ( m 1 ? 1 ) ( m 2 ? 1 ) m 2 n 2 S 1 + m 2 ( n 1 ? 1 ) + n 2 ( m 1 ? 1 ) m 1 ( m 2 ? 1 ) n 2 S 2 + m 1 ( m 2 ? n 2 ) ? m 2 n 1 4 ( m 1 ? 1 ) ( m 2 ? 1 ) n 2 S 3 } Large M ensures matrix ? ^ to be positive definite since S 1 and S 2 are of order O ( M 2) but S 3= O ( 1 ). However, when M is small (such as M <20), ? ^ may not be positive definite. In this case, one can either set S 3=0 in ? ^ to obtain a consistent (positive definite) estimate of ? using ( 1 + r 0 ) { m 1 ( n 2 ? 1 ) + n 1 ( m 1 ? 1 ) ( m 2 ? 1 ) m 2 n 2 S 1 + m 2 ( n 1 ? 1 ) + n 2 ( m 1 ? 1 ) m 1 ( m 2 ? 1 ) n 2 S 2 } or use ? ~ to estimate ? since ? ~ is always positive definite. Remark 2 In case when 1 ? 4 d 1 ? 2 ? ( d 2 ? 1 2 ) [ t d b ] 0 , one can approximate ((1+ r 0)/ r 0)( A + r 0 B ) in ( 4 ) by (1+ r 0)?1/(4 d 1 and use a more conservative sample size estimation N =(1+ r 0) d 2 ? 1/ d 1. Remark 3 The use of matrix notation in Theorem 1 makes it convenient to program in Splus, R, Matlab, or others. It is seen that S 3? i ( i =1,2) and S 3 are sample variance–covariance matrices of the column vectors in matrices ( R i ( x 3 ? i , 11 ( 0 ) ) ? R i ( x 3 ? i , 1 K ( 0 ) ) R i ( x 3 ? i , 21 ( 0 ) ) ? R i ( x 3 ? i , 2 K ( 0 ) ) ? ? ? R i ( x 3 ? i , m 3 ? i 1 ( 0 ) ) ? R i ( x 3 ? i , m 3 ? i K ( 0 ) ) ) and ( ? ( x 111 ( 0 ) , x 211 ( 0 ) ) ? ? ( x 11 K ( 0 ) , x 21 K ( 0 ) ) ? ? ? ? ( x 1 m 1 1 ( 0 ) , x 211 ( 0 ) ) ? ? ( x 1 m 1 K ( 0 ) , x 21 K ( 0 ) ) ? ? ? ? ( x 111 ( 0 ) , x 2 m 2 1 ( 0 ) ) ? ? ( x 11 K ( 0 ) , x 2 m 2 K ( 0 ) ) ? ? ? ? ( x 1 m 1 1 ( 0 ) , x 2 m 2 1 ( 0 ) ) ? ? ( x 1 m 1 K ( 0 ) , x 2 m 2 K ( 0 ) ) ) respectively. Note that the denominators in these covariances are m 3? i and m 1 m 2, respectively, not the ( m 1?1) and ( m 1 m 2?1) as the default sample covariances given by most software. We can improve the sample size estimate by bootstrapping using the pilot data. First, take bootstrap samples with sample sizes m 1 and m 2 for the two groups, respectively. Second, obtain bootstrap estimates of J T S 1 J , J T S 2 J , and J T S 3 J . Finally, substitute these bootstrap estimates into ( 8 ) or ( 9 ) to compute N . To search for the optimal randomization ratio r 0= n 2/ n 1, one can plot N versus r 0 and find the value of r 0 that corresponds to the smallest N value. Our simulation shows that the optimal r 0 can slightly deviate from the balanced design ( r 0=1) in either direction, but the loss of efficiency of a balanced design compared with the optimal one is minor—often within 1.5 per cent. Remark 4 An immediate application of Theorem 1 is to obtain an unbiased estimate of ? for the computation of test statistic Z in ( 3 ) after all data have been collected. Replacing m 1 and m 2 in ( 7 ) by n 1 and n 2, respectively, and computing S 1, S 2, and S 3 using current data instead of the pilot data, expression ( 7 ) is simplified to ? ^ = N ( n 1 ? 1 ) ( n 2 ? 1 ) ( 1 n 2 S 1 + 1 n 1 S 2 ? 1 4 S 3 ) This ? ^ can be used to compute test statistic Z in ( 3 ).  Theorem 1 Let ( X i 1 ( o ) , … , X i k ( o ) ) and ( X i 1, …, X iK ) represent random vectors of the i th group in a pilot study and the future study, respectively. Observations { ( x i j 1 ( o ) , … , x i j K ( o ) ) : j = 1 , … , m i } are independent identically distributed realizations of ( X i 1 ( o ) , … , X i K ( o ) ) , i = 1 , 2 . Suppose that covariance matrices between the pilot data and the future data when ? = ? a =( ? 1 a , …, ? Ka ) are associated through the following: (6) cov { F i u ( o ) ( X j u ( o ) ) , F i v ( o ) ( X j v ( o ) ) } = cov [ { F i u ( X j v ) , F i v ( X j v ) } ? ? a ] , i ? j , i , j = 1 , 2 cov { ? ( X 1 u ( o ) , X 2 u ( o ) ) , ? ( X 1 v ( o ) , X 2 v ( o ) ) } = cov [ { ? ( X 1 u , X 2 u ) , ? ( X 1 v , X 2 v ) } ? ? a ] Let ? 1 = ( 4 m 1 + 4 m 1 2 r 0 ) S 1 + ( 4 m 2 2 + 4 m 2 r 0 ) S 2 ? ( m 1 m 2 2 + m 1 2 m 2 r 0 ) S 3 and ? 2 = 4 m 1 2 S 1 + 4 m 2 2 S 2 ? m 1 2 m 2 2 S 3 . Then an unbiased estimate of ? under ? = ? a is given by (7) ? ^ = 1 + r 0 4 d 1 ( ? 1 ? ? 2 1 n 1 ) A proof of this theorem is given in Appendix B . Requirement ( 6 ) applies to many situations. For example, it applies to the commonly used assumption that future data relate to pilot data through a location-scale transformation, that is, when there exist two (possibly unknown) constants ? 1 and ? 2 such that { ? 1 ( X i u ( o ) ? ? 2 ) , ? 1 ( X i v ( o ) ? ? 2 ) , ? 1 ( X i k ( o ) ? ? 2 ) } has the same distribution as { X iu, X iv, X ik }. Furthermore, it applies to all cases when there exists some (possibly unknown) monotonic increasing function g such that { g ( X i u ( o ) ) , g ( X i v ( o ) ) , g ( X i k ( o ) ) } has the same distribution as { X iu, X iv, X ik } ( i =1,2; u,v,k =1, …, K ). The function g can be introduced by the improvement of medical care techniques (that could result in a reduction in variation) or the change in clinical practice over time (that could result in a shift in outcome means). Define E ~ = 1 + r 0 d 1 { m 1 ( 1 + m 1 r 0 ? m 1 n 1 ) S 1 + m 2 ( m 2 + r 0 ? m 2 n 1 ) s 2 + m 1 2 m 2 2 4 n 1 S 3 } Then ? ~ = ? ^ + ( ( 1 + r 0 ) ? 4 d 1 ) ( m 1 m 2 2 + m 1 2 m 2 r 0 ) S 3 . When m 1 and m 2 increase such that m 1/ m 2 goes to a positive constant, the difference ? ~ ? ? ^ is of order O (1/ m 1). Let ? i be the sum of all K 2 elements in ? i , i =1,2. Replacing ((1+ r 0)/ r 0)( A + r 0 B ) in ( 4 ) by ? ^ in ( 7 ) gives a total sample size estimation: (8) N = ( 1 + r 0 ) d 2 ? 1 2 d 1 { 1 + 1 ? 4 d 1 ? 2 d 2 ? 1 2 } If, instead, when ? in ( 4 ) is replaced by ? ~ , we obtain a more conservative estimate of the sample size: (9) N = ( 1 + r 0 ) d 2 d 3 2 d 1 . { 1 + 1 ? 4 d 1 ? 2 d 2 d 3 2 } where d 3= ? 1+ m 1 m 2( m 2+ m 1 r 0) J T S 3 J > ? 1.  Remark 1 Let M = m 1+ m 2. Formulas ( 8 ) and ( 9 ) are derived under the assumption that M/N = o ( 1 ) or N is at least the same magnitude as M , which is reasonable in real applications since data from a smaller pilot study are often used for the design of a future larger clinical trial. On the other hand, if M is much larger than N , conducting a new clinical trial for the sample patient population will not be considered necessary. We can also express ? ^ in Theorem 1 as ? ^ = ( 1 + r 0 ) { m 1 ( n 2 ? 1 ) + n 1 ( m 1 ? 1 ) ( m 2 ? 1 ) m 2 n 2 S 1 + m 2 ( n 1 ? 1 ) + n 2 ( m 1 ? 1 ) m 1 ( m 2 ? 1 ) n 2 S 2 + m 1 ( m 2 ? n 2 ) ? m 2 n 1 4 ( m 1 ? 1 ) ( m 2 ? 1 ) n 2 S 3 } Large M ensures matrix ? ^ to be positive definite since S 1 and S 2 are of order O ( M 2) but S 3= O ( 1 ). However, when M is small (such as M <20), ? ^ may not be positive definite. In this case, one can either set S 3=0 in ? ^ to obtain a consistent (positive definite) estimate of ? using ( 1 + r 0 ) { m 1 ( n 2 ? 1 ) + n 1 ( m 1 ? 1 ) ( m 2 ? 1 ) m 2 n 2 S 1 + m 2 ( n 1 ? 1 ) + n 2 ( m 1 ? 1 ) m 1 ( m 2 ? 1 ) n 2 S 2 } or use ? ~ to estimate ? since ? ~ is always positive definite.  Remark 2 In case when 1 ? 4 d 1 ? 2 ? ( d 2 ? 1 2 ) [ t d b ] 0 , one can approximate ((1+ r 0)/ r 0)( A + r 0 B ) in ( 4 ) by (1+ r 0)?1/(4 d 1 and use a more conservative sample size estimation N =(1+ r 0) d 2 ? 1/ d 1.  Remark 3 The use of matrix notation in Theorem 1 makes it convenient to program in Splus, R, Matlab, or others. It is seen that S 3? i ( i =1,2) and S 3 are sample variance–covariance matrices of the column vectors in matrices ( R i ( x 3 ? i , 11 ( 0 ) ) ? R i ( x 3 ? i , 1 K ( 0 ) ) R i ( x 3 ? i , 21 ( 0 ) ) ? R i ( x 3 ? i , 2 K ( 0 ) ) ? ? ? R i ( x 3 ? i , m 3 ? i 1 ( 0 ) ) ? R i ( x 3 ? i , m 3 ? i K ( 0 ) ) ) and ( ? ( x 111 ( 0 ) , x 211 ( 0 ) ) ? ? ( x 11 K ( 0 ) , x 21 K ( 0 ) ) ? ? ? ? ( x 1 m 1 1 ( 0 ) , x 211 ( 0 ) ) ? ? ( x 1 m 1 K ( 0 ) , x 21 K ( 0 ) ) ? ? ? ? ( x 111 ( 0 ) , x 2 m 2 1 ( 0 ) ) ? ? ( x 11 K ( 0 ) , x 2 m 2 K ( 0 ) ) ? ? ? ? ( x 1 m 1 1 ( 0 ) , x 2 m 2 1 ( 0 ) ) ? ? ( x 1 m 1 K ( 0 ) , x 2 m 2 K ( 0 ) ) ) respectively. Note that the denominators in these covariances are m 3? i and m 1 m 2, respectively, not the ( m 1?1) and ( m 1 m 2?1) as the default sample covariances given by most software. We can improve the sample size estimate by bootstrapping using the pilot data. First, take bootstrap samples with sample sizes m 1 and m 2 for the two groups, respectively. Second, obtain bootstrap estimates of J T S 1 J , J T S 2 J , and J T S 3 J . Finally, substitute these bootstrap estimates into ( 8 ) or ( 9 ) to compute N . To search for the optimal randomization ratio r 0= n 2/ n 1, one can plot N versus r 0 and find the value of r 0 that corresponds to the smallest N value. Our simulation shows that the optimal r 0 can slightly deviate from the balanced design ( r 0=1) in either direction, but the loss of efficiency of a balanced design compared with the optimal one is minor—often within 1.5 per cent.  Remark 4 An immediate application of Theorem 1 is to obtain an unbiased estimate of ? for the computation of test statistic Z in ( 3 ) after all data have been collected. Replacing m 1 and m 2 in ( 7 ) by n 1 and n 2, respectively, and computing S 1, S 2, and S 3 using current data instead of the pilot data, expression ( 7 ) is simplified to ? ^ = N ( n 1 ? 1 ) ( n 2 ? 1 ) ( 1 n 2 S 1 + 1 n 1 S 2 ? 1 4 S 3 ) This ? ^ can be used to compute test statistic Z in ( 3 ).  5. UNIVARIATE CASES: <italic>K</italic>=1 When F 1 and F 2 are absolutely continuous and are identical under the null hypothesis, substituting ? 2 = 1 12 and K =1 into ( 5 ), we obtain exactly the same sample size formula as Noether’s [ 11 ] formula: N = ( z ? + z ? ) 2 ( 1 + r 0 ) 2 ? ( 3 r 0 ? ? a 2 ) . Simulations of Sundukchi and Guenther [ 13 ] also showed that the accuracy of the asymptotic approximation to the distribution of the Wilcoxon–Mann–Whitney test statistic was surprisingly good for data from various distributions. For univariate ordered categorical data, Whitehead [ 9 ] assumed proportional odds among the ordered categories. His sample size computation requires the proportions in all categories to be known in advance for both groups under both the null hypothesis and the alternative. He further showed that, if the proportional odds assumption is violated (e.g. due to the measurement errors in the data), the sample size could increase considerably. We note that under the proportional odds assumption P ( X 1? i )=exp( ? i )/{1+exp( ? i )} and P ( X 2? i )=exp( ? i ? ? R )/{1+exp( ? i ? ? R ) condition ? R >0 implies P ( X 1< X 2)? P ( X 1> X 2)>0. Thus, our sample size computation formula can also be applied to cases when the proportional odds assumption is made.  6. MULTIVARIATE CASE: IDENTICAL DISTRIBUTION UNDER THE NULL HYPOTHESIS Let F i ( t 1, …, t K ) be the joint distribution of X i 1, …, X iK . A special case of H 0 in ( 1 ) is to assume identical distribution between the two groups H 0: F 1? F 2 and assume that the variance–covariance matrix ? is the same under both H 0 and the local alternative ? ? a . These assumptions have been made in many traditional nonparametric hypothesis tests, for example, in [ 14 - 16 ]. For this special case, we provide a smaller upper bound ? 2 for ( 5 ) when no prior data are available. When some prior data are available, we will provide a sample size expression that uses an estimate of ?. When no preliminary data are available, we use the fact that var [ F i u ( X i u ) ] ? 1 12 under the null hypothesis F 1? F 2 [ 17 ]. This gives a tighter upper bound ? 2 in ( 5 ): ? 2 = min { 1 ? 12 , ( 1 ? min ( 1 ? v ? K ) ? v a 2 ) ? 4 } . When some preliminary data are available, we can obtain a better estimate of ? under these more restricted assumption. We continue to use notations in Section 3 and assume that ( 6 ) holds. To simplify our notation, we further define M = m 1+ m 2, y i v ( 0 ) = { x 1 i v ( 0 ) if i = 1 , … , m 1 x 2 , ( i ? m 1 ) ? ( 0 ) if i = m 1 + 1 , … , M } R iv = rank of y i v ( o ) among { y 1 v ( o ) , … , y M v ( o ) } and R ? v = ( 1 ? M ) ? i = 1 M R i v , s 1 u v = ( 1 ? M ) ? i = 1 M ( R i u ? R ? u ) ( R i v ? R ? v ) . Then, an unbiased estimate of ? under the alternative ? = ? a is given by (10) ? ^ = 1 + r 0 4 m 1 m 2 ( m 1 + m 2 ? 1 ) ( m 1 + m 2 ? 2 ) ( ? 1 ? ? 2 1 n 1 ) Here, ?1 and ?2 are defined by ?1=4( m 1 m 2?1)(1+ r 0) S 1?(1+ r 0) m 1 m 2( m 1+ m 2?1) S 3 and ?2=4(2 m 1 m 2? m 1? m 2) S 1? m 1 m 2( m 1+ m 2)( m 1+ m 2?1) S 3. We continue to use ? i to denote the sum of all K 2 elements in ? i , i =1,2. Replacing ? in ( 4 ) by ? ^ in ( 10 ), solve for N : N = ( 1 + r 0 ) d 2 ? 1 2 d 1 ? { 1 + 1 ? 4 d 1 ? ? 2 d 2 ? 1 2 } which has exactly the same form as ( 8 ) but with d 1 replaced by d 1 ? = m 1 m 2 r 0 ( m 1 + m 2 ? 1 ) ( m 1 + m 2 ? 2 ) . A conservative estimate is to replace ? 1 by d 3= ? 1+(1+ r 0) m 1 m 2( m 1+ m 2?1) J T S 3 J .  7. COMPARISON WITH BONFERRONI ADJUSTMENT Bonferroni adjustment is a simple method to control the overall type I error when multiple tests are performed for testing the hypothesis H 0: ? 1=*#x22EF;= ? K =0 and controlling power at the alternative H 1: at least one ? v = ? va >0 ( v =1, …, K ). Since conclusions from Bonferroni adjustment depend on the smallest observed p -value, sample size using Bonferroni adjustment can be approximated by N B = min ( 1 ? v ? K ) 4 ( ? v 2 ? ? v a 2 ) { ( 1 + r 0 ) 2 ? r 0 } ( Z ? ? K + z ? ) 2 . Substituting ? v 2 = ( 1 ? ? v a 2 ) ? 4 into N B and ? 2 = ( 1 ? min ( 1 ? v ? K ) ? v a 2 ) ? 4 into N in ( 5 ), one obtains N N B = ( 1 ? min ( 1 ? v ? K ) ? v a 2 ) ( Z ? + Z ? ) 2 { ? + ( 1 ? ? ) ? K } min ( 1 ? v ? K ) ( 1 ? ? v a 2 ) ( ? ? ? ? v a ) 2 ( Z ? ? K + Z ? ) 2 When values of ? 1 a 2 , … , ? K a 2 are close to each other, N/N B?( z ? + z ? )2{ ? (1? ? )/ K /( z ?/K + z ? )2?( z ? + z ? )2/( z ?/K + z ? )2. For fixed ? and ? , it decreases to zero quickly as K increases. Thus, if a treatment shows similar magnitude of benefit across different outcomes, Bonferroni adjustment becomes more conservative as the number of outcomes K increases. On the other hand, when values of ? 1 a 2 , … , ? K a 2 are quite different from each other, especially when one of them is approaching to one, N B is decreasing quickly (no matter what K value is), and N/N B can be much greater than one. This is intuitive since Bonferroni adjustment is designed to test whether a treatment shows any effect on at least one of the K outcomes while rank-sum-type test is designed to evaluate its average effect measured by GTE. It is worth noting that many extended Bonferroni procedures (e.g. [ 18 - 20 ]) are proposed to increase the test power when all ? v a 2 are close to each other, since they also compare p -values from univariate tests with values greater than ?/K . If the goal is to test whether a treatment has any effect on K outcomes, the use of Bonferroni adjustment or its extensions will be more efficient. However, when the goal is to test whether a treatment has benefit on most of the outcomes, the use of rank-sum test (or Z ) and ( 5 ) will be more efficient.  8. MULTIVARIATE CASES: MULTIPLE BINARY OUTCOMES Using GEE, Rochon [ 10 ] presented a sample size computation algorithm for a binary outcome measured longitudinally when the correlation between the measure at time ? t and the measure at time ? s has the form ? | ? t ? ? s | ? ( s ? t ). Since GEE models treatment means and correlations independently and ignores the restrictions on the correlation by the means, Rochon [ 10 ] acknowledged the difficulties in applying his approach for repeated binary data. In general, when the form of correlation structure among multiple binary outcomes is unknown, it is difficult to extend Rochon’s sample size procedure for the multiple binary outcome case. Under the special case when the correlation matrix among outcomes is a known function of some unknown parameters, Rochon’s procedure can be applied for sample size computation with multiple binary outcomes measured at a single time point. A typical feature of a binary outcome is that the outcome variance is a function of outcome mean (the proportion of success). If the parameter to be tested is a function of the outcome means, then both test statistic and the sample size will be driven by the magnitude of the means. This is not a desired property for many study designs. In this section, we show how sample size from Rochon’s procedure and our formulas ( 8 ) and ( 9 ) in Section 4 are affected by the outcome means. Denote ? iv = P ( X iv =1), ? i v 2 = ? i v ( 1 ? ? i v ) and ? =( ? 11, …, ? 1 K , ? 21, …, ? 2 K )T. Then ? v = ? 2 v ? ? 1 v . Consider the case when corr( X iu, X iv )= ? ( u ? v, i =1,2) is known. The design matrix X in [ 10 ] is a (2 K )×2 matrix of the form X T = [ 1 ? 1 0 ? 0 0 ? 0 1 ? 1 ] Using the logit link h ( ? )= X? where ? =( ? 1, ? 2)T, the model-based covariance matrix of ? ^ from GEE procedure is var ( ? ^ ) = 1 1 + 2 ( K ? 1 ) ? ? ( 2 K ? 1 ) ? 2 × [ ? ( ? j = 1 K ? 1 j ) 2 + { 1 + ( 2 K ? 3 ) ? } ? j = 1 K ? 1 j 2 0 0 ? ( ? j = 1 K ? 2 j ) 2 + { 1 + ( 2 K ? 3 ) ? } ? j = 1 K ? 2 j 2 ] Testing ? ? = 0 is equivalent to testing ? 1??2=0. Now are have {1+2( K ?1) ? ?(2 K ?1) ? 2} var ( ? ^ 1 ? ? ^ 2 ) = ? [ ( ? j = 1 K ? 1 j ) 2 + ( ? j = 1 K ? 2 j ) 2 ] + { 1 + ( 2 K ? 3 ) ? } ? j = 1 K ( ? 1 j 2 + ? 2 j 2 ) . It is seen that if all outcomes form two clusters, one with success probabilities very close to 0.5, the other with success probabilities close to 0 or 1, then, no matter whether ? v = ? 2 v ? ? 1 v remains the same across the K outcomes, the variance of ? ^ 1 ? ? ^ 2 , and thus the sample size or the test statistic, will mainly be determined by the variances from the outcomes in the first cluster. In other words, both test statistic and sample size computation will be driven by the outcomes whose success rates are close to 0.5. In sample size computation, whether outcomes form two such clusters may be discovered by looking at whether prespecified values ? 1 a , …, ? Ka form two such clusters. The power of the rank-sum-type test and the sample size formulas ( 8 ) and ( 9 ) when some pilot data are available also have the same feature. However, because of the presence of matrix C in ( 2 ), ( 8 ) and ( 9 ) could be less seriously affected than the GEE approach. To see this, consider the simple case when all binary outcomes are independent. Let x ? i u ( o ) = ( 1 ? m i ) ? j = 1 m i x i j u ( o ) ? m i . Then s 1 u u = m 2 2 x ? 1 u ( o ) ( 1 ? x ? 1 u ( o ) ) ? 4 , s 2 u u = m 1 2 x ? 2 u ( o ) ( 1 ? x ? 2 u ( o ) ) ? 4 and s 3 u u = ( 1 + x ? 2 u ( o ) ? x ? 1 u ( o ) ) 2 x ? 1 u ( o ) ( 1 ? x ? 2 u ( o ) ) + ( 1 ? x ? 2 u ( o ) + x ? 1 u ( o ) ) 2 ( 1 ? x ? 1 u ( o ) ) x ? 2 u ( o ) . Sample size, N , in ( 8 ) or ( 9 ) depends on data through J T S 1 J = ? u = 1 K s 1 u u = ? u = 1 K ( m 2 2 ? 4 ) x ? 1 u ( o ) ( 1 ? x ? 1 u ( o ) ) , J T S 2 J = ? u = 1 K s 2 u u = ( m 1 2 ? 4 ) x ? 2 u ( o ) ( 1 ? x ? 2 u ( o ) ) and J T S 3 J = ? u = 1 K s 3 u u . Thus, values of both J T S 1 J and J T S 2 J will be driven by outcomes in the first cluster. This situation is encountered because, with binary outcomes, the variance is a function of the mean. This may be viewed as an undesirable feature of both our approach and Rochon’s approach.  9. SIMULATION To evaluate the performance of sample size formulas, we simulated data from distributions with different shapes. Let x i j u = w u y i j 0 + 1 ? w u 2 y i j u , i =1,2; j =1, …, n i; u =1, …, K . The y variables are generated independently from normal, exponential, and beta distributions, respectively. We consider K =2,5,10, ? =0.05, and ? =0.10, 0.20. Different correlation structures are considered: w 1=?= w K =0.5 for equal correlation and w 1=?= w K ?1=0.5 or 0.8, w K =0 for unequal correlation. For beta distribution, data are further discretized into five ordered values depending on which of the five intervals they are belonging: [0,0.2], (0.2,0.4], (0.4,0.6], (0.6,0.8], and (0.8,0.1]. We fix r 0=1. For normal distribution, data from both groups are generated from the standard normal distribution under null hypothesis H 0, and 0.5 is added to data in group 2 under the alternative hypothesis H 1. For exponential distribution, data from both groups are generated from the standard exponential distribution with density f ( x )=e? x under H 0, and data from group 2 are generated from the distribution with density f ( x )=2e?2 x /3/3 under H 1. For beta distribution, data from both groups are generated from Beta(0.5, 1) distribution under H 0, and data from group 2 are generated from Beta(0.7, 1) under H 1. Sample size n 1= N /(1+ r 0)= N /2 in Table II is computed using ( 5 ) with ? =0.5 or 0.8, ? 2 = 1 12 and ? ? a being computed using methods in Section 2. Using these sample sizes, 5000 simulations were performed to evaluate the type I error and statistical power at ? ? a of rank-sum-type test and the test based on Z in ( 3 ). Since data from both groups are generated from the same distribution under H 0, we have h 1= h 2=1 [ 7 ]; thus, both rank-sum-type test and its modified test are identical. Table II shows that sample size computed from ( 5 ), with ? replaced by the maximum correlation among X i 1, …, X iK , gives good control of type I error and statistical power under various distribution settings. In all cases, sample size computed from formula ( 5 ) is slightly conservative. For unequal correlation case, the K th outcome is simulated independent of the other K ?1 outcomes. It is not surprising to see that the resulting statistical power is higher than the corresponding equal correlation case, since we still substitute ? by the same maximum correlation among X i 1, …, X iK in sample size computation. This is reasonable because adding independent outcome with the same magnitude of treatment effect as other outcomes will always increase the statistical power.  10. APPLICATION IN PD TRIAL DESIGN The neuroprotection exploratory trials in Parkinson’s disease (NET-PD) are a series of PD clinical trials sponsored by NIH/NINDS to identify the most promising neuroprotective compounds for individuals with PD [ 21 ]. A phase III trial in NET-PD was designed to compare creatine with placebo in the following five primary outcomes: the changes from baseline visit to the end of 5-year follow-up in the measures of modified Rankin, symbol digit modalities (verbal), Schwab and England ADL scale (SEADL), PDQ-39, and ambulatory capacity. The study sets power at 85 per cent when the creatine group would achieve an overall mean reduction computed from the mean reductions over placebo of 3, 0.2, 2, 0.33, and 1.5, respectively, among these five primary outcomes. Based on the literature and discussions among trial investigators, the common standard deviations for these five outcomes were set at 9, 1, 11, 2.11, and 8.0, respectively. Using normal approximation formula in Section 2, we computed the alternative ( ? 1 a , …, ? 5 a )=(0.1863, 0.1125, 0.1023, 0.0881, and 0.1055). This gives ? ? a = 0.1189 . Bonferroni adjustment to the five one-sided tests required a sample size of 925 patients per group. Since no pilot data were available to estimate covariance matrices A and B in ( 4 ) in 5-year outcome changes, formula ( 5 ) was used to estimate sample size. It was assumed that, under the null hypothesis, creatine group and placebo group would have the same distribution. The upper bound ? 2 = 1 4 was substituted into ( 5 ). The trial uses randomization ratio r0=1. The following table gives a range of sample size per group, using formula ( 5 ), when ? ranges from 0.1 to 1.0 and ( ?,? )=(0.05,0.15): ? 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Sample size per group 238 305 373 441 509 576 644 712 780 847 In a pilot 2-year phase II study, a 1-year change of modified Rankin, SEADL, PDQ-39, and ambulatory capacity was measured. The absolute values of correlation coefficients among these four outcomes ranged from 0.002 to 0.35. If it was assumed that correlations among all five outcomes in their 5-year changes were not greater than 0.5, we could choose a sample size of 509 patients per treatment group.  11. DISCUSSION The clinical trials’ literature is replete with discussions of sample size determination. While there are publications describing the computations for multivariate settings, appropriately the vast body of literature is focused on the univariate case in which a single outcome variable has been identified for the primary efficacy assessment. Lachin [ 1 ] has catalogued a number of useful expressions for clinical trial sample size calculations in this single variable situation. Little work has been done in sample size computation even for single ordered categorical outcome [ 22 ]. In PD and in many other diseases, it is difficult, if not impossible, to select a single measured variable that will capture the multi-dimensional features associated with disease improvement or deterioration. Multiple continuous and ordered categorical outcomes are often required to be analyzed jointly to determine whether a new treatment should be recommended. In these cases, the approach described in this paper may have merit. In addition, many clinical trials are designed on the premise that the two treatment groups have identical distributions of response variables under the null hypothesis. Again, the strategy used in this paper does not require such strict equality, but permits inequality of variance–covariance structures between the two treatment groups. When faced with several important variables for a trial, there are a number of approaches that might be followed to plan the sample size for the study. One approach is to select a single variable as primary and consider the others as important secondary variables. The sample size planning is then driven by the one identified primary variable, and once a sample size is calculated, it is used to calculate what power the study will have with that N for the secondary variables. Another approach is to identify two primary variables and then calculate sample size for each while being certain to incorporate the formal testing strategy. That is, will the trial require differences for both variables or for at least one of the two? A Bonferroni multiple test adjustment might be employed. We have seen that the Bonferroni sample size calculations will require greater numbers than the rank-sum-type test when treatment effects are close to each other across variables. A final benefit of this approach is its applicability to a variety of settings involving continuous or discrete random variables. This renders substantial flexibility for use in planning a trial with a complex constellation of outcomes. Admittedly, our approach is based on a parameterization that focuses on the GTE and tacitly assumes that it makes clinical sense to combine effects in the manner proposed through the GTE. If nothing else, this approach can be used to calculate sample size and then can be contrasted to the result from calculations performed using the more traditional approaches assuming normality, equality of variance, and other restrictions. There are limitations to the development outlined herein. First, like many sample size papers we have not focused on the many issues that can complicate the design of a trial. These include: issues of noncompliance, attrition, the registration of ineligible of patients, and similar pragmatic matters. Furthermore, the development focuses on the GTE and is essentially aggregating effects across variables. If the variables interact with treatment producing qualitative interactions, then the interpretation of this planning exercise will be unclear. This, however, is true for any similar multivariate analysis that summarizes an effect into a main effect averaged over the levels of an interacting factor. Hence, knowledge of the clinical application and understanding the variables are critical aspects to the use of these results. We believe the approach outlined here represents a new way of thinking about this problem, and it has the potential to be applied to a number of clinical trial settings, particularly for chronic diseases.  11. DISCUSSION The clinical trials’ literature is replete with discussions of sample size determination. While there are publications describing the computations for multivariate settings, appropriately the vast body of literature is focused on the univariate case in which a single outcome variable has been identified for the primary efficacy assessment. Lachin [ 1 ] has catalogued a number of useful expressions for clinical trial sample size calculations in this single variable situation. Little work has been done in sample size computation even for single ordered categorical outcome [ 22 ]. In PD and in many other diseases, it is difficult, if not impossible, to select a single measured variable that will capture the multi-dimensional features associated with disease improvement or deterioration. Multiple continuous and ordered categorical outcomes are often required to be analyzed jointly to determine whether a new treatment should be recommended. In these cases, the approach described in this paper may have merit. In addition, many clinical trials are designed on the premise that the two treatment groups have identical distributions of response variables under the null hypothesis. Again, the strategy used in this paper does not require such strict equality, but permits inequality of variance–covariance structures between the two treatment groups. When faced with several important variables for a trial, there are a number of approaches that might be followed to plan the sample size for the study. One approach is to select a single variable as primary and consider the others as important secondary variables. The sample size planning is then driven by the one identified primary variable, and once a sample size is calculated, it is used to calculate what power the study will have with that N for the secondary variables. Another approach is to identify two primary variables and then calculate sample size for each while being certain to incorporate the formal testing strategy. That is, will the trial require differences for both variables or for at least one of the two? A Bonferroni multiple test adjustment might be employed. We have seen that the Bonferroni sample size calculations will require greater numbers than the rank-sum-type test when treatment effects are close to each other across variables. A final benefit of this approach is its applicability to a variety of settings involving continuous or discrete random variables. This renders substantial flexibility for use in planning a trial with a complex constellation of outcomes. Admittedly, our approach is based on a parameterization that focuses on the GTE and tacitly assumes that it makes clinical sense to combine effects in the manner proposed through the GTE. If nothing else, this approach can be used to calculate sample size and then can be contrasted to the result from calculations performed using the more traditional approaches assuming normality, equality of variance, and other restrictions. There are limitations to the development outlined herein. First, like many sample size papers we have not focused on the many issues that can complicate the design of a trial. These include: issues of noncompliance, attrition, the registration of ineligible of patients, and similar pragmatic matters. Furthermore, the development focuses on the GTE and is essentially aggregating effects across variables. If the variables interact with treatment producing qualitative interactions, then the interpretation of this planning exercise will be unclear. This, however, is true for any similar multivariate analysis that summarizes an effect into a main effect averaged over the levels of an interacting factor. Hence, knowledge of the clinical application and understanding the variables are critical aspects to the use of these results. We believe the approach outlined here represents a new way of thinking about this problem, and it has the potential to be applied to a number of clinical trial settings, particularly for chronic diseases.  C.1. Computation of <italic>Z</italic>, <inline-formula><mml:math display="inline" id="M162" overflow="scroll"><mml:mover accent="true"><mml:mi>?</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>, <inline-formula><mml:math display="inline" id="M163" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math display="inline" id="M164" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> x<- GST.parameter(data, n1) Z<- sum(x$theta)*sqrt(N)/2/sum(x$Sigma) Sigma.hat<- x$Sigma h1.hat<- x$h1 h2.hat<- x$h2  C.1. Computation of <italic>Z</italic>, <inline-formula><mml:math display="inline" id="M162" overflow="scroll"><mml:mover accent="true"><mml:mi>?</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>, <inline-formula><mml:math display="inline" id="M163" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math display="inline" id="M164" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> x<- GST.parameter(data, n1) Z<- sum(x$theta)*sqrt(N)/2/sum(x$Sigma) Sigma.hat<- x$Sigma h1.hat<- x$h1 h2.hat<- x$h2  C.2. Computation of sample size N using formula (<xref ref-type="disp-formula" rid="FD13">8</xref>) Suppose that observations from a pilot study are saved in Splus ( m 1+ m 2)× k matrix pilot.data whose first m 1 rows are observations from group 1 and the rest m 2 rows are observations from group 2. z.alpha<- qnorm(1-alpha) z.beta<- qnorm(1-beta) x<- GST.parameter(pilot.data, m1) d1.m1m2<- r0*(m1?1)*(m2?1) #=d1/m1/m2 d2<- (z.alpha+z.beta)^2/k^2/theta.bar^2 # compute gamma1.m1m2=gamma1/m1/m2 and gamma2.m1m2=gamma2/m1/m2 gamma1.m1m2<- (4*m1 + 4*m1^2*r0)*sum(x$S1.n1n2) + (4*m2^2 + 4*m2*r0)*sum(x$S2.n1n2) ? (m1*m2^2 + m1^2*m2*r0)*sum(x$S3.n1n2) gamma2.m1m2<- 4*m1^2*sum(x$S1.n1n2) + 4*m2^2*sum(x$S2.n1n2) ? m1^2*m2^2*sum(x$S3.n1n2) # The required total sample size N is: N<- ceiling((1+r0)*d2*gamma1.m1m2/2/d1.m1m2*(1+ sqrt(1-4*d1.m1m2*gamma2.m1m2/d2/gamma1.m1m2^2)))  C.2. Computation of sample size N using formula (<xref ref-type="disp-formula" rid="FD13">8</xref>) Suppose that observations from a pilot study are saved in Splus ( m 1+ m 2)× k matrix pilot.data whose first m 1 rows are observations from group 1 and the rest m 2 rows are observations from group 2. z.alpha<- qnorm(1-alpha) z.beta<- qnorm(1-beta) x<- GST.parameter(pilot.data, m1) d1.m1m2<- r0*(m1?1)*(m2?1) #=d1/m1/m2 d2<- (z.alpha+z.beta)^2/k^2/theta.bar^2 # compute gamma1.m1m2=gamma1/m1/m2 and gamma2.m1m2=gamma2/m1/m2 gamma1.m1m2<- (4*m1 + 4*m1^2*r0)*sum(x$S1.n1n2) + (4*m2^2 + 4*m2*r0)*sum(x$S2.n1n2) ? (m1*m2^2 + m1^2*m2*r0)*sum(x$S3.n1n2) gamma2.m1m2<- 4*m1^2*sum(x$S1.n1n2) + 4*m2^2*sum(x$S2.n1n2) ? m1^2*m2^2*sum(x$S3.n1n2) # The required total sample size N is: N<- ceiling((1+r0)*d2*gamma1.m1m2/2/d1.m1m2*(1+ sqrt(1-4*d1.m1m2*gamma2.m1m2/d2/gamma1.m1m2^2))) 