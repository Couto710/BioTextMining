Convergence of biomarkers, bioinformatics and nanotechnology for individualized cancer treatment Recent advances in biomarker discovery, biocomputing, and nanotechnology have raised new opportunities for the emerging field of personalized medicine in which disease detection, diagnosis, and therapy are tailored to each individual’s molecular profile, and also for predictive medicine that uses genetic/molecular information to predict disease development, progression, and clinical outcome. Here we discuss advanced biocomputing tools for cancer biomarker discovery and multiplexed nanoparticle probes for cancer biomarker profiling, together with prospects and challenges in correlating biomolecular signatures with clinical outcome. This bio-nano-info convergence holds great promise for molecular diagnosis and individualized therapy of cancer and other human diseases.  Introduction The last two decades have witnessed an explosive growth in the amount of genomic and proteomic data, major advances in unraveling the molecular mechanisms of human diseases, and a rapid pace in developing new technologies for molecular diagnostics and therapy. This has ushered in a new era of molecular medicine in which disease detection, diagnosis and treatment are tailored to each individual’s molecular profile ( 1 - 4 ). This revolution is based on the availability and application of new biomarkers for predicting disease behavior, advanced technologies for rapid detection and diagnosis, new therapies for molecular and cellular targeting, as well as on computing technologies for data analysis and management. For molecular profiling and diagnostics, however, a major challenge is that human diseases are often characterized by histologic lesions that are heterogeneous at the cellular and molecular levels. In cancerous tumors, for example, malignant cells are typically intermixed with benign stroma, blood vessels, and inflammatory cells ( 5 - 8 ). Current technologies such as real-time polymerase chain reactions (RT-PCR) and gene microarrays are not designed to handle this type of heterogeneity, in part because they require destructive preparation of cells and tissue specimens into a homogeneous solution, leading to a loss of valuable information regarding the 3-D cellular environment and tissue morphology. The development of nanotechnology has provided new opportunities for integrating morphological and molecular information, and also for correlating observed molecular and cellular changes with disease behavior ( 9 - 11 ). In particular, bioconjugated quantum dots (QDs) ( 12 - 15 ) have been used to quantify multiple biomarkers in intact cancer cells and tissue specimens, allowing a comparative test of traditional histopathology versus molecular signatures for the same tissue ( 16 - 20 ). For molecular imaging and therapy, nanotechnology can be used to improve the efficacy and toxicity profiles of chemotherapeutic agents because these agents can be encapsulated, covalently attached, or adsorbed onto nanoparticles ( 21 - 23 ). At the present, a major task in biomedical nanotechnology is to understand how nanoparticles interact with blood, cells, and organs under in vivo physiological conditions, and how to overcome one of their inherent limitations, i.e. their delivery to diseased sites or organs ( 24 - 26 ). Another major challenge is to generate critical studies that can clearly link biomarkers with disease behaviors, such as the rate of tumor progression and different responses to surgery, radiation or drug therapy ( 27 ). Here we discuss how biomarkers and biocomputing can be integrated with nanotechnology for high-throughput analysis of gene expression data and for multiplexed molecular profiling of intact cells and tissue specimens (see Figure 1 ). In particular, we discuss web-based bioinformatics tools for biomarker discovery, optimization, and clinical validation. Biomarkers Biomolecular markers include altered or mutant genes, RNA, proteins, lipids, carbohydrates, small metabolite molecules, and altered expression states of such markers that can be correlated with a biological behavior or a clinical outcome ( 28 - 31 ). Most biomarkers have been discovered by molecular profiling studies, based on an association or correlation between a molecular signature and disease behavior. One of the first molecular profiling studies was reported by Golub et al . ( 32 ), who showed that gene expression patterns could classify tumors, thereby yielding new insights into tumor pathology such as its stage, grade, clinical course, and response to treatment. Gene expression studies further revealed that the molecular signatures of each tumor are a result of the combined tumoral, stromal, and inflammatory factors of the original heterogeneous lesion ( 33 ). The first clinical correlation of gene expression patterns with clinical outcome was reported for diffuse large B-cell lymphoma ( 34 ), a clinically heterogeneous disease. Whereas most of the patients succumbed to the disease, the remainder responded well to therapy and had prolonged survival. This variability in disease progression could be correlated with a distinct pattern of gene expression. The concept of a specific molecular portrait for a tumor of each individual patient was later validated by Perou, Bittner, and their coworkers using an array of clinical samples ( 35 , 36 ). Recent work in several groups has identified unique gene expression patterns, which are strongly correlated with clinical outcomes for other types of tumors including prostate, breast, lung, and liver cancers ( 37 - 41 ). Biomarkers are usually divided into prognostic, predictive, and therapeutic response markers. Prognostic biomarkers allow to predict the natural course of an individual cancer, thus making it possible to distinguish indolent tumors from aggressive tumors. Predictive biomarkers are used to assess the probability that a patient will benefit from a particular treatment. For example, patients with breast cancer in which the gene HER2 ( ERBB2 ) encoding a receptor tyrosine kinase is amplified are expected to benefit from treatment with trastuzumab (Herceptin) ( 42 ), whereas, in cases in which the gene encoding the estrogen receptor is overexpressed by the tumor, the patients might better respond to tamoxifen treatment ( 43 ). Pharmacodynamic biomarkers measure the short-term treatment effects a drug has on a tumor and these are used to guide dose selection in the early stages of clinical development of new drugs. For most applications, single biomarkers are unlikely to provide the necessary sensitivity and specificity owing to the substantial heterogeneity among cancers. It is unrealistic to expect that a single biomarker will provide information about tissue type and malignant transformation throughout the various stages of tumor development and progression. Therefore, panels of biomarkers are needed, but their discovery and validation must go through several key steps before they could be employed in clinical practice. As shown in Figure 2 , the first step involves experimental design and acquisition of molecular data, typically in the form of large amounts of genomic or proteomic expression data together with the patient history. These data need to be properly organized and annotated using available databases and web-based tools. Furthermore, the original data are evaluated and improved by removing technical artifacts and by combining multiple datasets to increase statistical significance. The second stage in data processing uses feature extraction and classification methods such as omniBiomarker (see below) to identify relevant biomarkers, which are differentially expressed. Before these biomarkers can be used in a clinical application, their functional relevance is validated through determining their expression level with multiplexed nanotechnology (for proteins), or by RT-PCR (for nucleic acids). In the following, we discuss web-based bioinformatics tools for analysis of microarray data, biomarker discovery, and their clinical validation. Bioinformatics Tools Early in the microarray era, bioinformatics tools often focused on unsupervised clustering and the main interests were to explore new technologies and to discovernew properties within the data structure, without dwelling on potential clinical applications. For example, Eisen et al. ( 44 ) developed a software application that combines several types of unsupervised clustering methods. A more recent development combines clustering algorithms and visualization tools into a web-based application ( 45 ), but with a focus on unsupervised clustering. Similar methods have been applied to analyze high-throughput gene expression data from different clinical scenarios and have led to significant findings concerning the identification of cancer subtypes ( 46 , 47 ). As such, unsupervised clustering applications are still widely used for data visualization and discovery. More recently, the focus of analysis of microarray data has moved away from unsupervised clustering to more guided and supervised analysis. Consequently, web-based bioinformatics applications have shifted, and these newer tools focus on the analysis of genes which are differentially expressed under different known conditions. Some of these tools are specific to microarray platforms; for example, MAGMA and ILOOP (Interwoven Loop) are web-based applications designed to analyze two-channel microarrays ( 48 , 49 ). ILOOP is an interface that assists in the experimental design of two-channel microarrays, while MAGMA incorporates standard normalization and statistical methods into an application which primary aim is usability and reproducibility. Not surprisingly, many of these web-based applications implement functionality for several common steps in the data analysis pipeline. GEPAS (Gene Expression Profile Analysis Suite), for example, includes functions that address several aspects of microarray analysis, including data normalization, feature selection, class prediction, and even unsupervised clustering ( 50 ). CARMAweb (comprehensive R and bioconductor-based web) is another recent tool for microarray analysis ( 51 ), which uses modules from Bioconductor, an open-source bioinformatics software package that leverages the R programming language ( https://carmaweb.genome.tugraz.at ). The microarray analysis functions available in Bioconductor include background correction, quality control, normalization, differential gene detection, clustering, dimensionality reduction, and visualization ( 52 ). As with most bioinformatics applications, the main contribution of CARMAweb to the bioinformatics community is the integration of numerous tools into a user-friendly web interface. GenePattern ( 53 ) is another compilation of different gene expression analysis tools, and is furthering the concept of usability and reproducibility by being integrated into the cancer Bioinformatics Grid (caBIG), an initiative of the National Cancer Institute (NCI), to create a standard for semantic interoperability of bioinformatics software ( 54 ). It is well established that the lists of candidate biomarkers resulting from microarray data analysis depend on both, the available samples and the selection algorithm ( 55 ). In fact, these lists may be highly unstable and often vary from sample to sample. Furthermore, high-throughput assay platforms typically consist of tens of thousands of genes, many of which are still not fully understood. Thus, the task of interpreting their results is daunting. By associating each candidate gene with a biological function, one might be able to begin to understand the underlying mechanisms of the associated disease and the biological relevance of the feature selection algorithm. Databases such as the Gene Ontology (GO) are designed to facilitate interpretation of gene functions on a large scale ( 56 ). A diverse range of GO tools is available to extract statistically significant conclusions from a GO database analysis. These are available as either web-based or downloadable packages, including GoMiner ( 57 , 58 ), GOStat ( 59 ), AmiGO ( 60 ), BiNGO ( 61 ), and GOEAST ( 62 ). There are also similar applications that mine the literature, rather than the GO database. CoPub, for example, links lists of candidate genes to keywords that are obtained from the literature by searching Medline abstracts and visualizes those keywords that are statistically overrepresented using a network structure ( http://services.nbic.nl/cgi-bin/copub/CoPub.pl ) ( 63 ). With the steadily increasing accumulation of gene expression data, several applications have emerged with the aim to organize and integrate these data sources and heterogeneous datasets more effectively. As previously mentioned, increasing the data sample size can improve the reproducibility of the resulting predictive models. Thus, there has been a demand for solutions that would allow data sharing. The Gene Expression Omnibus (GEO) ( 64 ) and ArrayExpress ( 65 ) are examples of large repositories that adhere to community data standards such as MIAME ( 66 ). ArrayWiki is an alternative solution that allows the community of users to annotate gene expression metadata ( 67 ). caArray is part of the caBIG initiative and is intended to become a semantically interoperable standard for microarray storage of caBIG applications ( 54 ). Just as there is an overlap between the different analytical methods in gene expression analysis and gene interpretation software, there are overlaps between the data that are deposited in these high-throughput data repositories. Consequently, a web-based application called the ‘Microarray Retriever’ ( 68 ) has been developed to retrieve gene expression data from both the GEO and ArrayExpress repositories in order to maximize the potential for large-sample microarray studies. Similarly, GEOmetadb is an improvement over the querying capabilities of the GEO repository ( 69 ). Although this application is currently only available for GEO, it is anticipated that meta-analysis applications will become increasingly useful. Despite the availability of these software packages, it remains difficult to use the data output of a quality control and normalization application in a subsequent clustering or feature selection application ( 70 ). Furthermore, there is a need to translate lists of gene symbols from a feature selection application before they could be interpreted by a particular GO application. Workflow applications, such as GeneTrailExpress and Taverna, address this issue in different ways. GeneTrailExpress is a comprehensive web-based application that implements its own normalization, statistical analysis, interpretation, and visualization modules based on common methods ( 71 ). Taverna is more general and builds workflows for caBIG certified web services ( 72 ). Another web-based bioinformatics resource for biomarker identification, the so-called omniBioMarker, has been developed by Phan et al. ( 73 ) (see Figure 3 ). In this software tool, biomarkers are identified through several steps including quality control and normalization, feature selection, biological interpretation, validation, and clinical prediction. Since one cannot expect a single path within the biomarker identification pipeline to perform well for all possible datasets ( 74 ), unique analysis parameters will need to be applied for each specific clinical problem. The computational foundation of omniBiomarker addresses this problem by fine-tuning every step in the pipeline to a particular dataset or clinical problem based on prior biological knowledge ( 73 ). This knowledge is used to overcome the “curse of dimensionality” (see Box 1 and Figure 4 ) and to stabilize the results, as well as to increase the reproducibility of clinical prediction. The first step in the biomarker identification pipeline is quality control. Due to the stochastic nature of high-throughput data, it is important to assess data quality prior to their further analysis. Moreover, the large quantity of high-throughput data requires specialized software applications. There are several existing applications that assess data quality, particularly for microarrays, within a population of samples while simultaneously estimating and normalizing gene expression. These applications vary in terms of their modeling complexity and usability, ranging from downloadable software packages, for example RMA Express ( 75 ) and dChip ( 76 ), to web-based applications such as caCorrect ( 77 ). Although gene expression assays are generally reproducible ( 78 ), statistical artifacts in smaller datasets need to be identified and either corrected or removed prior to further data analysis. For a case study for the use of omniBiomarker for biomarker discovery see Box 2. Clinical Validation by Multiplexed Molecular Analysis For large data sets of over 100,000 genes and proteins, computing tools can be used to select and optimize a small panel of biomarkers (perhaps a dozen of genes or proteins) that are strong predictors for patient outcome or therapeutic response. Nanoparticles that are conjugated to antibodies can be designed with the purpose of following this small set of biomarkers for molecular diagnosis and targeted therapy. In particular, multiplexed QD probes can be used to profile a selected biomarker panel in typical clinical tissue specimens, such as needle biopsies and tissue microarrays. The use of around five to ten protein biomarkers could have a significant impact on disease diagnosis, as well as in guiding individualized treatment. Towards these goals, Xing et al. ( 18 ) have obtained promising results for the molecular profiling of clinical formalin-fixed paraffin-embedded (FFPE) prostate specimens. In this study, four QD-antibody conjugates have been used to recognize and detect four tumor antigens, the E3 ubiquitin ligase mdm-2, the tumor-suppressor p53, the zinc-finger transcription factor EGR-1 and the cyclin-dependent kinase inhibitor p21/CDN1A. These markers are known to be important in prostate cancer diagnosis and have been correlated with tumor behavior ( 79 , 80 ). Recent work also confirmed that the results from molecular profiling with QDs was consistent with results obtained by traditional immunohistochemistry (IHC) and fluorescence in situ hybridization (FISH) using human breast cancer cells ( 19 ). It is important to note that tumor classification with antigens which are expressed at low levels can be subjective and therefore requires experienced observers which furthermore can often contribute to considerable variations. In contrast, quantitative QD measurements allow accurate and user-independent determination of tumor antigens even when they are expressed at low levels. Thus, the quantitative nature of QD-based molecular profiling could simplify and standardize categorization of antigens of low-abundance on intact cells and tissue specimens. This is of fundamental importance in the management of breast cancer, since the likely benefit of hormonal therapies and trastuzumab directly depends not only on the presence, but also the quantity of hormone or HER2 receptors ( 81 - 83 ). Prospects and Challenges Looking into the future, there are a number of research directions that are particularly promising for biomedical applications but require additional concerted efforts for success. The first direction of research is the design and development of nanoparticles, either with only one or multiple functionalities. For applications in cancer and other medical conditions, relevant nanoparticle functions include imaging (either as single or dual-modality) and therapy, via their delivery of a drug or of a combination of several drugs, as well as targeting through one or more ligands. With each function added, nanoparticles could be designed to have novel properties and applications. For example, binary nanoparticles with two functionalities could be developed for molecular imaging and targeted therapy, or for simultaneous imaging and therapy (but without targeting). Bioconjugated QDs, which have both targeting and imaging functions, could be used for targeted tumor imaging and for molecular profiling applications. Conversely, ternary nanoparticles that combine three functions could be designed so that they would allow for simultaneous imaging and targeted therapy. The second direction of research will address the optimizing biomarker panels using bioinformatics and quantitative molecular profiling with the help of nanotechnology, for example by using bioconjugated nanoparticle probes in order to predict cancer behavior, clinical outcome, treatment response, and thus to individualize or personalize therapy. Such an approach should ideally start with retrospective studies of archived specimens as the patient outcome is already known for these specimens. The key hypotheses that will need to be tested are that a panel of tumor markers will allow more accurate correlations than relying on single tumor markers; and that the combination of tumor gene expression and host stroma molecular data is necessary for defining aggressive phenotypes of cancer, as well as for determining the response of early stage disease to treatment (chemotherapy, radiation, or surgery). The third important research direction is to further investigate nanoparticle distribution, excretion, metabolism, and pharmacodynamics in in-vivo animal models. These studies will be very important in the development of nanoparticles for clinical applications in cancer imaging or therapy.  Biomarkers Biomolecular markers include altered or mutant genes, RNA, proteins, lipids, carbohydrates, small metabolite molecules, and altered expression states of such markers that can be correlated with a biological behavior or a clinical outcome ( 28 - 31 ). Most biomarkers have been discovered by molecular profiling studies, based on an association or correlation between a molecular signature and disease behavior. One of the first molecular profiling studies was reported by Golub et al . ( 32 ), who showed that gene expression patterns could classify tumors, thereby yielding new insights into tumor pathology such as its stage, grade, clinical course, and response to treatment. Gene expression studies further revealed that the molecular signatures of each tumor are a result of the combined tumoral, stromal, and inflammatory factors of the original heterogeneous lesion ( 33 ). The first clinical correlation of gene expression patterns with clinical outcome was reported for diffuse large B-cell lymphoma ( 34 ), a clinically heterogeneous disease. Whereas most of the patients succumbed to the disease, the remainder responded well to therapy and had prolonged survival. This variability in disease progression could be correlated with a distinct pattern of gene expression. The concept of a specific molecular portrait for a tumor of each individual patient was later validated by Perou, Bittner, and their coworkers using an array of clinical samples ( 35 , 36 ). Recent work in several groups has identified unique gene expression patterns, which are strongly correlated with clinical outcomes for other types of tumors including prostate, breast, lung, and liver cancers ( 37 - 41 ). Biomarkers are usually divided into prognostic, predictive, and therapeutic response markers. Prognostic biomarkers allow to predict the natural course of an individual cancer, thus making it possible to distinguish indolent tumors from aggressive tumors. Predictive biomarkers are used to assess the probability that a patient will benefit from a particular treatment. For example, patients with breast cancer in which the gene HER2 ( ERBB2 ) encoding a receptor tyrosine kinase is amplified are expected to benefit from treatment with trastuzumab (Herceptin) ( 42 ), whereas, in cases in which the gene encoding the estrogen receptor is overexpressed by the tumor, the patients might better respond to tamoxifen treatment ( 43 ). Pharmacodynamic biomarkers measure the short-term treatment effects a drug has on a tumor and these are used to guide dose selection in the early stages of clinical development of new drugs. For most applications, single biomarkers are unlikely to provide the necessary sensitivity and specificity owing to the substantial heterogeneity among cancers. It is unrealistic to expect that a single biomarker will provide information about tissue type and malignant transformation throughout the various stages of tumor development and progression. Therefore, panels of biomarkers are needed, but their discovery and validation must go through several key steps before they could be employed in clinical practice. As shown in Figure 2 , the first step involves experimental design and acquisition of molecular data, typically in the form of large amounts of genomic or proteomic expression data together with the patient history. These data need to be properly organized and annotated using available databases and web-based tools. Furthermore, the original data are evaluated and improved by removing technical artifacts and by combining multiple datasets to increase statistical significance. The second stage in data processing uses feature extraction and classification methods such as omniBiomarker (see below) to identify relevant biomarkers, which are differentially expressed. Before these biomarkers can be used in a clinical application, their functional relevance is validated through determining their expression level with multiplexed nanotechnology (for proteins), or by RT-PCR (for nucleic acids). In the following, we discuss web-based bioinformatics tools for analysis of microarray data, biomarker discovery, and their clinical validation.  Bioinformatics Tools Early in the microarray era, bioinformatics tools often focused on unsupervised clustering and the main interests were to explore new technologies and to discovernew properties within the data structure, without dwelling on potential clinical applications. For example, Eisen et al. ( 44 ) developed a software application that combines several types of unsupervised clustering methods. A more recent development combines clustering algorithms and visualization tools into a web-based application ( 45 ), but with a focus on unsupervised clustering. Similar methods have been applied to analyze high-throughput gene expression data from different clinical scenarios and have led to significant findings concerning the identification of cancer subtypes ( 46 , 47 ). As such, unsupervised clustering applications are still widely used for data visualization and discovery. More recently, the focus of analysis of microarray data has moved away from unsupervised clustering to more guided and supervised analysis. Consequently, web-based bioinformatics applications have shifted, and these newer tools focus on the analysis of genes which are differentially expressed under different known conditions. Some of these tools are specific to microarray platforms; for example, MAGMA and ILOOP (Interwoven Loop) are web-based applications designed to analyze two-channel microarrays ( 48 , 49 ). ILOOP is an interface that assists in the experimental design of two-channel microarrays, while MAGMA incorporates standard normalization and statistical methods into an application which primary aim is usability and reproducibility. Not surprisingly, many of these web-based applications implement functionality for several common steps in the data analysis pipeline. GEPAS (Gene Expression Profile Analysis Suite), for example, includes functions that address several aspects of microarray analysis, including data normalization, feature selection, class prediction, and even unsupervised clustering ( 50 ). CARMAweb (comprehensive R and bioconductor-based web) is another recent tool for microarray analysis ( 51 ), which uses modules from Bioconductor, an open-source bioinformatics software package that leverages the R programming language ( https://carmaweb.genome.tugraz.at ). The microarray analysis functions available in Bioconductor include background correction, quality control, normalization, differential gene detection, clustering, dimensionality reduction, and visualization ( 52 ). As with most bioinformatics applications, the main contribution of CARMAweb to the bioinformatics community is the integration of numerous tools into a user-friendly web interface. GenePattern ( 53 ) is another compilation of different gene expression analysis tools, and is furthering the concept of usability and reproducibility by being integrated into the cancer Bioinformatics Grid (caBIG), an initiative of the National Cancer Institute (NCI), to create a standard for semantic interoperability of bioinformatics software ( 54 ). It is well established that the lists of candidate biomarkers resulting from microarray data analysis depend on both, the available samples and the selection algorithm ( 55 ). In fact, these lists may be highly unstable and often vary from sample to sample. Furthermore, high-throughput assay platforms typically consist of tens of thousands of genes, many of which are still not fully understood. Thus, the task of interpreting their results is daunting. By associating each candidate gene with a biological function, one might be able to begin to understand the underlying mechanisms of the associated disease and the biological relevance of the feature selection algorithm. Databases such as the Gene Ontology (GO) are designed to facilitate interpretation of gene functions on a large scale ( 56 ). A diverse range of GO tools is available to extract statistically significant conclusions from a GO database analysis. These are available as either web-based or downloadable packages, including GoMiner ( 57 , 58 ), GOStat ( 59 ), AmiGO ( 60 ), BiNGO ( 61 ), and GOEAST ( 62 ). There are also similar applications that mine the literature, rather than the GO database. CoPub, for example, links lists of candidate genes to keywords that are obtained from the literature by searching Medline abstracts and visualizes those keywords that are statistically overrepresented using a network structure ( http://services.nbic.nl/cgi-bin/copub/CoPub.pl ) ( 63 ). With the steadily increasing accumulation of gene expression data, several applications have emerged with the aim to organize and integrate these data sources and heterogeneous datasets more effectively. As previously mentioned, increasing the data sample size can improve the reproducibility of the resulting predictive models. Thus, there has been a demand for solutions that would allow data sharing. The Gene Expression Omnibus (GEO) ( 64 ) and ArrayExpress ( 65 ) are examples of large repositories that adhere to community data standards such as MIAME ( 66 ). ArrayWiki is an alternative solution that allows the community of users to annotate gene expression metadata ( 67 ). caArray is part of the caBIG initiative and is intended to become a semantically interoperable standard for microarray storage of caBIG applications ( 54 ). Just as there is an overlap between the different analytical methods in gene expression analysis and gene interpretation software, there are overlaps between the data that are deposited in these high-throughput data repositories. Consequently, a web-based application called the ‘Microarray Retriever’ ( 68 ) has been developed to retrieve gene expression data from both the GEO and ArrayExpress repositories in order to maximize the potential for large-sample microarray studies. Similarly, GEOmetadb is an improvement over the querying capabilities of the GEO repository ( 69 ). Although this application is currently only available for GEO, it is anticipated that meta-analysis applications will become increasingly useful. Despite the availability of these software packages, it remains difficult to use the data output of a quality control and normalization application in a subsequent clustering or feature selection application ( 70 ). Furthermore, there is a need to translate lists of gene symbols from a feature selection application before they could be interpreted by a particular GO application. Workflow applications, such as GeneTrailExpress and Taverna, address this issue in different ways. GeneTrailExpress is a comprehensive web-based application that implements its own normalization, statistical analysis, interpretation, and visualization modules based on common methods ( 71 ). Taverna is more general and builds workflows for caBIG certified web services ( 72 ). Another web-based bioinformatics resource for biomarker identification, the so-called omniBioMarker, has been developed by Phan et al. ( 73 ) (see Figure 3 ). In this software tool, biomarkers are identified through several steps including quality control and normalization, feature selection, biological interpretation, validation, and clinical prediction. Since one cannot expect a single path within the biomarker identification pipeline to perform well for all possible datasets ( 74 ), unique analysis parameters will need to be applied for each specific clinical problem. The computational foundation of omniBiomarker addresses this problem by fine-tuning every step in the pipeline to a particular dataset or clinical problem based on prior biological knowledge ( 73 ). This knowledge is used to overcome the “curse of dimensionality” (see Box 1 and Figure 4 ) and to stabilize the results, as well as to increase the reproducibility of clinical prediction. The first step in the biomarker identification pipeline is quality control. Due to the stochastic nature of high-throughput data, it is important to assess data quality prior to their further analysis. Moreover, the large quantity of high-throughput data requires specialized software applications. There are several existing applications that assess data quality, particularly for microarrays, within a population of samples while simultaneously estimating and normalizing gene expression. These applications vary in terms of their modeling complexity and usability, ranging from downloadable software packages, for example RMA Express ( 75 ) and dChip ( 76 ), to web-based applications such as caCorrect ( 77 ). Although gene expression assays are generally reproducible ( 78 ), statistical artifacts in smaller datasets need to be identified and either corrected or removed prior to further data analysis. For a case study for the use of omniBiomarker for biomarker discovery see Box 2.  Clinical Validation by Multiplexed Molecular Analysis For large data sets of over 100,000 genes and proteins, computing tools can be used to select and optimize a small panel of biomarkers (perhaps a dozen of genes or proteins) that are strong predictors for patient outcome or therapeutic response. Nanoparticles that are conjugated to antibodies can be designed with the purpose of following this small set of biomarkers for molecular diagnosis and targeted therapy. In particular, multiplexed QD probes can be used to profile a selected biomarker panel in typical clinical tissue specimens, such as needle biopsies and tissue microarrays. The use of around five to ten protein biomarkers could have a significant impact on disease diagnosis, as well as in guiding individualized treatment. Towards these goals, Xing et al. ( 18 ) have obtained promising results for the molecular profiling of clinical formalin-fixed paraffin-embedded (FFPE) prostate specimens. In this study, four QD-antibody conjugates have been used to recognize and detect four tumor antigens, the E3 ubiquitin ligase mdm-2, the tumor-suppressor p53, the zinc-finger transcription factor EGR-1 and the cyclin-dependent kinase inhibitor p21/CDN1A. These markers are known to be important in prostate cancer diagnosis and have been correlated with tumor behavior ( 79 , 80 ). Recent work also confirmed that the results from molecular profiling with QDs was consistent with results obtained by traditional immunohistochemistry (IHC) and fluorescence in situ hybridization (FISH) using human breast cancer cells ( 19 ). It is important to note that tumor classification with antigens which are expressed at low levels can be subjective and therefore requires experienced observers which furthermore can often contribute to considerable variations. In contrast, quantitative QD measurements allow accurate and user-independent determination of tumor antigens even when they are expressed at low levels. Thus, the quantitative nature of QD-based molecular profiling could simplify and standardize categorization of antigens of low-abundance on intact cells and tissue specimens. This is of fundamental importance in the management of breast cancer, since the likely benefit of hormonal therapies and trastuzumab directly depends not only on the presence, but also the quantity of hormone or HER2 receptors ( 81 - 83 ).  Prospects and Challenges Looking into the future, there are a number of research directions that are particularly promising for biomedical applications but require additional concerted efforts for success. The first direction of research is the design and development of nanoparticles, either with only one or multiple functionalities. For applications in cancer and other medical conditions, relevant nanoparticle functions include imaging (either as single or dual-modality) and therapy, via their delivery of a drug or of a combination of several drugs, as well as targeting through one or more ligands. With each function added, nanoparticles could be designed to have novel properties and applications. For example, binary nanoparticles with two functionalities could be developed for molecular imaging and targeted therapy, or for simultaneous imaging and therapy (but without targeting). Bioconjugated QDs, which have both targeting and imaging functions, could be used for targeted tumor imaging and for molecular profiling applications. Conversely, ternary nanoparticles that combine three functions could be designed so that they would allow for simultaneous imaging and targeted therapy. The second direction of research will address the optimizing biomarker panels using bioinformatics and quantitative molecular profiling with the help of nanotechnology, for example by using bioconjugated nanoparticle probes in order to predict cancer behavior, clinical outcome, treatment response, and thus to individualize or personalize therapy. Such an approach should ideally start with retrospective studies of archived specimens as the patient outcome is already known for these specimens. The key hypotheses that will need to be tested are that a panel of tumor markers will allow more accurate correlations than relying on single tumor markers; and that the combination of tumor gene expression and host stroma molecular data is necessary for defining aggressive phenotypes of cancer, as well as for determining the response of early stage disease to treatment (chemotherapy, radiation, or surgery). The third important research direction is to further investigate nanoparticle distribution, excretion, metabolism, and pharmacodynamics in in-vivo animal models. These studies will be very important in the development of nanoparticles for clinical applications in cancer imaging or therapy. 