Statistical Learning in Children With Specific Language Impairment Purpose In this study, the authors examined (a) whether children with specific language impairment (SLI) can implicitly compute the probabilities of adjacent sound sequences, (b) if this ability is related to degree of exposure, (c) if it is domain specific or domain general and, (d) if it is related to vocabulary. Method Children with SLI and normal language controls (ages 6;5–14;4 [years;months]) listened to 21 min of a language in which transitional probabilities within words were higher than those between words. In a second study, children with SLI and Age–Nonverbal IQ matched controls (8;0–10;11) listened to the same language for 42 min and to a second 42 min “tone” language containing the identical statistical structure as the “speech” language. Results After 21 min, the SLI group's performance was at chance, whereas performance for the control group was significantly greater than chance and significantly correlated with receptive and expressive vocabulary knowledge. In the 42-minute speech condition, the SLI group's performance was significantly greater than chance and correlated with receptive vocabulary but was no different from chance in the analogous 42-minute tone condition. Performance for the control group was again significantly greater than chance in 42-minute speech and tone conditions. Conclusions These findings suggest that poor implicit learning may underlie aspects of the language impairments in SLI.  Experiment 1 Method Participants A total of 113 children, 35 children with SLI (6;5–14;4) and 78 typically developing children with NL (5;7–12;10) participated in Experiment 1. All children met the following criteria: (a) non-verbal Intelligence of 85 or greater, as measured by the Leiter International Performance Scale (LIPS; Roid & Miller, 1997 ); (b) normal hearing based on ASHA 1997 guidelines for hearing screening on the day of the experiment (at 500, 1000, 2000, and 4000 Hz at 20 dB); (c) normal corrected vision; (d) normal oral and speech motor abilities; and (e) monolingual English speakers. For the children with SLI, all subtests of the Clinical Evaluation of Language Fundamentals–Third Edition (CELF-3; Semel, Wiig, & Secord, 1995 ) were administered, and for the NL group, the three expressive language subtests and the Concepts and Directions receptive language subtest from the CELF-3 were administered. In addition, to investigate whether statistical word learning is related to lexical knowledge, the Peabody Picture Vocabulary Test-Third Edition (PPVT-III; Dunn & Dunn, 1997 ) and the Expressive Vocabulary Test (EVT; Williams, 1997 ) also were administered to both groups. For the group with SLI, composite expressive language scores from the CELF-3 were at or below 1.5 SD below the mean. For the NL group, standardized language measures from the CELF-3 and the PPVT-III, as well as the EVT, were all at or above age-level expectations. The SLI and NL groups' performance differed significantly on all standardized measures (see Table 1 ). 1 Stimuli The stimuli for this study were the same as those used by Saffran et al. (1997) . The language consisted of 12 CV syllables made up of seven consonants and vowels (p, t, b, d, a, I, and u). These CV pairs were combined into six trisyllabic “words” (>dutaba, tutibu, pidabu, patubi, bupada, and babupu). The language was constructed to ensure that the transitional probabilities between syllables within the words were higher than the transitional probabilities between syllables across word boundaries. Because some of the syllables occurred in more words that others (e.g., bu occurred in four words, whereas ta occurred in only one word), the within-word transitional probabilities ranged from 0.37 to 1.0. The transitional probabilities across the word boundaries ranged from 0.1 to 0.2. Three-hundred tokens of each of the six words were combined in a random sequence and were created into a stream of speech using the MacInTalk (Apple, Cupertino, CA) speech synthesizer, with the constraint that the same word could not occur twice in a row. The result was a 4,536-syllable, continuous speech stream that contained no acoustic word boundary cues, equivalent coarticulation between syllables, no prosodic cues, and no pauses between or within the words. The speech stream was produced using a female monotone voice speaking at 216 syllables per min. In addition to the speech stream, six nonword foils were created ( batipa, bidata, dupitu, pubati, tapuba , and tipabu ). The nonwords were made up of syllables from the language's syllable inventory that never followed each other in the speech stream. The transitional probabilities of the syllable sequences for the nonwords were thus zero. The test stimuli—both words and nonwords—were synthesized in citation form using the MacInTalk speech synthesizer. The six words and six nonwords were paired exhaustively to generate a 36-trial, two-alternative forced-choice test; half of the test items contained a word as the first member of a pair, and half contained a nonword as the first member of a pair. The test items were recorded onto a digital minidisk for subsequent playback. The stimulus words and their transitional probabilities, as well as the nonword foils, are listed in Table 2 . Procedure The procedure was the same as that used in Saffran et al. (1997) . While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2 (Houghton Mifflin Harcourt Learning Technology and Riverdeep International Education, Ltd, Beijing, China). Children listened to the tape for a total of 21 min. During the 21 min of exposure, the examiner sat quietly behind the children to ensure that they sustained interest in the drawing task and were not distracted. At the end of the 21 min, children were tested using a forced-choice paradigm. Children heard pairs of trisyllables (which is a word paired with a nonword) on each trial and were asked to choose the sound in each pair that sounded more like the sounds they heard while drawing. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing word–nonword pairs derived from words in English and were asked to identify which one sounded more like a word (e.g., com-pu-ter vs. pu-ter-com ). Following the practice trials, the children were presented with the 36 test pairs. All of the children were able to successfully complete the practice trials, and no children were excluded from the study due to their inability to understand the task. Results and Discussion The results for the SLI and NL groups are presented in Figure 1 . An analysis of covariance (ANCOVA) with age and nonverbal IQ as covariates revealed that the SLI group's ability to attend to transitional probabilities in the speech stream was significantly poorer than the NL group's: F (1, 109) = 5.6, p < .01, partial ?2 = .05, ? = .65. The mean for the children with SLI was 52% ( SD = 11%) and for the NL group was 58% ( SD = 13%) where chance equals 50%. Single-sample t tests (two-tailed) indicated that the SLI group's performance did not differ from chance, t (34) = 0.97, p = .33, whereas the typical children's performance was significantly better than chance, t (77) = 5.53, p < .001. One question is whether the strength of the transitional probabilities between the words played a role in how well individual words were learned. As noted earlier, the transitional probabilities within the words ranged from 0.37 to 1.0. Analysis of the individual target words for the SLI group indicated that none of the six words were learned significantly better than chance. For the NL group, all six words were learned significantly better than expected by chance ( p < .05), suggesting that after only 21 min of exposure, the typically developing children were easily able to exploit transitional probabilities to discover the words embedded in the speech stream. There is reason to believe that the ability to track sequential statistics should be related to lexical knowledge. Challenges segmenting words from the speech stream would likely slow lexical development. Indeed, infant segmentation skill, broadly construed (i.e., including cues other than just sequential statistics), predicts later vocabulary outcomes ( Newman, Bernstein Ratner, Jusczyk, Jusczyk, & Dow, 2006 ; Singh & Nestor, 2006 ; Singh, Nestor, Paulson, & Strand, 2007 ). We thus asked whether children's ability to track the transitional probabilities in the word segmentation task is related to their vocabulary. Pearson correlations for age, nonverbal IQ, and raw scores from measures of expressive (EVT) and receptive vocabulary (PPVT-III) indicate that the NL group's performance on the statistical word learning task was significantly correlated with age ( p < .05), receptive vocabulary ( p < .01), and expressive vocabulary ( p < .01; Table 3 ). Given that age and statistical learning performance were significantly correlated, we conducted a second correlation analysis controlling for age. After removing age, performance on the statistical learning task remained significantly correlated with expressive vocabulary ( r = .28, p < .001) and receptive vocabulary ( r = .23, p < .05) for the typically developing children. Pearson correlations for age, nonverbal IQ, and raw scores from measures of expressive and receptive vocabulary (PPVT-III) indicate that the SLI group's performance on the statistical word learning task was not significantly correlated with age ( p = .45), nonverbal IQ ( p = .24), receptive vocabulary ( p = .40), or expressive vocabulary ( p = .17). The results of Experiment 1 indicate that after 21 min of exposure to a continuous speech stream, children with SLI were not able to use statistical information to implicitly discover word boundaries based on differences in transitional probabilities. In contrast, typically developing children were able to discover word boundaries after only 21 min of exposure, and this ability to use statistical information in the speech stream was also significantly correlated with both expressive and receptive vocabulary knowledge. One question is whether the children with SLI were exposed to the speech stream for a long enough duration to discover the statistical patterns among adjacent sound sequences. Saffran et al. (1997) observed a significant increase in performance for both adults and school-aged children when they were exposed to the 21 min of the language on 2 consecutive days. Thus, it is not clear from Experiment 1 if children with SLI are unable to track the differences in transitional probabilities due to the impoverished nature of the input or if they are simply inefficient at computing the statistics, requiring more exposure to the speech stream. If the latter is the case, the children with SLI may be able to compute the statistics given longer exposure to the input. We tested this hypothesis in Experiment 2a. In Experiment 2b, we asked whether the pattern of performance observed for children with SLI in the speech exposure condition in Experiment 2a is unique to speech processing. Specifically, in Experiment 2b, we used a nonlinguistic task designed to be analogous to the word segmentation task, in which tones were substituted for the syllables in the “words,” generating a fluent stream of tones ( Saffran et al., 1999 ).  Method Participants A total of 113 children, 35 children with SLI (6;5–14;4) and 78 typically developing children with NL (5;7–12;10) participated in Experiment 1. All children met the following criteria: (a) non-verbal Intelligence of 85 or greater, as measured by the Leiter International Performance Scale (LIPS; Roid & Miller, 1997 ); (b) normal hearing based on ASHA 1997 guidelines for hearing screening on the day of the experiment (at 500, 1000, 2000, and 4000 Hz at 20 dB); (c) normal corrected vision; (d) normal oral and speech motor abilities; and (e) monolingual English speakers. For the children with SLI, all subtests of the Clinical Evaluation of Language Fundamentals–Third Edition (CELF-3; Semel, Wiig, & Secord, 1995 ) were administered, and for the NL group, the three expressive language subtests and the Concepts and Directions receptive language subtest from the CELF-3 were administered. In addition, to investigate whether statistical word learning is related to lexical knowledge, the Peabody Picture Vocabulary Test-Third Edition (PPVT-III; Dunn & Dunn, 1997 ) and the Expressive Vocabulary Test (EVT; Williams, 1997 ) also were administered to both groups. For the group with SLI, composite expressive language scores from the CELF-3 were at or below 1.5 SD below the mean. For the NL group, standardized language measures from the CELF-3 and the PPVT-III, as well as the EVT, were all at or above age-level expectations. The SLI and NL groups' performance differed significantly on all standardized measures (see Table 1 ). 1 Stimuli The stimuli for this study were the same as those used by Saffran et al. (1997) . The language consisted of 12 CV syllables made up of seven consonants and vowels (p, t, b, d, a, I, and u). These CV pairs were combined into six trisyllabic “words” (>dutaba, tutibu, pidabu, patubi, bupada, and babupu). The language was constructed to ensure that the transitional probabilities between syllables within the words were higher than the transitional probabilities between syllables across word boundaries. Because some of the syllables occurred in more words that others (e.g., bu occurred in four words, whereas ta occurred in only one word), the within-word transitional probabilities ranged from 0.37 to 1.0. The transitional probabilities across the word boundaries ranged from 0.1 to 0.2. Three-hundred tokens of each of the six words were combined in a random sequence and were created into a stream of speech using the MacInTalk (Apple, Cupertino, CA) speech synthesizer, with the constraint that the same word could not occur twice in a row. The result was a 4,536-syllable, continuous speech stream that contained no acoustic word boundary cues, equivalent coarticulation between syllables, no prosodic cues, and no pauses between or within the words. The speech stream was produced using a female monotone voice speaking at 216 syllables per min. In addition to the speech stream, six nonword foils were created ( batipa, bidata, dupitu, pubati, tapuba , and tipabu ). The nonwords were made up of syllables from the language's syllable inventory that never followed each other in the speech stream. The transitional probabilities of the syllable sequences for the nonwords were thus zero. The test stimuli—both words and nonwords—were synthesized in citation form using the MacInTalk speech synthesizer. The six words and six nonwords were paired exhaustively to generate a 36-trial, two-alternative forced-choice test; half of the test items contained a word as the first member of a pair, and half contained a nonword as the first member of a pair. The test items were recorded onto a digital minidisk for subsequent playback. The stimulus words and their transitional probabilities, as well as the nonword foils, are listed in Table 2 . Procedure The procedure was the same as that used in Saffran et al. (1997) . While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2 (Houghton Mifflin Harcourt Learning Technology and Riverdeep International Education, Ltd, Beijing, China). Children listened to the tape for a total of 21 min. During the 21 min of exposure, the examiner sat quietly behind the children to ensure that they sustained interest in the drawing task and were not distracted. At the end of the 21 min, children were tested using a forced-choice paradigm. Children heard pairs of trisyllables (which is a word paired with a nonword) on each trial and were asked to choose the sound in each pair that sounded more like the sounds they heard while drawing. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing word–nonword pairs derived from words in English and were asked to identify which one sounded more like a word (e.g., com-pu-ter vs. pu-ter-com ). Following the practice trials, the children were presented with the 36 test pairs. All of the children were able to successfully complete the practice trials, and no children were excluded from the study due to their inability to understand the task.  Participants A total of 113 children, 35 children with SLI (6;5–14;4) and 78 typically developing children with NL (5;7–12;10) participated in Experiment 1. All children met the following criteria: (a) non-verbal Intelligence of 85 or greater, as measured by the Leiter International Performance Scale (LIPS; Roid & Miller, 1997 ); (b) normal hearing based on ASHA 1997 guidelines for hearing screening on the day of the experiment (at 500, 1000, 2000, and 4000 Hz at 20 dB); (c) normal corrected vision; (d) normal oral and speech motor abilities; and (e) monolingual English speakers. For the children with SLI, all subtests of the Clinical Evaluation of Language Fundamentals–Third Edition (CELF-3; Semel, Wiig, & Secord, 1995 ) were administered, and for the NL group, the three expressive language subtests and the Concepts and Directions receptive language subtest from the CELF-3 were administered. In addition, to investigate whether statistical word learning is related to lexical knowledge, the Peabody Picture Vocabulary Test-Third Edition (PPVT-III; Dunn & Dunn, 1997 ) and the Expressive Vocabulary Test (EVT; Williams, 1997 ) also were administered to both groups. For the group with SLI, composite expressive language scores from the CELF-3 were at or below 1.5 SD below the mean. For the NL group, standardized language measures from the CELF-3 and the PPVT-III, as well as the EVT, were all at or above age-level expectations. The SLI and NL groups' performance differed significantly on all standardized measures (see Table 1 ). 1  Stimuli The stimuli for this study were the same as those used by Saffran et al. (1997) . The language consisted of 12 CV syllables made up of seven consonants and vowels (p, t, b, d, a, I, and u). These CV pairs were combined into six trisyllabic “words” (>dutaba, tutibu, pidabu, patubi, bupada, and babupu). The language was constructed to ensure that the transitional probabilities between syllables within the words were higher than the transitional probabilities between syllables across word boundaries. Because some of the syllables occurred in more words that others (e.g., bu occurred in four words, whereas ta occurred in only one word), the within-word transitional probabilities ranged from 0.37 to 1.0. The transitional probabilities across the word boundaries ranged from 0.1 to 0.2. Three-hundred tokens of each of the six words were combined in a random sequence and were created into a stream of speech using the MacInTalk (Apple, Cupertino, CA) speech synthesizer, with the constraint that the same word could not occur twice in a row. The result was a 4,536-syllable, continuous speech stream that contained no acoustic word boundary cues, equivalent coarticulation between syllables, no prosodic cues, and no pauses between or within the words. The speech stream was produced using a female monotone voice speaking at 216 syllables per min. In addition to the speech stream, six nonword foils were created ( batipa, bidata, dupitu, pubati, tapuba , and tipabu ). The nonwords were made up of syllables from the language's syllable inventory that never followed each other in the speech stream. The transitional probabilities of the syllable sequences for the nonwords were thus zero. The test stimuli—both words and nonwords—were synthesized in citation form using the MacInTalk speech synthesizer. The six words and six nonwords were paired exhaustively to generate a 36-trial, two-alternative forced-choice test; half of the test items contained a word as the first member of a pair, and half contained a nonword as the first member of a pair. The test items were recorded onto a digital minidisk for subsequent playback. The stimulus words and their transitional probabilities, as well as the nonword foils, are listed in Table 2 .  Procedure The procedure was the same as that used in Saffran et al. (1997) . While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2 (Houghton Mifflin Harcourt Learning Technology and Riverdeep International Education, Ltd, Beijing, China). Children listened to the tape for a total of 21 min. During the 21 min of exposure, the examiner sat quietly behind the children to ensure that they sustained interest in the drawing task and were not distracted. At the end of the 21 min, children were tested using a forced-choice paradigm. Children heard pairs of trisyllables (which is a word paired with a nonword) on each trial and were asked to choose the sound in each pair that sounded more like the sounds they heard while drawing. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing word–nonword pairs derived from words in English and were asked to identify which one sounded more like a word (e.g., com-pu-ter vs. pu-ter-com ). Following the practice trials, the children were presented with the 36 test pairs. All of the children were able to successfully complete the practice trials, and no children were excluded from the study due to their inability to understand the task.  Results and Discussion The results for the SLI and NL groups are presented in Figure 1 . An analysis of covariance (ANCOVA) with age and nonverbal IQ as covariates revealed that the SLI group's ability to attend to transitional probabilities in the speech stream was significantly poorer than the NL group's: F (1, 109) = 5.6, p < .01, partial ?2 = .05, ? = .65. The mean for the children with SLI was 52% ( SD = 11%) and for the NL group was 58% ( SD = 13%) where chance equals 50%. Single-sample t tests (two-tailed) indicated that the SLI group's performance did not differ from chance, t (34) = 0.97, p = .33, whereas the typical children's performance was significantly better than chance, t (77) = 5.53, p < .001. One question is whether the strength of the transitional probabilities between the words played a role in how well individual words were learned. As noted earlier, the transitional probabilities within the words ranged from 0.37 to 1.0. Analysis of the individual target words for the SLI group indicated that none of the six words were learned significantly better than chance. For the NL group, all six words were learned significantly better than expected by chance ( p < .05), suggesting that after only 21 min of exposure, the typically developing children were easily able to exploit transitional probabilities to discover the words embedded in the speech stream. There is reason to believe that the ability to track sequential statistics should be related to lexical knowledge. Challenges segmenting words from the speech stream would likely slow lexical development. Indeed, infant segmentation skill, broadly construed (i.e., including cues other than just sequential statistics), predicts later vocabulary outcomes ( Newman, Bernstein Ratner, Jusczyk, Jusczyk, & Dow, 2006 ; Singh & Nestor, 2006 ; Singh, Nestor, Paulson, & Strand, 2007 ). We thus asked whether children's ability to track the transitional probabilities in the word segmentation task is related to their vocabulary. Pearson correlations for age, nonverbal IQ, and raw scores from measures of expressive (EVT) and receptive vocabulary (PPVT-III) indicate that the NL group's performance on the statistical word learning task was significantly correlated with age ( p < .05), receptive vocabulary ( p < .01), and expressive vocabulary ( p < .01; Table 3 ). Given that age and statistical learning performance were significantly correlated, we conducted a second correlation analysis controlling for age. After removing age, performance on the statistical learning task remained significantly correlated with expressive vocabulary ( r = .28, p < .001) and receptive vocabulary ( r = .23, p < .05) for the typically developing children. Pearson correlations for age, nonverbal IQ, and raw scores from measures of expressive and receptive vocabulary (PPVT-III) indicate that the SLI group's performance on the statistical word learning task was not significantly correlated with age ( p = .45), nonverbal IQ ( p = .24), receptive vocabulary ( p = .40), or expressive vocabulary ( p = .17). The results of Experiment 1 indicate that after 21 min of exposure to a continuous speech stream, children with SLI were not able to use statistical information to implicitly discover word boundaries based on differences in transitional probabilities. In contrast, typically developing children were able to discover word boundaries after only 21 min of exposure, and this ability to use statistical information in the speech stream was also significantly correlated with both expressive and receptive vocabulary knowledge. One question is whether the children with SLI were exposed to the speech stream for a long enough duration to discover the statistical patterns among adjacent sound sequences. Saffran et al. (1997) observed a significant increase in performance for both adults and school-aged children when they were exposed to the 21 min of the language on 2 consecutive days. Thus, it is not clear from Experiment 1 if children with SLI are unable to track the differences in transitional probabilities due to the impoverished nature of the input or if they are simply inefficient at computing the statistics, requiring more exposure to the speech stream. If the latter is the case, the children with SLI may be able to compute the statistics given longer exposure to the input. We tested this hypothesis in Experiment 2a. In Experiment 2b, we asked whether the pattern of performance observed for children with SLI in the speech exposure condition in Experiment 2a is unique to speech processing. Specifically, in Experiment 2b, we used a nonlinguistic task designed to be analogous to the word segmentation task, in which tones were substituted for the syllables in the “words,” generating a fluent stream of tones ( Saffran et al., 1999 ).  Method Participants Thirty children who participated in Experiment 1 were brought back into the lab 6 months later to participate in Experiments 2a and 2b. The children were chosen to be part of a group of age- and nonverbal-IQ-matched groups. This group consisted of 15 children with SLI (ages 8;0–10;11) and 15 age- and nonverbal-IQ-matched (CA-NIQ) controls. The CA-NIQ group did not differ from the SLI group in age, t (28) = 0.35, p = .72, or nonverbal IQ, t (28) = 0.28, p = .77 (see Table 4 ). The children were seen for two visits with an average of 10–14 days between visits. On each visit, children participated in either Experiment 2a or Experiment 2b, with order of participation counterbalanced. Stimuli and Procedures Experiment 2a The stimuli and procedures for Experiment 2a were identical to those of Experiment 1, with the exception that the children listened to the same materials twice, without a break, for 42 continuous min. As in Experiment 1, prior to the testing phase, children were presented with practice trials containing word–nonword pairs derived from words in English (e.g., com-pu-ter vs pu-ter-com ). Following the practice trials, the children were then presented with the test trials from Experiment 1. Again, all of the children were able to successfully complete all of the practice trials, and no children were excluded from the experiment due to their inability to understand the task. Experiment 2b The materials for Experiment 2b were identical to Tone Language 1 from Saffran et al. (1999) . The tone stream was constructed out of 11 pure tones taken from the same octave (starting at middle C within a chromatic set), with the same duration (0.33 s), created using the sine wave generator in SoundEdit 16 (Adobe, San Jose, CA). The tones were combined into groups of three to form six tone words (GG#A, CC#D, D#ED, FCF#, DFE, and ADB). The tone words were not constructed in accordance with the rules of standard musical composition and did not resemble any paradigmatic melodic fragments. Transitional probabilities between tones within words averaged 0.64 (range = 0.25–1.00). In contrast, transitional probabilities between tones spanning word boundaries averaged 0.14 (range = 0.05–0.60). Although these two distributions did overlap, this overlap was rare, occurring for only 3 of the 30 across-word tone instances. The six tones were concatenated together in a random order, with no silent junctures between words, to create six different blocks containing 18 words each. No words occurred twice in a row. The six blocks were, in turn, concatenated together to produce a 7-minute continuous stream of tones. As with the speech stimuli used in Experiments 1 and 2a, there were no acoustic markers of tone-word boundaries. The only consistent cue to the beginning and end of the tone words was the transitional probabilities between tones. In addition to the tone stream, six tone nonword foils were created (see Table 5 ). The procedure was identical to that used in Experiment 2a. While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2. Children listened to the tape for a total of 42 min. At the end of the 42 min, children heard pairs of “word” and “nonword” tone sequences and were asked to choose the sound sequence that sounded more familiar. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing tone sequences derived from familiar children's nursery rhymes presented in the correct or incorrect order (e.g., the tune, without words, from “ Mary Had a Little Lamb ” vs. the tune from “ Lamb Little Mary Had a ”). Following the practice trials, the children were then presented with the 36 test pairs. Again, all of the children were able to successfully complete all of the practice trials.  Participants Thirty children who participated in Experiment 1 were brought back into the lab 6 months later to participate in Experiments 2a and 2b. The children were chosen to be part of a group of age- and nonverbal-IQ-matched groups. This group consisted of 15 children with SLI (ages 8;0–10;11) and 15 age- and nonverbal-IQ-matched (CA-NIQ) controls. The CA-NIQ group did not differ from the SLI group in age, t (28) = 0.35, p = .72, or nonverbal IQ, t (28) = 0.28, p = .77 (see Table 4 ). The children were seen for two visits with an average of 10–14 days between visits. On each visit, children participated in either Experiment 2a or Experiment 2b, with order of participation counterbalanced.  Stimuli and Procedures Experiment 2a The stimuli and procedures for Experiment 2a were identical to those of Experiment 1, with the exception that the children listened to the same materials twice, without a break, for 42 continuous min. As in Experiment 1, prior to the testing phase, children were presented with practice trials containing word–nonword pairs derived from words in English (e.g., com-pu-ter vs pu-ter-com ). Following the practice trials, the children were then presented with the test trials from Experiment 1. Again, all of the children were able to successfully complete all of the practice trials, and no children were excluded from the experiment due to their inability to understand the task. Experiment 2b The materials for Experiment 2b were identical to Tone Language 1 from Saffran et al. (1999) . The tone stream was constructed out of 11 pure tones taken from the same octave (starting at middle C within a chromatic set), with the same duration (0.33 s), created using the sine wave generator in SoundEdit 16 (Adobe, San Jose, CA). The tones were combined into groups of three to form six tone words (GG#A, CC#D, D#ED, FCF#, DFE, and ADB). The tone words were not constructed in accordance with the rules of standard musical composition and did not resemble any paradigmatic melodic fragments. Transitional probabilities between tones within words averaged 0.64 (range = 0.25–1.00). In contrast, transitional probabilities between tones spanning word boundaries averaged 0.14 (range = 0.05–0.60). Although these two distributions did overlap, this overlap was rare, occurring for only 3 of the 30 across-word tone instances. The six tones were concatenated together in a random order, with no silent junctures between words, to create six different blocks containing 18 words each. No words occurred twice in a row. The six blocks were, in turn, concatenated together to produce a 7-minute continuous stream of tones. As with the speech stimuli used in Experiments 1 and 2a, there were no acoustic markers of tone-word boundaries. The only consistent cue to the beginning and end of the tone words was the transitional probabilities between tones. In addition to the tone stream, six tone nonword foils were created (see Table 5 ). The procedure was identical to that used in Experiment 2a. While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2. Children listened to the tape for a total of 42 min. At the end of the 42 min, children heard pairs of “word” and “nonword” tone sequences and were asked to choose the sound sequence that sounded more familiar. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing tone sequences derived from familiar children's nursery rhymes presented in the correct or incorrect order (e.g., the tune, without words, from “ Mary Had a Little Lamb ” vs. the tune from “ Lamb Little Mary Had a ”). Following the practice trials, the children were then presented with the 36 test pairs. Again, all of the children were able to successfully complete all of the practice trials.  Experiment 2a The stimuli and procedures for Experiment 2a were identical to those of Experiment 1, with the exception that the children listened to the same materials twice, without a break, for 42 continuous min. As in Experiment 1, prior to the testing phase, children were presented with practice trials containing word–nonword pairs derived from words in English (e.g., com-pu-ter vs pu-ter-com ). Following the practice trials, the children were then presented with the test trials from Experiment 1. Again, all of the children were able to successfully complete all of the practice trials, and no children were excluded from the experiment due to their inability to understand the task.  Experiment 2b The materials for Experiment 2b were identical to Tone Language 1 from Saffran et al. (1999) . The tone stream was constructed out of 11 pure tones taken from the same octave (starting at middle C within a chromatic set), with the same duration (0.33 s), created using the sine wave generator in SoundEdit 16 (Adobe, San Jose, CA). The tones were combined into groups of three to form six tone words (GG#A, CC#D, D#ED, FCF#, DFE, and ADB). The tone words were not constructed in accordance with the rules of standard musical composition and did not resemble any paradigmatic melodic fragments. Transitional probabilities between tones within words averaged 0.64 (range = 0.25–1.00). In contrast, transitional probabilities between tones spanning word boundaries averaged 0.14 (range = 0.05–0.60). Although these two distributions did overlap, this overlap was rare, occurring for only 3 of the 30 across-word tone instances. The six tones were concatenated together in a random order, with no silent junctures between words, to create six different blocks containing 18 words each. No words occurred twice in a row. The six blocks were, in turn, concatenated together to produce a 7-minute continuous stream of tones. As with the speech stimuli used in Experiments 1 and 2a, there were no acoustic markers of tone-word boundaries. The only consistent cue to the beginning and end of the tone words was the transitional probabilities between tones. In addition to the tone stream, six tone nonword foils were created (see Table 5 ). The procedure was identical to that used in Experiment 2a. While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2. Children listened to the tape for a total of 42 min. At the end of the 42 min, children heard pairs of “word” and “nonword” tone sequences and were asked to choose the sound sequence that sounded more familiar. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing tone sequences derived from familiar children's nursery rhymes presented in the correct or incorrect order (e.g., the tune, without words, from “ Mary Had a Little Lamb ” vs. the tune from “ Lamb Little Mary Had a ”). Following the practice trials, the children were then presented with the 36 test pairs. Again, all of the children were able to successfully complete all of the practice trials.  Experiment 2 Method Participants Thirty children who participated in Experiment 1 were brought back into the lab 6 months later to participate in Experiments 2a and 2b. The children were chosen to be part of a group of age- and nonverbal-IQ-matched groups. This group consisted of 15 children with SLI (ages 8;0–10;11) and 15 age- and nonverbal-IQ-matched (CA-NIQ) controls. The CA-NIQ group did not differ from the SLI group in age, t (28) = 0.35, p = .72, or nonverbal IQ, t (28) = 0.28, p = .77 (see Table 4 ). The children were seen for two visits with an average of 10–14 days between visits. On each visit, children participated in either Experiment 2a or Experiment 2b, with order of participation counterbalanced. Stimuli and Procedures Experiment 2a The stimuli and procedures for Experiment 2a were identical to those of Experiment 1, with the exception that the children listened to the same materials twice, without a break, for 42 continuous min. As in Experiment 1, prior to the testing phase, children were presented with practice trials containing word–nonword pairs derived from words in English (e.g., com-pu-ter vs pu-ter-com ). Following the practice trials, the children were then presented with the test trials from Experiment 1. Again, all of the children were able to successfully complete all of the practice trials, and no children were excluded from the experiment due to their inability to understand the task. Experiment 2b The materials for Experiment 2b were identical to Tone Language 1 from Saffran et al. (1999) . The tone stream was constructed out of 11 pure tones taken from the same octave (starting at middle C within a chromatic set), with the same duration (0.33 s), created using the sine wave generator in SoundEdit 16 (Adobe, San Jose, CA). The tones were combined into groups of three to form six tone words (GG#A, CC#D, D#ED, FCF#, DFE, and ADB). The tone words were not constructed in accordance with the rules of standard musical composition and did not resemble any paradigmatic melodic fragments. Transitional probabilities between tones within words averaged 0.64 (range = 0.25–1.00). In contrast, transitional probabilities between tones spanning word boundaries averaged 0.14 (range = 0.05–0.60). Although these two distributions did overlap, this overlap was rare, occurring for only 3 of the 30 across-word tone instances. The six tones were concatenated together in a random order, with no silent junctures between words, to create six different blocks containing 18 words each. No words occurred twice in a row. The six blocks were, in turn, concatenated together to produce a 7-minute continuous stream of tones. As with the speech stimuli used in Experiments 1 and 2a, there were no acoustic markers of tone-word boundaries. The only consistent cue to the beginning and end of the tone words was the transitional probabilities between tones. In addition to the tone stream, six tone nonword foils were created (see Table 5 ). The procedure was identical to that used in Experiment 2a. While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2. Children listened to the tape for a total of 42 min. At the end of the 42 min, children heard pairs of “word” and “nonword” tone sequences and were asked to choose the sound sequence that sounded more familiar. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing tone sequences derived from familiar children's nursery rhymes presented in the correct or incorrect order (e.g., the tune, without words, from “ Mary Had a Little Lamb ” vs. the tune from “ Lamb Little Mary Had a ”). Following the practice trials, the children were then presented with the 36 test pairs. Again, all of the children were able to successfully complete all of the practice trials. Results The results for the SLI and CA-NIQ groups are presented in Figure 2 . A repeated measures ANCOVA with age and nonverbal IQ as covariates revealed a main effect for group, F (1, 26) = 7.4, p = .003, partial ?2 = .37, ? = .91, across the speech and tone conditions, with overall performance for the children with SLI being poorer than that of their typical language peers. An interaction was also observed where the performance of the children with SLI did not differ from that of the CA-NIQ group in the speech condition (Experiment 2a): F (1, 26) = 2.95, p = .11, partial ?2 = .09, ? = .34. However, the two groups did exhibit significantly different performance in the tone condition (Experiment 2b): F (1, 26) = 12.3, p = .002, partial ?2 = .09, ? = .92. In the speech condition, the mean was 56.2% ( SD = 10%) for the SLI group and 64.4% ( SD = 15%) for the CA-NIQ group, where chance equals 50%. Single-sample t tests (two-tailed) calculated for each group individually indicated that both groups performed significantly better than would be expected by chance: SLI, t (14) = 2.3, p < .05; CA-NIQ, t (14) = 3.74, p < .01. In the tone condition, the mean score for the SLI group was 48% ( SD = 11%) and for the CA-NIQ control group was 66% ( SD = 15%) where chance equals 50%. A single-sample t test (two-tailed) for the SLI group indicated that their performance after 42 min of exposure to the tone stimuli was no different from chance, t (14) = 0.62, p = .54, whereas the CA-NIQ group's performance was again significantly better than chance, t (14) = 4.09, p < .001. In Experiment 1, we observed that, after 21 min of exposure to the speech stream, the CA-NIQ groups' performance was significantly correlated with both expressive and receptive vocabulary. However, we observed no relationship between statistical learning and vocabulary knowledge for the children with SLI after 21 min of exposure. We thus asked whether the increased exposure to the speech stream in Experiment 2a would reveal a relationship between statistical learning and vocabulary knowledge for the children with SLI. A Pearson's correlation (two-tailed) for age, nonverbal IQ, and raw score for the EVT and PPVT-III indicated that the SLI group's statistical word learning performance, after double the exposure to the speech stream, was not significantly correlated with expressive vocabulary, age, or IQ but was significantly correlated with receptive vocabulary ( p < .03; see Table 6 ). In Experiment 1, we also observed that the typically developing children learned all six words after only 21 min of exposure. With doubled exposure, the performance for the CA-NIQ group did not differ from their performance after 21 min of exposure (64%) and 42 min (64%), t (14) = 0.04, p = .96, and they again learned all six words in Experiment 2a. The children with SLI learned 2:6 words at/or approaching a level significantly greater than chance— patubi having a transitional probability of 0.5 ( p < .05) and bupada having a transitional probability of 0.42 ( p = .07). That the children with SLI did not learn any of the words having the highest transitional probabilities suggests, at least on the surface, that even with double the exposure time, they were unable to use transitional probabilities to discover the word boundaries within the stream of speech. However, 10 of the 15 children with SLI had performance that was greater than 50% after double the exposure, whereas 5 of the 15 children with SLI had performance that was at or below 50%. One question is whether the pattern of learning for the children with SLI whose performance was above 50% differed from those whose performance was not above chance. In the 42-min speech condition, the children with SLI with above-chance performance learned five of the six target words at/or approaching a level significantly greater than chance ( dutaba, patubi, bupada, babupu, p < .05; pidabu, p = .09). In contrast, after double the exposure, the remaining children with SLI learned only 2:6 words at a level significantly greater than chance ( dutaba, pidabu, p < .05, vs. tutibu, p = .55; patubi, p = .63; bupada, p = .83; and babupu, p = .72). Thus, it appears that the children with SLI are tracking at least some statistical information in the input. Importantly, however, for the above-chance SLI group, one word was not learned. This word, tutibu ( p = .37), had the second highest transitional probability: 0.75. If the children with SLI were using transitional probability as a cue to discover word boundaries within the speech stream, why then, with double the exposure to the speech stream, were they unable to discover the boundaries for the word having the second highest transitional probability? Analysis of the response patterns of the children revealed that the target/foil test trials where the target and the foil had the identical vowel sequence— tutibu/dupitu —had the highest error rate, with 7 of the 10 children with SLI incorrectly choosing the foil dubitu . For the children to correctly choose the target over the foil, they not only had to track the transitional probabilities in the speech stream during the exposure phase but they also had to have a memory of the target words that contained enough phonological detail to enable them to differentiate the target from the foils during the testing phase. Taken together, the pattern of results for the children with SLI suggests that, with double the exposure, they are able to segment the speech stream to some extent but that their knowledge of the newly learned words may not contain sufficient phonological detail to enable them to differentiate newly learned target words from highly phonologically similar foils. In Experiment 2b, we asked whether the pattern of performance observed for children with SLI in Experiment 2a is unique to speech. Specifically, we used a nonlinguistic task designed to be analogous to the word segmentation task, in which tones are substituted for the syllables in the “words,” generating a continuous stream of tones ( Saffran et al., 1999 ). This task allowed us to ask whether statistical learning outcomes for children with SLI and CA-NIQ controls are the same for speech and for an analogous nonlinguistic task (e.g., tone-word segmentation) after 42 min of exposure. As noted earlier, because the tone language is analogous to the speech stimuli ( Saffran et al., 1996 ), we can compare the children's performance across the two modalities. The results of the ANCOVA discussed previously show that the CA-NIQ group performed above chance in both the speech and tone conditions, whereas performance of the SLI group differed as a function of the input stimuli, with above-chance performance only for the speech stimuli and not for the tone stimuli. In the 42-minute speech condition, the CA-NIQ group was able to learn all six words, and in the 42-minute tone condition, these same children were able to learn five of the six tone sequences at a level of significance greater than chance. Replicating Saffran's (1999) adult results, the one tone sequence not learned by the CA-NIQ group (the ABD tone sequence) had the lowest transitional probability (.37). Although the performance for the SLI group was no different from chance in the 42-minute tone condition, one of the six tone sequences was learned at a level greater than chance (D#ED; p < .05; transitional probability of .67). The results from Experiment 2b show that typically developing children are able to group sequences of auditory “events” in the same manner regardless of whether the input is linguistic (e.g., syllables) or nonlinguistic (e.g., tones). In Saffran et al. (1999) , the adults heard the tone stimuli for a total of 21 min. With twice as much exposure, the typically developing children were able to learn five of the six trisyllabic tone-sequences embedded within the tone stream. However, the children with SLI were less successful with the tone-sequences, with overall performance no different from chance. An important question is whether the children with SLI in Experiments 2a and 2b differed in some fundamental way from those children with SLI in Experiment 1. The children with SLI in Experiments 2a and 2b did not differ from the children with SLI in Experiment 1 in respect to Age, F (1, 49) = 0.32, p = .59; nonverbal IQ, F (1, 49) = 2.5, p = .11; Expressive Language, F (1, 49) = 0.35, p = .56; or Receptive Language, F (1, 49) = .65, p = .42. Thus, differences in age, nonverbal IQ, receptive, and/or expressive language abilities do not account for the differences in performance for the children with SLI in Experiment 1 versus Experiments 2a and 2b. This pattern of results suggests that the increased exposure to the speech stimuli in Experiment 2a played a key role in the performance of the children with SLI. A second important question is whether the children whose performance was above chance differ in some fundamental way from those children whose performance was not. In Experiment 1, the children with SLI whose performance was above chance ( n = 17) did not differ from the children with SLI whose performance was below chance ( n = 18) in Age, F (1, 34) = 0.0, p = .99; nonverbal IQ, F (1, 34) = 0.35, p = .55; Expressive Language, F (1, 34) = 0.34, p = .55; or Receptive Language, F (1, 34) = 0.32, p = .57. The typically developing children whose performance was above chance ( n = 26) also did not differ from the typically children whose performance was below chance in Age, F (1, 76) = 1.6, p = .20; nonverbal IQ, F (1, 76) = 0.64, p = .42; or Expressive Language, F (1, 76) = 0.81, p = .36. Similarly, in Experiment 2a, the children with SLI whose performance was above chance ( n = 10) did not differ from the children with SLI whose performance was below chance ( n = 5) for Age, F (1, 14) = 0.53, p = .47; Expressive Language, F (1, 14) = 0.0, p = .95; or Receptive Language, F (1, 34) = 0.16, p = .69, but did differ in nonverbal IQ, F (1, 14) = 5.7, p = .03. Although non-verbal IQ was higher for the children with SLI whose performance was above chance than for the children whose performance was below chance, it was not significantly correlated with statistical word learning performance. For the CA-NIQ group, 13:15 children had performance that was above chance, precluding statistical analysis. In Experiment 2b, the children with SLI whose performance was above 50% ( n = 5) did not differ from the children whose performance was below 50% ( n = 10) with respect to Age, F (1, 14) = 0.79, p = .38; nonverbal IQ, F (1, 14) = 0.0, p = .98; Expressive Language, F (1, 14) = 0.18, p = .67; or Receptive Language, F (1, 14) = 3.9, p = .07. For the CA-NIQ group, the children whose performance was above 50% ( n = 11) also did not differ from the children whose performance was below 50% for Age, F (1, 13) = 1.3, p = .27; nonverbal IQ, F (1, 13) = 0.05, p = .95; or Expressive Language, F (1, 13) = 0.98, p = .90. At this time, given the available behavioral data, it is not clear what factors differentiate the children who were able to segment the input using statistical sequential information implicitly from children who were unable to segment the speech stream. General Discussion In these studies, we asked if children with SLI are both sensitive to the quantitative aspects of distributional information in a language corpus and able to store this information to a degree that supports vocabulary development—specifically, whether they are able to implicitly track statistical information to discover word boundaries in running speech. We also asked if this ability is related to frequency or degree of exposure and to vocabulary knowledge, and if it appears to be a domain-general or domain-specific skill. The findings from our studies support the hypothesis that typically developing children are equipped with computational tools that can harness statistical information to detect word boundaries, that this ability is related to measures of receptive and expressive word knowledge, and that it appears to be a domain-general ability being broadly similar across speech and tone conditions. The findings for the children with SLI are less clear cut and suggest that the computational mechanism that allows unimpaired children to use statistical information to discover word boundaries is not as effectively functional in children with SLI. Although with double exposure, the children with SLI were able to track the transitional probabilities in the speech condition, they still had difficulty. Specifically, they were unsuccessful at differentiating newly learned target words from highly similar-sounding foils during the testing phase of the task. One possibility is that children with SLI were unable to retain in memory a sufficiently detailed phonological form of the target words. This is consistent with recent work suggesting that the phonological representations of words in the lexicons of children with SLI are more holistic and less well specified than those of typically developing children ( Mainela-Arnold, Evans, & Coady, 2008 ). If one takes the view that representation and processing of all aspects of language (e.g., speech, words, and grammar) are dependent on a computational system where learning takes place over distributed representations, occurring through changes in the strength of these representations as a result of statistical contingencies in the environment (e.g., Elman et al., 1996 ), then the pattern of performance for the children with SLI suggests that even with double the exposure, the representations of newly learned words may be phonologically underspecified. The difficulties that the children with SLI experienced segmenting the speech stream may also have been compounded by the nature of speech stimuli itself, as it was impoverished with respect to the cues that are available for children to discover word boundaries in naturally occurring speech. In natural speech, a variety of cues, such as prosody and coarticulation, occur in conjunction with transitional probabilities, aiding the listener in the discovery of word boundaries. Not only were these redundant cues unavailable for the children in the speech condition, but the speech stimulus was synthesized speech, possibly adding to the difficulties experienced by the children with SLI. There is a growing body of evidence that shows that children with SLI are significantly impaired across a range of speech perception tasks when the stimuli consist of synthesized speech in contrast to natural speech ( Coady, Kluender, & Evans, 2005 ; Coady, Evans, Mainela-Arnold, & Kluender, 2007 ; Evans, Viele, & Kass, 2002 ; Joanisse et al., 2000 ). The results of Experiment 2b indicate, however, that the poor performance of the children with SLI in Experiments 1 and 2a was not due solely to the degraded speech stimuli. Experiment 2b consisted of highly perceptible tones, yet the children with SLI were still unable to discover the tone-word boundaries. Taken together with prior research ( Saffran et al., 1997 ), these studies make it clear that implicit learning is a robust phenomenon in typically developing children. Specifically, typically developing children can track transitional probabilities from a stream of speech with a level of efficiency and specificity that allows them to not only learn words having varying transitional probabilities (e.g., 0.37–1.0) but also to differentiate these newly learned words from highly similar-sounding foils during testing despite the degraded nature of the synthetic speech stimuli. The difficulty in sequence learning by children in the SLI group suggests that (a) difficulties in tracking statistical properties of sounds for children with SLI is not limited to speech and (b) the nonlinguistic materials were actually more difficult for the children with SLI than the linguistic materials, perhaps due to the relative novelty of the tone sequences. In any event, these findings only highlight the robustness of the implicit learning mechanism in typical children and the fragile and ineffective nature of this mechanism in children with SLI. On the surface, the difference in the performance of the children with SLI in the 42-min speech and in the speech and tone conditions suggests that implicit learning is not a domain-general mechanism in children with SLI. However, the speech and tone conditions differed in important ways that may have resulted in different performance in the two conditions. First, all of the children in Experiments 2a and 2b had prior exposure to the speech stimuli because of their prior participation in Experiment 1. Thus, the children's exposure time to the speech stimuli, over the span of Experiments 1 and 2a, was actually 63 min. It could be that the children with SLI actually require not 40+ but 60+ min of exposure to the speech stream before they are able to discover the word boundaries. If the children had received 60+ min of exposure to the tone language, their performance in the speech and tone conditions may have been similar. Note, however, that there were 6 months between the two experiments. For Experiment 1 participation to have affected Experiment 2 performance, the children would have had to maintain these representations over a long time interval. A second important difference is that there is overlap in the transitional probabilities within and across the word boundaries in the tone stimuli not present in the speech stimuli. This overlap is extremely rare, occurring for only 3 of the 30 across-word tone-pairs where the probability was .6 (when the words GG#A happened to be followed by DFE, as the cross-boundary sequence AD also occurred in the word ADB). The occurrence of such overlaps may have made segmentation more difficult in the tone language as compared with the speech language. However, recall that the typically developing children showed equivalent performance in the tone and speech conditions in Experiment 2. There is, thus, some factor that made the tone condition disproportionately harder for the children with SLI compared with their typically developing peers. Importantly, however, there were children with SLI whose performance was above chance in all three experiments. An important question is whether these children differed in some fundamental way from the children whose performance was not above chance. With the exception of nonverbal IQ in Experiment 2a, which was not significantly correlated with statistical word learning abilities, the children did not differ by age, IQ, or receptive/ expressive vocabulary or language abilities. The fact that differences in intelligence, age, or language did not account for differences in statistical word learning abilities suggests that the children differed in some other fundamental way. One possibility is that the children differed in their working memory capacity and/or attentional resources. Studies comparing implicit learning in high- versus low-load conditions for adults show that statistical word learning performance is significantly poorer when working memory/attentional resources are reduced and are not available to be dedicated to the discovery of word boundaries ( Ludden & Gupta, 2000 ). Children with SLI have reduced working memory capacity as compared with that of their peers (cf. Coady & Evans, 2008 ; Graf Estes, Evans, & Else-Quest, 2007 ; Leonard et al., 2007 ; Montgomery & Evans, 2009 ). Moreover, there is a growing body of evidence suggesting that children with SLI may also have problems with selective auditory attention, especially at the earliest stages of sensory processing (e.g., Helzer, Champlin, & Gillam, 1996 ; Montgomery, Evans, & Gillam, 2009 ; Stevens, Sanders, & Neville, 2006 ; Uwer, Albrecht, & von Suchodoletz, 2002 ). It may be that the children differed in attention or working memory abilities and this played a critical role in the statistical word learning abilities in children, which is clearly an important issue that warrants further investigation. Another interesting outcome in Experiment 1 was that statistical learning was significantly correlated with age for the typical children (aged 5;7–12;10). Given that very young children and even infants succeed on statistical word learning tasks, this is a somewhat curious finding. There are, however, differences both in the complexity of the exposure languages and the methodologies used to measure statistical learning in infants and adults that may account for differences in implicit learning skills of infants, children, and adults. In infant studies, exposure languages are generally much less complex than adult languages. For example, Graf Estes et al. (2007) used a language consisting of four CVCV target words. This contrasts sharply with our study and others, where the language consisted of six CVCVCV target words. In addition to differences in the complexity of the exposure languages, learning in infant studies is often measured with paradigms such as preferential looking, which is presumably less cognitively demanding than the two-alternative forced-choice paradigm used in our study. In light of the role that working memory capacity and attention has on statistical learning ( Ludden & Gupta, 2000 ), this mechanism may be sensitive to and influenced by developmental changes in attention and working memory capacity. The differences in the individual words learned by the children with and without SLI as well as the differences in the relationships between statistical word learning and expressive and receptive vocabulary in the two groups indicate that the pattern of learning by the children with SLI differs somewhat from that of typically developing children. Tomblin et al. (2007) also observed differences in the pattern of sequence learning in the children with SLI when compared with their NL controls. Specifically, their NL control group exhibited an initial rapid rate of learning followed by a gradual approach toward an asymptote. In contrast, the shape of the learning curve for the SLI group in Tomblin et al.'s study consisted of a period of slowed responses prior to the rapid onset of learning but no evidence of an asymptote by the end of the training. Performance on the last block of trials did not differ between the SLI and NL controls. What is interesting is the slowing in reaction times for the SLI group after the initial block of pattern sequence trials. Tomblin et al. suggest that in the early stages of learning the new sequences, the representations are initially unstable in children with SLI as compared with NL children. Several studies of lexical and sentence processing in individuals with SLI suggest that there may be less suppression of competing candidate representations than observed in typically developing children ( McMurray, Samuelson, Lee, & Tomblin, 2006 ; Mainela-Arnold, Evans, & Coady, 2007 , 2008 ). Tomblin et al. suggest that for their individuals with SLI, multiple candidate targets are initially generated, with subsequent instability as these candidates compete for priority as the dominant representation. This instability is resolved only after sufficient training. Although our study does not allow for investigation of the stability of the representations of the single word/tone sequence that was learned by the children with SLI, our findings are consistent with Tomblin et al.'s work, strongly supporting the contention that the learning challenges for children with SLI are not limited to linguistic sequences (e.g., Tomblin et al., 2007 ). The term implicit learning characterizes a heterogeneous collection of learning capacities that, in addition to perceptual motor learning (e.g., procedural memory), includes probabilistic learning of categories, statistical learning, artificial grammar learning, and prototype abstraction ( Perruchet & Pacton, 2006 ; Squire & Zola, 1996 ). The findings for our experiments, taken together with the work by Tomblin et al. (2007) and Plante et al. (2002) suggest that Ullman's procedural learning deficit hypothesis of SLI may need to be extended to include deficits in other domains of implicit learning in children with SLI. Ullman's DP model assumes that the acquisition and use of the form-meaning–associated aspects of language (e.g., lexicon) are supported by the declarative memory system. Our results indicate that aspects of vocabulary learning are also supported by the implicit system, in the earliest stages in word learning where infants begin to discover word boundaries within the stream of speech around them. The findings from the current study also shed light on our understanding of the domain specificity of implicit learning and suggest that even when the statistical structure of the input is identical, differences in the features of the stimuli (e.g., speech vs. tones) result in different learning patterns in typically developing children. Finally, these results suggest that future studies need to consider implicit learning across the visual, auditory, and perceptual motor modalities in order to more carefully characterize the challenges facing learners with SLI.  Experiment 2 Method Participants Thirty children who participated in Experiment 1 were brought back into the lab 6 months later to participate in Experiments 2a and 2b. The children were chosen to be part of a group of age- and nonverbal-IQ-matched groups. This group consisted of 15 children with SLI (ages 8;0–10;11) and 15 age- and nonverbal-IQ-matched (CA-NIQ) controls. The CA-NIQ group did not differ from the SLI group in age, t (28) = 0.35, p = .72, or nonverbal IQ, t (28) = 0.28, p = .77 (see Table 4 ). The children were seen for two visits with an average of 10–14 days between visits. On each visit, children participated in either Experiment 2a or Experiment 2b, with order of participation counterbalanced. Stimuli and Procedures Experiment 2a The stimuli and procedures for Experiment 2a were identical to those of Experiment 1, with the exception that the children listened to the same materials twice, without a break, for 42 continuous min. As in Experiment 1, prior to the testing phase, children were presented with practice trials containing word–nonword pairs derived from words in English (e.g., com-pu-ter vs pu-ter-com ). Following the practice trials, the children were then presented with the test trials from Experiment 1. Again, all of the children were able to successfully complete all of the practice trials, and no children were excluded from the experiment due to their inability to understand the task. Experiment 2b The materials for Experiment 2b were identical to Tone Language 1 from Saffran et al. (1999) . The tone stream was constructed out of 11 pure tones taken from the same octave (starting at middle C within a chromatic set), with the same duration (0.33 s), created using the sine wave generator in SoundEdit 16 (Adobe, San Jose, CA). The tones were combined into groups of three to form six tone words (GG#A, CC#D, D#ED, FCF#, DFE, and ADB). The tone words were not constructed in accordance with the rules of standard musical composition and did not resemble any paradigmatic melodic fragments. Transitional probabilities between tones within words averaged 0.64 (range = 0.25–1.00). In contrast, transitional probabilities between tones spanning word boundaries averaged 0.14 (range = 0.05–0.60). Although these two distributions did overlap, this overlap was rare, occurring for only 3 of the 30 across-word tone instances. The six tones were concatenated together in a random order, with no silent junctures between words, to create six different blocks containing 18 words each. No words occurred twice in a row. The six blocks were, in turn, concatenated together to produce a 7-minute continuous stream of tones. As with the speech stimuli used in Experiments 1 and 2a, there were no acoustic markers of tone-word boundaries. The only consistent cue to the beginning and end of the tone words was the transitional probabilities between tones. In addition to the tone stream, six tone nonword foils were created (see Table 5 ). The procedure was identical to that used in Experiment 2a. While the tape of the continuous speech stream played in the background, children were asked to draw a picture using a computer-coloring program, Kid Pix 2. Children listened to the tape for a total of 42 min. At the end of the 42 min, children heard pairs of “word” and “nonword” tone sequences and were asked to choose the sound sequence that sounded more familiar. Prior to the testing phase, to ensure that the children understood the task, children were presented with practice trials containing tone sequences derived from familiar children's nursery rhymes presented in the correct or incorrect order (e.g., the tune, without words, from “ Mary Had a Little Lamb ” vs. the tune from “ Lamb Little Mary Had a ”). Following the practice trials, the children were then presented with the 36 test pairs. Again, all of the children were able to successfully complete all of the practice trials. Results The results for the SLI and CA-NIQ groups are presented in Figure 2 . A repeated measures ANCOVA with age and nonverbal IQ as covariates revealed a main effect for group, F (1, 26) = 7.4, p = .003, partial ?2 = .37, ? = .91, across the speech and tone conditions, with overall performance for the children with SLI being poorer than that of their typical language peers. An interaction was also observed where the performance of the children with SLI did not differ from that of the CA-NIQ group in the speech condition (Experiment 2a): F (1, 26) = 2.95, p = .11, partial ?2 = .09, ? = .34. However, the two groups did exhibit significantly different performance in the tone condition (Experiment 2b): F (1, 26) = 12.3, p = .002, partial ?2 = .09, ? = .92. In the speech condition, the mean was 56.2% ( SD = 10%) for the SLI group and 64.4% ( SD = 15%) for the CA-NIQ group, where chance equals 50%. Single-sample t tests (two-tailed) calculated for each group individually indicated that both groups performed significantly better than would be expected by chance: SLI, t (14) = 2.3, p < .05; CA-NIQ, t (14) = 3.74, p < .01. In the tone condition, the mean score for the SLI group was 48% ( SD = 11%) and for the CA-NIQ control group was 66% ( SD = 15%) where chance equals 50%. A single-sample t test (two-tailed) for the SLI group indicated that their performance after 42 min of exposure to the tone stimuli was no different from chance, t (14) = 0.62, p = .54, whereas the CA-NIQ group's performance was again significantly better than chance, t (14) = 4.09, p < .001. In Experiment 1, we observed that, after 21 min of exposure to the speech stream, the CA-NIQ groups' performance was significantly correlated with both expressive and receptive vocabulary. However, we observed no relationship between statistical learning and vocabulary knowledge for the children with SLI after 21 min of exposure. We thus asked whether the increased exposure to the speech stream in Experiment 2a would reveal a relationship between statistical learning and vocabulary knowledge for the children with SLI. A Pearson's correlation (two-tailed) for age, nonverbal IQ, and raw score for the EVT and PPVT-III indicated that the SLI group's statistical word learning performance, after double the exposure to the speech stream, was not significantly correlated with expressive vocabulary, age, or IQ but was significantly correlated with receptive vocabulary ( p < .03; see Table 6 ). In Experiment 1, we also observed that the typically developing children learned all six words after only 21 min of exposure. With doubled exposure, the performance for the CA-NIQ group did not differ from their performance after 21 min of exposure (64%) and 42 min (64%), t (14) = 0.04, p = .96, and they again learned all six words in Experiment 2a. The children with SLI learned 2:6 words at/or approaching a level significantly greater than chance— patubi having a transitional probability of 0.5 ( p < .05) and bupada having a transitional probability of 0.42 ( p = .07). That the children with SLI did not learn any of the words having the highest transitional probabilities suggests, at least on the surface, that even with double the exposure time, they were unable to use transitional probabilities to discover the word boundaries within the stream of speech. However, 10 of the 15 children with SLI had performance that was greater than 50% after double the exposure, whereas 5 of the 15 children with SLI had performance that was at or below 50%. One question is whether the pattern of learning for the children with SLI whose performance was above 50% differed from those whose performance was not above chance. In the 42-min speech condition, the children with SLI with above-chance performance learned five of the six target words at/or approaching a level significantly greater than chance ( dutaba, patubi, bupada, babupu, p < .05; pidabu, p = .09). In contrast, after double the exposure, the remaining children with SLI learned only 2:6 words at a level significantly greater than chance ( dutaba, pidabu, p < .05, vs. tutibu, p = .55; patubi, p = .63; bupada, p = .83; and babupu, p = .72). Thus, it appears that the children with SLI are tracking at least some statistical information in the input. Importantly, however, for the above-chance SLI group, one word was not learned. This word, tutibu ( p = .37), had the second highest transitional probability: 0.75. If the children with SLI were using transitional probability as a cue to discover word boundaries within the speech stream, why then, with double the exposure to the speech stream, were they unable to discover the boundaries for the word having the second highest transitional probability? Analysis of the response patterns of the children revealed that the target/foil test trials where the target and the foil had the identical vowel sequence— tutibu/dupitu —had the highest error rate, with 7 of the 10 children with SLI incorrectly choosing the foil dubitu . For the children to correctly choose the target over the foil, they not only had to track the transitional probabilities in the speech stream during the exposure phase but they also had to have a memory of the target words that contained enough phonological detail to enable them to differentiate the target from the foils during the testing phase. Taken together, the pattern of results for the children with SLI suggests that, with double the exposure, they are able to segment the speech stream to some extent but that their knowledge of the newly learned words may not contain sufficient phonological detail to enable them to differentiate newly learned target words from highly phonologically similar foils. In Experiment 2b, we asked whether the pattern of performance observed for children with SLI in Experiment 2a is unique to speech. Specifically, we used a nonlinguistic task designed to be analogous to the word segmentation task, in which tones are substituted for the syllables in the “words,” generating a continuous stream of tones ( Saffran et al., 1999 ). This task allowed us to ask whether statistical learning outcomes for children with SLI and CA-NIQ controls are the same for speech and for an analogous nonlinguistic task (e.g., tone-word segmentation) after 42 min of exposure. As noted earlier, because the tone language is analogous to the speech stimuli ( Saffran et al., 1996 ), we can compare the children's performance across the two modalities. The results of the ANCOVA discussed previously show that the CA-NIQ group performed above chance in both the speech and tone conditions, whereas performance of the SLI group differed as a function of the input stimuli, with above-chance performance only for the speech stimuli and not for the tone stimuli. In the 42-minute speech condition, the CA-NIQ group was able to learn all six words, and in the 42-minute tone condition, these same children were able to learn five of the six tone sequences at a level of significance greater than chance. Replicating Saffran's (1999) adult results, the one tone sequence not learned by the CA-NIQ group (the ABD tone sequence) had the lowest transitional probability (.37). Although the performance for the SLI group was no different from chance in the 42-minute tone condition, one of the six tone sequences was learned at a level greater than chance (D#ED; p < .05; transitional probability of .67). The results from Experiment 2b show that typically developing children are able to group sequences of auditory “events” in the same manner regardless of whether the input is linguistic (e.g., syllables) or nonlinguistic (e.g., tones). In Saffran et al. (1999) , the adults heard the tone stimuli for a total of 21 min. With twice as much exposure, the typically developing children were able to learn five of the six trisyllabic tone-sequences embedded within the tone stream. However, the children with SLI were less successful with the tone-sequences, with overall performance no different from chance. An important question is whether the children with SLI in Experiments 2a and 2b differed in some fundamental way from those children with SLI in Experiment 1. The children with SLI in Experiments 2a and 2b did not differ from the children with SLI in Experiment 1 in respect to Age, F (1, 49) = 0.32, p = .59; nonverbal IQ, F (1, 49) = 2.5, p = .11; Expressive Language, F (1, 49) = 0.35, p = .56; or Receptive Language, F (1, 49) = .65, p = .42. Thus, differences in age, nonverbal IQ, receptive, and/or expressive language abilities do not account for the differences in performance for the children with SLI in Experiment 1 versus Experiments 2a and 2b. This pattern of results suggests that the increased exposure to the speech stimuli in Experiment 2a played a key role in the performance of the children with SLI. A second important question is whether the children whose performance was above chance differ in some fundamental way from those children whose performance was not. In Experiment 1, the children with SLI whose performance was above chance ( n = 17) did not differ from the children with SLI whose performance was below chance ( n = 18) in Age, F (1, 34) = 0.0, p = .99; nonverbal IQ, F (1, 34) = 0.35, p = .55; Expressive Language, F (1, 34) = 0.34, p = .55; or Receptive Language, F (1, 34) = 0.32, p = .57. The typically developing children whose performance was above chance ( n = 26) also did not differ from the typically children whose performance was below chance in Age, F (1, 76) = 1.6, p = .20; nonverbal IQ, F (1, 76) = 0.64, p = .42; or Expressive Language, F (1, 76) = 0.81, p = .36. Similarly, in Experiment 2a, the children with SLI whose performance was above chance ( n = 10) did not differ from the children with SLI whose performance was below chance ( n = 5) for Age, F (1, 14) = 0.53, p = .47; Expressive Language, F (1, 14) = 0.0, p = .95; or Receptive Language, F (1, 34) = 0.16, p = .69, but did differ in nonverbal IQ, F (1, 14) = 5.7, p = .03. Although non-verbal IQ was higher for the children with SLI whose performance was above chance than for the children whose performance was below chance, it was not significantly correlated with statistical word learning performance. For the CA-NIQ group, 13:15 children had performance that was above chance, precluding statistical analysis. In Experiment 2b, the children with SLI whose performance was above 50% ( n = 5) did not differ from the children whose performance was below 50% ( n = 10) with respect to Age, F (1, 14) = 0.79, p = .38; nonverbal IQ, F (1, 14) = 0.0, p = .98; Expressive Language, F (1, 14) = 0.18, p = .67; or Receptive Language, F (1, 14) = 3.9, p = .07. For the CA-NIQ group, the children whose performance was above 50% ( n = 11) also did not differ from the children whose performance was below 50% for Age, F (1, 13) = 1.3, p = .27; nonverbal IQ, F (1, 13) = 0.05, p = .95; or Expressive Language, F (1, 13) = 0.98, p = .90. At this time, given the available behavioral data, it is not clear what factors differentiate the children who were able to segment the input using statistical sequential information implicitly from children who were unable to segment the speech stream. General Discussion In these studies, we asked if children with SLI are both sensitive to the quantitative aspects of distributional information in a language corpus and able to store this information to a degree that supports vocabulary development—specifically, whether they are able to implicitly track statistical information to discover word boundaries in running speech. We also asked if this ability is related to frequency or degree of exposure and to vocabulary knowledge, and if it appears to be a domain-general or domain-specific skill. The findings from our studies support the hypothesis that typically developing children are equipped with computational tools that can harness statistical information to detect word boundaries, that this ability is related to measures of receptive and expressive word knowledge, and that it appears to be a domain-general ability being broadly similar across speech and tone conditions. The findings for the children with SLI are less clear cut and suggest that the computational mechanism that allows unimpaired children to use statistical information to discover word boundaries is not as effectively functional in children with SLI. Although with double exposure, the children with SLI were able to track the transitional probabilities in the speech condition, they still had difficulty. Specifically, they were unsuccessful at differentiating newly learned target words from highly similar-sounding foils during the testing phase of the task. One possibility is that children with SLI were unable to retain in memory a sufficiently detailed phonological form of the target words. This is consistent with recent work suggesting that the phonological representations of words in the lexicons of children with SLI are more holistic and less well specified than those of typically developing children ( Mainela-Arnold, Evans, & Coady, 2008 ). If one takes the view that representation and processing of all aspects of language (e.g., speech, words, and grammar) are dependent on a computational system where learning takes place over distributed representations, occurring through changes in the strength of these representations as a result of statistical contingencies in the environment (e.g., Elman et al., 1996 ), then the pattern of performance for the children with SLI suggests that even with double the exposure, the representations of newly learned words may be phonologically underspecified. The difficulties that the children with SLI experienced segmenting the speech stream may also have been compounded by the nature of speech stimuli itself, as it was impoverished with respect to the cues that are available for children to discover word boundaries in naturally occurring speech. In natural speech, a variety of cues, such as prosody and coarticulation, occur in conjunction with transitional probabilities, aiding the listener in the discovery of word boundaries. Not only were these redundant cues unavailable for the children in the speech condition, but the speech stimulus was synthesized speech, possibly adding to the difficulties experienced by the children with SLI. There is a growing body of evidence that shows that children with SLI are significantly impaired across a range of speech perception tasks when the stimuli consist of synthesized speech in contrast to natural speech ( Coady, Kluender, & Evans, 2005 ; Coady, Evans, Mainela-Arnold, & Kluender, 2007 ; Evans, Viele, & Kass, 2002 ; Joanisse et al., 2000 ). The results of Experiment 2b indicate, however, that the poor performance of the children with SLI in Experiments 1 and 2a was not due solely to the degraded speech stimuli. Experiment 2b consisted of highly perceptible tones, yet the children with SLI were still unable to discover the tone-word boundaries. Taken together with prior research ( Saffran et al., 1997 ), these studies make it clear that implicit learning is a robust phenomenon in typically developing children. Specifically, typically developing children can track transitional probabilities from a stream of speech with a level of efficiency and specificity that allows them to not only learn words having varying transitional probabilities (e.g., 0.37–1.0) but also to differentiate these newly learned words from highly similar-sounding foils during testing despite the degraded nature of the synthetic speech stimuli. The difficulty in sequence learning by children in the SLI group suggests that (a) difficulties in tracking statistical properties of sounds for children with SLI is not limited to speech and (b) the nonlinguistic materials were actually more difficult for the children with SLI than the linguistic materials, perhaps due to the relative novelty of the tone sequences. In any event, these findings only highlight the robustness of the implicit learning mechanism in typical children and the fragile and ineffective nature of this mechanism in children with SLI. On the surface, the difference in the performance of the children with SLI in the 42-min speech and in the speech and tone conditions suggests that implicit learning is not a domain-general mechanism in children with SLI. However, the speech and tone conditions differed in important ways that may have resulted in different performance in the two conditions. First, all of the children in Experiments 2a and 2b had prior exposure to the speech stimuli because of their prior participation in Experiment 1. Thus, the children's exposure time to the speech stimuli, over the span of Experiments 1 and 2a, was actually 63 min. It could be that the children with SLI actually require not 40+ but 60+ min of exposure to the speech stream before they are able to discover the word boundaries. If the children had received 60+ min of exposure to the tone language, their performance in the speech and tone conditions may have been similar. Note, however, that there were 6 months between the two experiments. For Experiment 1 participation to have affected Experiment 2 performance, the children would have had to maintain these representations over a long time interval. A second important difference is that there is overlap in the transitional probabilities within and across the word boundaries in the tone stimuli not present in the speech stimuli. This overlap is extremely rare, occurring for only 3 of the 30 across-word tone-pairs where the probability was .6 (when the words GG#A happened to be followed by DFE, as the cross-boundary sequence AD also occurred in the word ADB). The occurrence of such overlaps may have made segmentation more difficult in the tone language as compared with the speech language. However, recall that the typically developing children showed equivalent performance in the tone and speech conditions in Experiment 2. There is, thus, some factor that made the tone condition disproportionately harder for the children with SLI compared with their typically developing peers. Importantly, however, there were children with SLI whose performance was above chance in all three experiments. An important question is whether these children differed in some fundamental way from the children whose performance was not above chance. With the exception of nonverbal IQ in Experiment 2a, which was not significantly correlated with statistical word learning abilities, the children did not differ by age, IQ, or receptive/ expressive vocabulary or language abilities. The fact that differences in intelligence, age, or language did not account for differences in statistical word learning abilities suggests that the children differed in some other fundamental way. One possibility is that the children differed in their working memory capacity and/or attentional resources. Studies comparing implicit learning in high- versus low-load conditions for adults show that statistical word learning performance is significantly poorer when working memory/attentional resources are reduced and are not available to be dedicated to the discovery of word boundaries ( Ludden & Gupta, 2000 ). Children with SLI have reduced working memory capacity as compared with that of their peers (cf. Coady & Evans, 2008 ; Graf Estes, Evans, & Else-Quest, 2007 ; Leonard et al., 2007 ; Montgomery & Evans, 2009 ). Moreover, there is a growing body of evidence suggesting that children with SLI may also have problems with selective auditory attention, especially at the earliest stages of sensory processing (e.g., Helzer, Champlin, & Gillam, 1996 ; Montgomery, Evans, & Gillam, 2009 ; Stevens, Sanders, & Neville, 2006 ; Uwer, Albrecht, & von Suchodoletz, 2002 ). It may be that the children differed in attention or working memory abilities and this played a critical role in the statistical word learning abilities in children, which is clearly an important issue that warrants further investigation. Another interesting outcome in Experiment 1 was that statistical learning was significantly correlated with age for the typical children (aged 5;7–12;10). Given that very young children and even infants succeed on statistical word learning tasks, this is a somewhat curious finding. There are, however, differences both in the complexity of the exposure languages and the methodologies used to measure statistical learning in infants and adults that may account for differences in implicit learning skills of infants, children, and adults. In infant studies, exposure languages are generally much less complex than adult languages. For example, Graf Estes et al. (2007) used a language consisting of four CVCV target words. This contrasts sharply with our study and others, where the language consisted of six CVCVCV target words. In addition to differences in the complexity of the exposure languages, learning in infant studies is often measured with paradigms such as preferential looking, which is presumably less cognitively demanding than the two-alternative forced-choice paradigm used in our study. In light of the role that working memory capacity and attention has on statistical learning ( Ludden & Gupta, 2000 ), this mechanism may be sensitive to and influenced by developmental changes in attention and working memory capacity. The differences in the individual words learned by the children with and without SLI as well as the differences in the relationships between statistical word learning and expressive and receptive vocabulary in the two groups indicate that the pattern of learning by the children with SLI differs somewhat from that of typically developing children. Tomblin et al. (2007) also observed differences in the pattern of sequence learning in the children with SLI when compared with their NL controls. Specifically, their NL control group exhibited an initial rapid rate of learning followed by a gradual approach toward an asymptote. In contrast, the shape of the learning curve for the SLI group in Tomblin et al.'s study consisted of a period of slowed responses prior to the rapid onset of learning but no evidence of an asymptote by the end of the training. Performance on the last block of trials did not differ between the SLI and NL controls. What is interesting is the slowing in reaction times for the SLI group after the initial block of pattern sequence trials. Tomblin et al. suggest that in the early stages of learning the new sequences, the representations are initially unstable in children with SLI as compared with NL children. Several studies of lexical and sentence processing in individuals with SLI suggest that there may be less suppression of competing candidate representations than observed in typically developing children ( McMurray, Samuelson, Lee, & Tomblin, 2006 ; Mainela-Arnold, Evans, & Coady, 2007 , 2008 ). Tomblin et al. suggest that for their individuals with SLI, multiple candidate targets are initially generated, with subsequent instability as these candidates compete for priority as the dominant representation. This instability is resolved only after sufficient training. Although our study does not allow for investigation of the stability of the representations of the single word/tone sequence that was learned by the children with SLI, our findings are consistent with Tomblin et al.'s work, strongly supporting the contention that the learning challenges for children with SLI are not limited to linguistic sequences (e.g., Tomblin et al., 2007 ). The term implicit learning characterizes a heterogeneous collection of learning capacities that, in addition to perceptual motor learning (e.g., procedural memory), includes probabilistic learning of categories, statistical learning, artificial grammar learning, and prototype abstraction ( Perruchet & Pacton, 2006 ; Squire & Zola, 1996 ). The findings for our experiments, taken together with the work by Tomblin et al. (2007) and Plante et al. (2002) suggest that Ullman's procedural learning deficit hypothesis of SLI may need to be extended to include deficits in other domains of implicit learning in children with SLI. Ullman's DP model assumes that the acquisition and use of the form-meaning–associated aspects of language (e.g., lexicon) are supported by the declarative memory system. Our results indicate that aspects of vocabulary learning are also supported by the implicit system, in the earliest stages in word learning where infants begin to discover word boundaries within the stream of speech around them. The findings from the current study also shed light on our understanding of the domain specificity of implicit learning and suggest that even when the statistical structure of the input is identical, differences in the features of the stimuli (e.g., speech vs. tones) result in different learning patterns in typically developing children. Finally, these results suggest that future studies need to consider implicit learning across the visual, auditory, and perceptual motor modalities in order to more carefully characterize the challenges facing learners with SLI.  Results The results for the SLI and CA-NIQ groups are presented in Figure 2 . A repeated measures ANCOVA with age and nonverbal IQ as covariates revealed a main effect for group, F (1, 26) = 7.4, p = .003, partial ?2 = .37, ? = .91, across the speech and tone conditions, with overall performance for the children with SLI being poorer than that of their typical language peers. An interaction was also observed where the performance of the children with SLI did not differ from that of the CA-NIQ group in the speech condition (Experiment 2a): F (1, 26) = 2.95, p = .11, partial ?2 = .09, ? = .34. However, the two groups did exhibit significantly different performance in the tone condition (Experiment 2b): F (1, 26) = 12.3, p = .002, partial ?2 = .09, ? = .92. In the speech condition, the mean was 56.2% ( SD = 10%) for the SLI group and 64.4% ( SD = 15%) for the CA-NIQ group, where chance equals 50%. Single-sample t tests (two-tailed) calculated for each group individually indicated that both groups performed significantly better than would be expected by chance: SLI, t (14) = 2.3, p < .05; CA-NIQ, t (14) = 3.74, p < .01. In the tone condition, the mean score for the SLI group was 48% ( SD = 11%) and for the CA-NIQ control group was 66% ( SD = 15%) where chance equals 50%. A single-sample t test (two-tailed) for the SLI group indicated that their performance after 42 min of exposure to the tone stimuli was no different from chance, t (14) = 0.62, p = .54, whereas the CA-NIQ group's performance was again significantly better than chance, t (14) = 4.09, p < .001. In Experiment 1, we observed that, after 21 min of exposure to the speech stream, the CA-NIQ groups' performance was significantly correlated with both expressive and receptive vocabulary. However, we observed no relationship between statistical learning and vocabulary knowledge for the children with SLI after 21 min of exposure. We thus asked whether the increased exposure to the speech stream in Experiment 2a would reveal a relationship between statistical learning and vocabulary knowledge for the children with SLI. A Pearson's correlation (two-tailed) for age, nonverbal IQ, and raw score for the EVT and PPVT-III indicated that the SLI group's statistical word learning performance, after double the exposure to the speech stream, was not significantly correlated with expressive vocabulary, age, or IQ but was significantly correlated with receptive vocabulary ( p < .03; see Table 6 ). In Experiment 1, we also observed that the typically developing children learned all six words after only 21 min of exposure. With doubled exposure, the performance for the CA-NIQ group did not differ from their performance after 21 min of exposure (64%) and 42 min (64%), t (14) = 0.04, p = .96, and they again learned all six words in Experiment 2a. The children with SLI learned 2:6 words at/or approaching a level significantly greater than chance— patubi having a transitional probability of 0.5 ( p < .05) and bupada having a transitional probability of 0.42 ( p = .07). That the children with SLI did not learn any of the words having the highest transitional probabilities suggests, at least on the surface, that even with double the exposure time, they were unable to use transitional probabilities to discover the word boundaries within the stream of speech. However, 10 of the 15 children with SLI had performance that was greater than 50% after double the exposure, whereas 5 of the 15 children with SLI had performance that was at or below 50%. One question is whether the pattern of learning for the children with SLI whose performance was above 50% differed from those whose performance was not above chance. In the 42-min speech condition, the children with SLI with above-chance performance learned five of the six target words at/or approaching a level significantly greater than chance ( dutaba, patubi, bupada, babupu, p < .05; pidabu, p = .09). In contrast, after double the exposure, the remaining children with SLI learned only 2:6 words at a level significantly greater than chance ( dutaba, pidabu, p < .05, vs. tutibu, p = .55; patubi, p = .63; bupada, p = .83; and babupu, p = .72). Thus, it appears that the children with SLI are tracking at least some statistical information in the input. Importantly, however, for the above-chance SLI group, one word was not learned. This word, tutibu ( p = .37), had the second highest transitional probability: 0.75. If the children with SLI were using transitional probability as a cue to discover word boundaries within the speech stream, why then, with double the exposure to the speech stream, were they unable to discover the boundaries for the word having the second highest transitional probability? Analysis of the response patterns of the children revealed that the target/foil test trials where the target and the foil had the identical vowel sequence— tutibu/dupitu —had the highest error rate, with 7 of the 10 children with SLI incorrectly choosing the foil dubitu . For the children to correctly choose the target over the foil, they not only had to track the transitional probabilities in the speech stream during the exposure phase but they also had to have a memory of the target words that contained enough phonological detail to enable them to differentiate the target from the foils during the testing phase. Taken together, the pattern of results for the children with SLI suggests that, with double the exposure, they are able to segment the speech stream to some extent but that their knowledge of the newly learned words may not contain sufficient phonological detail to enable them to differentiate newly learned target words from highly phonologically similar foils. In Experiment 2b, we asked whether the pattern of performance observed for children with SLI in Experiment 2a is unique to speech. Specifically, we used a nonlinguistic task designed to be analogous to the word segmentation task, in which tones are substituted for the syllables in the “words,” generating a continuous stream of tones ( Saffran et al., 1999 ). This task allowed us to ask whether statistical learning outcomes for children with SLI and CA-NIQ controls are the same for speech and for an analogous nonlinguistic task (e.g., tone-word segmentation) after 42 min of exposure. As noted earlier, because the tone language is analogous to the speech stimuli ( Saffran et al., 1996 ), we can compare the children's performance across the two modalities. The results of the ANCOVA discussed previously show that the CA-NIQ group performed above chance in both the speech and tone conditions, whereas performance of the SLI group differed as a function of the input stimuli, with above-chance performance only for the speech stimuli and not for the tone stimuli. In the 42-minute speech condition, the CA-NIQ group was able to learn all six words, and in the 42-minute tone condition, these same children were able to learn five of the six tone sequences at a level of significance greater than chance. Replicating Saffran's (1999) adult results, the one tone sequence not learned by the CA-NIQ group (the ABD tone sequence) had the lowest transitional probability (.37). Although the performance for the SLI group was no different from chance in the 42-minute tone condition, one of the six tone sequences was learned at a level greater than chance (D#ED; p < .05; transitional probability of .67). The results from Experiment 2b show that typically developing children are able to group sequences of auditory “events” in the same manner regardless of whether the input is linguistic (e.g., syllables) or nonlinguistic (e.g., tones). In Saffran et al. (1999) , the adults heard the tone stimuli for a total of 21 min. With twice as much exposure, the typically developing children were able to learn five of the six trisyllabic tone-sequences embedded within the tone stream. However, the children with SLI were less successful with the tone-sequences, with overall performance no different from chance. An important question is whether the children with SLI in Experiments 2a and 2b differed in some fundamental way from those children with SLI in Experiment 1. The children with SLI in Experiments 2a and 2b did not differ from the children with SLI in Experiment 1 in respect to Age, F (1, 49) = 0.32, p = .59; nonverbal IQ, F (1, 49) = 2.5, p = .11; Expressive Language, F (1, 49) = 0.35, p = .56; or Receptive Language, F (1, 49) = .65, p = .42. Thus, differences in age, nonverbal IQ, receptive, and/or expressive language abilities do not account for the differences in performance for the children with SLI in Experiment 1 versus Experiments 2a and 2b. This pattern of results suggests that the increased exposure to the speech stimuli in Experiment 2a played a key role in the performance of the children with SLI. A second important question is whether the children whose performance was above chance differ in some fundamental way from those children whose performance was not. In Experiment 1, the children with SLI whose performance was above chance ( n = 17) did not differ from the children with SLI whose performance was below chance ( n = 18) in Age, F (1, 34) = 0.0, p = .99; nonverbal IQ, F (1, 34) = 0.35, p = .55; Expressive Language, F (1, 34) = 0.34, p = .55; or Receptive Language, F (1, 34) = 0.32, p = .57. The typically developing children whose performance was above chance ( n = 26) also did not differ from the typically children whose performance was below chance in Age, F (1, 76) = 1.6, p = .20; nonverbal IQ, F (1, 76) = 0.64, p = .42; or Expressive Language, F (1, 76) = 0.81, p = .36. Similarly, in Experiment 2a, the children with SLI whose performance was above chance ( n = 10) did not differ from the children with SLI whose performance was below chance ( n = 5) for Age, F (1, 14) = 0.53, p = .47; Expressive Language, F (1, 14) = 0.0, p = .95; or Receptive Language, F (1, 34) = 0.16, p = .69, but did differ in nonverbal IQ, F (1, 14) = 5.7, p = .03. Although non-verbal IQ was higher for the children with SLI whose performance was above chance than for the children whose performance was below chance, it was not significantly correlated with statistical word learning performance. For the CA-NIQ group, 13:15 children had performance that was above chance, precluding statistical analysis. In Experiment 2b, the children with SLI whose performance was above 50% ( n = 5) did not differ from the children whose performance was below 50% ( n = 10) with respect to Age, F (1, 14) = 0.79, p = .38; nonverbal IQ, F (1, 14) = 0.0, p = .98; Expressive Language, F (1, 14) = 0.18, p = .67; or Receptive Language, F (1, 14) = 3.9, p = .07. For the CA-NIQ group, the children whose performance was above 50% ( n = 11) also did not differ from the children whose performance was below 50% for Age, F (1, 13) = 1.3, p = .27; nonverbal IQ, F (1, 13) = 0.05, p = .95; or Expressive Language, F (1, 13) = 0.98, p = .90. At this time, given the available behavioral data, it is not clear what factors differentiate the children who were able to segment the input using statistical sequential information implicitly from children who were unable to segment the speech stream.  Results The results for the SLI and CA-NIQ groups are presented in Figure 2 . A repeated measures ANCOVA with age and nonverbal IQ as covariates revealed a main effect for group, F (1, 26) = 7.4, p = .003, partial ?2 = .37, ? = .91, across the speech and tone conditions, with overall performance for the children with SLI being poorer than that of their typical language peers. An interaction was also observed where the performance of the children with SLI did not differ from that of the CA-NIQ group in the speech condition (Experiment 2a): F (1, 26) = 2.95, p = .11, partial ?2 = .09, ? = .34. However, the two groups did exhibit significantly different performance in the tone condition (Experiment 2b): F (1, 26) = 12.3, p = .002, partial ?2 = .09, ? = .92. In the speech condition, the mean was 56.2% ( SD = 10%) for the SLI group and 64.4% ( SD = 15%) for the CA-NIQ group, where chance equals 50%. Single-sample t tests (two-tailed) calculated for each group individually indicated that both groups performed significantly better than would be expected by chance: SLI, t (14) = 2.3, p < .05; CA-NIQ, t (14) = 3.74, p < .01. In the tone condition, the mean score for the SLI group was 48% ( SD = 11%) and for the CA-NIQ control group was 66% ( SD = 15%) where chance equals 50%. A single-sample t test (two-tailed) for the SLI group indicated that their performance after 42 min of exposure to the tone stimuli was no different from chance, t (14) = 0.62, p = .54, whereas the CA-NIQ group's performance was again significantly better than chance, t (14) = 4.09, p < .001. In Experiment 1, we observed that, after 21 min of exposure to the speech stream, the CA-NIQ groups' performance was significantly correlated with both expressive and receptive vocabulary. However, we observed no relationship between statistical learning and vocabulary knowledge for the children with SLI after 21 min of exposure. We thus asked whether the increased exposure to the speech stream in Experiment 2a would reveal a relationship between statistical learning and vocabulary knowledge for the children with SLI. A Pearson's correlation (two-tailed) for age, nonverbal IQ, and raw score for the EVT and PPVT-III indicated that the SLI group's statistical word learning performance, after double the exposure to the speech stream, was not significantly correlated with expressive vocabulary, age, or IQ but was significantly correlated with receptive vocabulary ( p < .03; see Table 6 ). In Experiment 1, we also observed that the typically developing children learned all six words after only 21 min of exposure. With doubled exposure, the performance for the CA-NIQ group did not differ from their performance after 21 min of exposure (64%) and 42 min (64%), t (14) = 0.04, p = .96, and they again learned all six words in Experiment 2a. The children with SLI learned 2:6 words at/or approaching a level significantly greater than chance— patubi having a transitional probability of 0.5 ( p < .05) and bupada having a transitional probability of 0.42 ( p = .07). That the children with SLI did not learn any of the words having the highest transitional probabilities suggests, at least on the surface, that even with double the exposure time, they were unable to use transitional probabilities to discover the word boundaries within the stream of speech. However, 10 of the 15 children with SLI had performance that was greater than 50% after double the exposure, whereas 5 of the 15 children with SLI had performance that was at or below 50%. One question is whether the pattern of learning for the children with SLI whose performance was above 50% differed from those whose performance was not above chance. In the 42-min speech condition, the children with SLI with above-chance performance learned five of the six target words at/or approaching a level significantly greater than chance ( dutaba, patubi, bupada, babupu, p < .05; pidabu, p = .09). In contrast, after double the exposure, the remaining children with SLI learned only 2:6 words at a level significantly greater than chance ( dutaba, pidabu, p < .05, vs. tutibu, p = .55; patubi, p = .63; bupada, p = .83; and babupu, p = .72). Thus, it appears that the children with SLI are tracking at least some statistical information in the input. Importantly, however, for the above-chance SLI group, one word was not learned. This word, tutibu ( p = .37), had the second highest transitional probability: 0.75. If the children with SLI were using transitional probability as a cue to discover word boundaries within the speech stream, why then, with double the exposure to the speech stream, were they unable to discover the boundaries for the word having the second highest transitional probability? Analysis of the response patterns of the children revealed that the target/foil test trials where the target and the foil had the identical vowel sequence— tutibu/dupitu —had the highest error rate, with 7 of the 10 children with SLI incorrectly choosing the foil dubitu . For the children to correctly choose the target over the foil, they not only had to track the transitional probabilities in the speech stream during the exposure phase but they also had to have a memory of the target words that contained enough phonological detail to enable them to differentiate the target from the foils during the testing phase. Taken together, the pattern of results for the children with SLI suggests that, with double the exposure, they are able to segment the speech stream to some extent but that their knowledge of the newly learned words may not contain sufficient phonological detail to enable them to differentiate newly learned target words from highly phonologically similar foils. In Experiment 2b, we asked whether the pattern of performance observed for children with SLI in Experiment 2a is unique to speech. Specifically, we used a nonlinguistic task designed to be analogous to the word segmentation task, in which tones are substituted for the syllables in the “words,” generating a continuous stream of tones ( Saffran et al., 1999 ). This task allowed us to ask whether statistical learning outcomes for children with SLI and CA-NIQ controls are the same for speech and for an analogous nonlinguistic task (e.g., tone-word segmentation) after 42 min of exposure. As noted earlier, because the tone language is analogous to the speech stimuli ( Saffran et al., 1996 ), we can compare the children's performance across the two modalities. The results of the ANCOVA discussed previously show that the CA-NIQ group performed above chance in both the speech and tone conditions, whereas performance of the SLI group differed as a function of the input stimuli, with above-chance performance only for the speech stimuli and not for the tone stimuli. In the 42-minute speech condition, the CA-NIQ group was able to learn all six words, and in the 42-minute tone condition, these same children were able to learn five of the six tone sequences at a level of significance greater than chance. Replicating Saffran's (1999) adult results, the one tone sequence not learned by the CA-NIQ group (the ABD tone sequence) had the lowest transitional probability (.37). Although the performance for the SLI group was no different from chance in the 42-minute tone condition, one of the six tone sequences was learned at a level greater than chance (D#ED; p < .05; transitional probability of .67). The results from Experiment 2b show that typically developing children are able to group sequences of auditory “events” in the same manner regardless of whether the input is linguistic (e.g., syllables) or nonlinguistic (e.g., tones). In Saffran et al. (1999) , the adults heard the tone stimuli for a total of 21 min. With twice as much exposure, the typically developing children were able to learn five of the six trisyllabic tone-sequences embedded within the tone stream. However, the children with SLI were less successful with the tone-sequences, with overall performance no different from chance. An important question is whether the children with SLI in Experiments 2a and 2b differed in some fundamental way from those children with SLI in Experiment 1. The children with SLI in Experiments 2a and 2b did not differ from the children with SLI in Experiment 1 in respect to Age, F (1, 49) = 0.32, p = .59; nonverbal IQ, F (1, 49) = 2.5, p = .11; Expressive Language, F (1, 49) = 0.35, p = .56; or Receptive Language, F (1, 49) = .65, p = .42. Thus, differences in age, nonverbal IQ, receptive, and/or expressive language abilities do not account for the differences in performance for the children with SLI in Experiment 1 versus Experiments 2a and 2b. This pattern of results suggests that the increased exposure to the speech stimuli in Experiment 2a played a key role in the performance of the children with SLI. A second important question is whether the children whose performance was above chance differ in some fundamental way from those children whose performance was not. In Experiment 1, the children with SLI whose performance was above chance ( n = 17) did not differ from the children with SLI whose performance was below chance ( n = 18) in Age, F (1, 34) = 0.0, p = .99; nonverbal IQ, F (1, 34) = 0.35, p = .55; Expressive Language, F (1, 34) = 0.34, p = .55; or Receptive Language, F (1, 34) = 0.32, p = .57. The typically developing children whose performance was above chance ( n = 26) also did not differ from the typically children whose performance was below chance in Age, F (1, 76) = 1.6, p = .20; nonverbal IQ, F (1, 76) = 0.64, p = .42; or Expressive Language, F (1, 76) = 0.81, p = .36. Similarly, in Experiment 2a, the children with SLI whose performance was above chance ( n = 10) did not differ from the children with SLI whose performance was below chance ( n = 5) for Age, F (1, 14) = 0.53, p = .47; Expressive Language, F (1, 14) = 0.0, p = .95; or Receptive Language, F (1, 34) = 0.16, p = .69, but did differ in nonverbal IQ, F (1, 14) = 5.7, p = .03. Although non-verbal IQ was higher for the children with SLI whose performance was above chance than for the children whose performance was below chance, it was not significantly correlated with statistical word learning performance. For the CA-NIQ group, 13:15 children had performance that was above chance, precluding statistical analysis. In Experiment 2b, the children with SLI whose performance was above 50% ( n = 5) did not differ from the children whose performance was below 50% ( n = 10) with respect to Age, F (1, 14) = 0.79, p = .38; nonverbal IQ, F (1, 14) = 0.0, p = .98; Expressive Language, F (1, 14) = 0.18, p = .67; or Receptive Language, F (1, 14) = 3.9, p = .07. For the CA-NIQ group, the children whose performance was above 50% ( n = 11) also did not differ from the children whose performance was below 50% for Age, F (1, 13) = 1.3, p = .27; nonverbal IQ, F (1, 13) = 0.05, p = .95; or Expressive Language, F (1, 13) = 0.98, p = .90. At this time, given the available behavioral data, it is not clear what factors differentiate the children who were able to segment the input using statistical sequential information implicitly from children who were unable to segment the speech stream.  General Discussion In these studies, we asked if children with SLI are both sensitive to the quantitative aspects of distributional information in a language corpus and able to store this information to a degree that supports vocabulary development—specifically, whether they are able to implicitly track statistical information to discover word boundaries in running speech. We also asked if this ability is related to frequency or degree of exposure and to vocabulary knowledge, and if it appears to be a domain-general or domain-specific skill. The findings from our studies support the hypothesis that typically developing children are equipped with computational tools that can harness statistical information to detect word boundaries, that this ability is related to measures of receptive and expressive word knowledge, and that it appears to be a domain-general ability being broadly similar across speech and tone conditions. The findings for the children with SLI are less clear cut and suggest that the computational mechanism that allows unimpaired children to use statistical information to discover word boundaries is not as effectively functional in children with SLI. Although with double exposure, the children with SLI were able to track the transitional probabilities in the speech condition, they still had difficulty. Specifically, they were unsuccessful at differentiating newly learned target words from highly similar-sounding foils during the testing phase of the task. One possibility is that children with SLI were unable to retain in memory a sufficiently detailed phonological form of the target words. This is consistent with recent work suggesting that the phonological representations of words in the lexicons of children with SLI are more holistic and less well specified than those of typically developing children ( Mainela-Arnold, Evans, & Coady, 2008 ). If one takes the view that representation and processing of all aspects of language (e.g., speech, words, and grammar) are dependent on a computational system where learning takes place over distributed representations, occurring through changes in the strength of these representations as a result of statistical contingencies in the environment (e.g., Elman et al., 1996 ), then the pattern of performance for the children with SLI suggests that even with double the exposure, the representations of newly learned words may be phonologically underspecified. The difficulties that the children with SLI experienced segmenting the speech stream may also have been compounded by the nature of speech stimuli itself, as it was impoverished with respect to the cues that are available for children to discover word boundaries in naturally occurring speech. In natural speech, a variety of cues, such as prosody and coarticulation, occur in conjunction with transitional probabilities, aiding the listener in the discovery of word boundaries. Not only were these redundant cues unavailable for the children in the speech condition, but the speech stimulus was synthesized speech, possibly adding to the difficulties experienced by the children with SLI. There is a growing body of evidence that shows that children with SLI are significantly impaired across a range of speech perception tasks when the stimuli consist of synthesized speech in contrast to natural speech ( Coady, Kluender, & Evans, 2005 ; Coady, Evans, Mainela-Arnold, & Kluender, 2007 ; Evans, Viele, & Kass, 2002 ; Joanisse et al., 2000 ). The results of Experiment 2b indicate, however, that the poor performance of the children with SLI in Experiments 1 and 2a was not due solely to the degraded speech stimuli. Experiment 2b consisted of highly perceptible tones, yet the children with SLI were still unable to discover the tone-word boundaries. Taken together with prior research ( Saffran et al., 1997 ), these studies make it clear that implicit learning is a robust phenomenon in typically developing children. Specifically, typically developing children can track transitional probabilities from a stream of speech with a level of efficiency and specificity that allows them to not only learn words having varying transitional probabilities (e.g., 0.37–1.0) but also to differentiate these newly learned words from highly similar-sounding foils during testing despite the degraded nature of the synthetic speech stimuli. The difficulty in sequence learning by children in the SLI group suggests that (a) difficulties in tracking statistical properties of sounds for children with SLI is not limited to speech and (b) the nonlinguistic materials were actually more difficult for the children with SLI than the linguistic materials, perhaps due to the relative novelty of the tone sequences. In any event, these findings only highlight the robustness of the implicit learning mechanism in typical children and the fragile and ineffective nature of this mechanism in children with SLI. On the surface, the difference in the performance of the children with SLI in the 42-min speech and in the speech and tone conditions suggests that implicit learning is not a domain-general mechanism in children with SLI. However, the speech and tone conditions differed in important ways that may have resulted in different performance in the two conditions. First, all of the children in Experiments 2a and 2b had prior exposure to the speech stimuli because of their prior participation in Experiment 1. Thus, the children's exposure time to the speech stimuli, over the span of Experiments 1 and 2a, was actually 63 min. It could be that the children with SLI actually require not 40+ but 60+ min of exposure to the speech stream before they are able to discover the word boundaries. If the children had received 60+ min of exposure to the tone language, their performance in the speech and tone conditions may have been similar. Note, however, that there were 6 months between the two experiments. For Experiment 1 participation to have affected Experiment 2 performance, the children would have had to maintain these representations over a long time interval. A second important difference is that there is overlap in the transitional probabilities within and across the word boundaries in the tone stimuli not present in the speech stimuli. This overlap is extremely rare, occurring for only 3 of the 30 across-word tone-pairs where the probability was .6 (when the words GG#A happened to be followed by DFE, as the cross-boundary sequence AD also occurred in the word ADB). The occurrence of such overlaps may have made segmentation more difficult in the tone language as compared with the speech language. However, recall that the typically developing children showed equivalent performance in the tone and speech conditions in Experiment 2. There is, thus, some factor that made the tone condition disproportionately harder for the children with SLI compared with their typically developing peers. Importantly, however, there were children with SLI whose performance was above chance in all three experiments. An important question is whether these children differed in some fundamental way from the children whose performance was not above chance. With the exception of nonverbal IQ in Experiment 2a, which was not significantly correlated with statistical word learning abilities, the children did not differ by age, IQ, or receptive/ expressive vocabulary or language abilities. The fact that differences in intelligence, age, or language did not account for differences in statistical word learning abilities suggests that the children differed in some other fundamental way. One possibility is that the children differed in their working memory capacity and/or attentional resources. Studies comparing implicit learning in high- versus low-load conditions for adults show that statistical word learning performance is significantly poorer when working memory/attentional resources are reduced and are not available to be dedicated to the discovery of word boundaries ( Ludden & Gupta, 2000 ). Children with SLI have reduced working memory capacity as compared with that of their peers (cf. Coady & Evans, 2008 ; Graf Estes, Evans, & Else-Quest, 2007 ; Leonard et al., 2007 ; Montgomery & Evans, 2009 ). Moreover, there is a growing body of evidence suggesting that children with SLI may also have problems with selective auditory attention, especially at the earliest stages of sensory processing (e.g., Helzer, Champlin, & Gillam, 1996 ; Montgomery, Evans, & Gillam, 2009 ; Stevens, Sanders, & Neville, 2006 ; Uwer, Albrecht, & von Suchodoletz, 2002 ). It may be that the children differed in attention or working memory abilities and this played a critical role in the statistical word learning abilities in children, which is clearly an important issue that warrants further investigation. Another interesting outcome in Experiment 1 was that statistical learning was significantly correlated with age for the typical children (aged 5;7–12;10). Given that very young children and even infants succeed on statistical word learning tasks, this is a somewhat curious finding. There are, however, differences both in the complexity of the exposure languages and the methodologies used to measure statistical learning in infants and adults that may account for differences in implicit learning skills of infants, children, and adults. In infant studies, exposure languages are generally much less complex than adult languages. For example, Graf Estes et al. (2007) used a language consisting of four CVCV target words. This contrasts sharply with our study and others, where the language consisted of six CVCVCV target words. In addition to differences in the complexity of the exposure languages, learning in infant studies is often measured with paradigms such as preferential looking, which is presumably less cognitively demanding than the two-alternative forced-choice paradigm used in our study. In light of the role that working memory capacity and attention has on statistical learning ( Ludden & Gupta, 2000 ), this mechanism may be sensitive to and influenced by developmental changes in attention and working memory capacity. The differences in the individual words learned by the children with and without SLI as well as the differences in the relationships between statistical word learning and expressive and receptive vocabulary in the two groups indicate that the pattern of learning by the children with SLI differs somewhat from that of typically developing children. Tomblin et al. (2007) also observed differences in the pattern of sequence learning in the children with SLI when compared with their NL controls. Specifically, their NL control group exhibited an initial rapid rate of learning followed by a gradual approach toward an asymptote. In contrast, the shape of the learning curve for the SLI group in Tomblin et al.'s study consisted of a period of slowed responses prior to the rapid onset of learning but no evidence of an asymptote by the end of the training. Performance on the last block of trials did not differ between the SLI and NL controls. What is interesting is the slowing in reaction times for the SLI group after the initial block of pattern sequence trials. Tomblin et al. suggest that in the early stages of learning the new sequences, the representations are initially unstable in children with SLI as compared with NL children. Several studies of lexical and sentence processing in individuals with SLI suggest that there may be less suppression of competing candidate representations than observed in typically developing children ( McMurray, Samuelson, Lee, & Tomblin, 2006 ; Mainela-Arnold, Evans, & Coady, 2007 , 2008 ). Tomblin et al. suggest that for their individuals with SLI, multiple candidate targets are initially generated, with subsequent instability as these candidates compete for priority as the dominant representation. This instability is resolved only after sufficient training. Although our study does not allow for investigation of the stability of the representations of the single word/tone sequence that was learned by the children with SLI, our findings are consistent with Tomblin et al.'s work, strongly supporting the contention that the learning challenges for children with SLI are not limited to linguistic sequences (e.g., Tomblin et al., 2007 ). The term implicit learning characterizes a heterogeneous collection of learning capacities that, in addition to perceptual motor learning (e.g., procedural memory), includes probabilistic learning of categories, statistical learning, artificial grammar learning, and prototype abstraction ( Perruchet & Pacton, 2006 ; Squire & Zola, 1996 ). The findings for our experiments, taken together with the work by Tomblin et al. (2007) and Plante et al. (2002) suggest that Ullman's procedural learning deficit hypothesis of SLI may need to be extended to include deficits in other domains of implicit learning in children with SLI. Ullman's DP model assumes that the acquisition and use of the form-meaning–associated aspects of language (e.g., lexicon) are supported by the declarative memory system. Our results indicate that aspects of vocabulary learning are also supported by the implicit system, in the earliest stages in word learning where infants begin to discover word boundaries within the stream of speech around them. The findings from the current study also shed light on our understanding of the domain specificity of implicit learning and suggest that even when the statistical structure of the input is identical, differences in the features of the stimuli (e.g., speech vs. tones) result in different learning patterns in typically developing children. Finally, these results suggest that future studies need to consider implicit learning across the visual, auditory, and perceptual motor modalities in order to more carefully characterize the challenges facing learners with SLI.  General Discussion In these studies, we asked if children with SLI are both sensitive to the quantitative aspects of distributional information in a language corpus and able to store this information to a degree that supports vocabulary development—specifically, whether they are able to implicitly track statistical information to discover word boundaries in running speech. We also asked if this ability is related to frequency or degree of exposure and to vocabulary knowledge, and if it appears to be a domain-general or domain-specific skill. The findings from our studies support the hypothesis that typically developing children are equipped with computational tools that can harness statistical information to detect word boundaries, that this ability is related to measures of receptive and expressive word knowledge, and that it appears to be a domain-general ability being broadly similar across speech and tone conditions. The findings for the children with SLI are less clear cut and suggest that the computational mechanism that allows unimpaired children to use statistical information to discover word boundaries is not as effectively functional in children with SLI. Although with double exposure, the children with SLI were able to track the transitional probabilities in the speech condition, they still had difficulty. Specifically, they were unsuccessful at differentiating newly learned target words from highly similar-sounding foils during the testing phase of the task. One possibility is that children with SLI were unable to retain in memory a sufficiently detailed phonological form of the target words. This is consistent with recent work suggesting that the phonological representations of words in the lexicons of children with SLI are more holistic and less well specified than those of typically developing children ( Mainela-Arnold, Evans, & Coady, 2008 ). If one takes the view that representation and processing of all aspects of language (e.g., speech, words, and grammar) are dependent on a computational system where learning takes place over distributed representations, occurring through changes in the strength of these representations as a result of statistical contingencies in the environment (e.g., Elman et al., 1996 ), then the pattern of performance for the children with SLI suggests that even with double the exposure, the representations of newly learned words may be phonologically underspecified. The difficulties that the children with SLI experienced segmenting the speech stream may also have been compounded by the nature of speech stimuli itself, as it was impoverished with respect to the cues that are available for children to discover word boundaries in naturally occurring speech. In natural speech, a variety of cues, such as prosody and coarticulation, occur in conjunction with transitional probabilities, aiding the listener in the discovery of word boundaries. Not only were these redundant cues unavailable for the children in the speech condition, but the speech stimulus was synthesized speech, possibly adding to the difficulties experienced by the children with SLI. There is a growing body of evidence that shows that children with SLI are significantly impaired across a range of speech perception tasks when the stimuli consist of synthesized speech in contrast to natural speech ( Coady, Kluender, & Evans, 2005 ; Coady, Evans, Mainela-Arnold, & Kluender, 2007 ; Evans, Viele, & Kass, 2002 ; Joanisse et al., 2000 ). The results of Experiment 2b indicate, however, that the poor performance of the children with SLI in Experiments 1 and 2a was not due solely to the degraded speech stimuli. Experiment 2b consisted of highly perceptible tones, yet the children with SLI were still unable to discover the tone-word boundaries. Taken together with prior research ( Saffran et al., 1997 ), these studies make it clear that implicit learning is a robust phenomenon in typically developing children. Specifically, typically developing children can track transitional probabilities from a stream of speech with a level of efficiency and specificity that allows them to not only learn words having varying transitional probabilities (e.g., 0.37–1.0) but also to differentiate these newly learned words from highly similar-sounding foils during testing despite the degraded nature of the synthetic speech stimuli. The difficulty in sequence learning by children in the SLI group suggests that (a) difficulties in tracking statistical properties of sounds for children with SLI is not limited to speech and (b) the nonlinguistic materials were actually more difficult for the children with SLI than the linguistic materials, perhaps due to the relative novelty of the tone sequences. In any event, these findings only highlight the robustness of the implicit learning mechanism in typical children and the fragile and ineffective nature of this mechanism in children with SLI. On the surface, the difference in the performance of the children with SLI in the 42-min speech and in the speech and tone conditions suggests that implicit learning is not a domain-general mechanism in children with SLI. However, the speech and tone conditions differed in important ways that may have resulted in different performance in the two conditions. First, all of the children in Experiments 2a and 2b had prior exposure to the speech stimuli because of their prior participation in Experiment 1. Thus, the children's exposure time to the speech stimuli, over the span of Experiments 1 and 2a, was actually 63 min. It could be that the children with SLI actually require not 40+ but 60+ min of exposure to the speech stream before they are able to discover the word boundaries. If the children had received 60+ min of exposure to the tone language, their performance in the speech and tone conditions may have been similar. Note, however, that there were 6 months between the two experiments. For Experiment 1 participation to have affected Experiment 2 performance, the children would have had to maintain these representations over a long time interval. A second important difference is that there is overlap in the transitional probabilities within and across the word boundaries in the tone stimuli not present in the speech stimuli. This overlap is extremely rare, occurring for only 3 of the 30 across-word tone-pairs where the probability was .6 (when the words GG#A happened to be followed by DFE, as the cross-boundary sequence AD also occurred in the word ADB). The occurrence of such overlaps may have made segmentation more difficult in the tone language as compared with the speech language. However, recall that the typically developing children showed equivalent performance in the tone and speech conditions in Experiment 2. There is, thus, some factor that made the tone condition disproportionately harder for the children with SLI compared with their typically developing peers. Importantly, however, there were children with SLI whose performance was above chance in all three experiments. An important question is whether these children differed in some fundamental way from the children whose performance was not above chance. With the exception of nonverbal IQ in Experiment 2a, which was not significantly correlated with statistical word learning abilities, the children did not differ by age, IQ, or receptive/ expressive vocabulary or language abilities. The fact that differences in intelligence, age, or language did not account for differences in statistical word learning abilities suggests that the children differed in some other fundamental way. One possibility is that the children differed in their working memory capacity and/or attentional resources. Studies comparing implicit learning in high- versus low-load conditions for adults show that statistical word learning performance is significantly poorer when working memory/attentional resources are reduced and are not available to be dedicated to the discovery of word boundaries ( Ludden & Gupta, 2000 ). Children with SLI have reduced working memory capacity as compared with that of their peers (cf. Coady & Evans, 2008 ; Graf Estes, Evans, & Else-Quest, 2007 ; Leonard et al., 2007 ; Montgomery & Evans, 2009 ). Moreover, there is a growing body of evidence suggesting that children with SLI may also have problems with selective auditory attention, especially at the earliest stages of sensory processing (e.g., Helzer, Champlin, & Gillam, 1996 ; Montgomery, Evans, & Gillam, 2009 ; Stevens, Sanders, & Neville, 2006 ; Uwer, Albrecht, & von Suchodoletz, 2002 ). It may be that the children differed in attention or working memory abilities and this played a critical role in the statistical word learning abilities in children, which is clearly an important issue that warrants further investigation. Another interesting outcome in Experiment 1 was that statistical learning was significantly correlated with age for the typical children (aged 5;7–12;10). Given that very young children and even infants succeed on statistical word learning tasks, this is a somewhat curious finding. There are, however, differences both in the complexity of the exposure languages and the methodologies used to measure statistical learning in infants and adults that may account for differences in implicit learning skills of infants, children, and adults. In infant studies, exposure languages are generally much less complex than adult languages. For example, Graf Estes et al. (2007) used a language consisting of four CVCV target words. This contrasts sharply with our study and others, where the language consisted of six CVCVCV target words. In addition to differences in the complexity of the exposure languages, learning in infant studies is often measured with paradigms such as preferential looking, which is presumably less cognitively demanding than the two-alternative forced-choice paradigm used in our study. In light of the role that working memory capacity and attention has on statistical learning ( Ludden & Gupta, 2000 ), this mechanism may be sensitive to and influenced by developmental changes in attention and working memory capacity. The differences in the individual words learned by the children with and without SLI as well as the differences in the relationships between statistical word learning and expressive and receptive vocabulary in the two groups indicate that the pattern of learning by the children with SLI differs somewhat from that of typically developing children. Tomblin et al. (2007) also observed differences in the pattern of sequence learning in the children with SLI when compared with their NL controls. Specifically, their NL control group exhibited an initial rapid rate of learning followed by a gradual approach toward an asymptote. In contrast, the shape of the learning curve for the SLI group in Tomblin et al.'s study consisted of a period of slowed responses prior to the rapid onset of learning but no evidence of an asymptote by the end of the training. Performance on the last block of trials did not differ between the SLI and NL controls. What is interesting is the slowing in reaction times for the SLI group after the initial block of pattern sequence trials. Tomblin et al. suggest that in the early stages of learning the new sequences, the representations are initially unstable in children with SLI as compared with NL children. Several studies of lexical and sentence processing in individuals with SLI suggest that there may be less suppression of competing candidate representations than observed in typically developing children ( McMurray, Samuelson, Lee, & Tomblin, 2006 ; Mainela-Arnold, Evans, & Coady, 2007 , 2008 ). Tomblin et al. suggest that for their individuals with SLI, multiple candidate targets are initially generated, with subsequent instability as these candidates compete for priority as the dominant representation. This instability is resolved only after sufficient training. Although our study does not allow for investigation of the stability of the representations of the single word/tone sequence that was learned by the children with SLI, our findings are consistent with Tomblin et al.'s work, strongly supporting the contention that the learning challenges for children with SLI are not limited to linguistic sequences (e.g., Tomblin et al., 2007 ). The term implicit learning characterizes a heterogeneous collection of learning capacities that, in addition to perceptual motor learning (e.g., procedural memory), includes probabilistic learning of categories, statistical learning, artificial grammar learning, and prototype abstraction ( Perruchet & Pacton, 2006 ; Squire & Zola, 1996 ). The findings for our experiments, taken together with the work by Tomblin et al. (2007) and Plante et al. (2002) suggest that Ullman's procedural learning deficit hypothesis of SLI may need to be extended to include deficits in other domains of implicit learning in children with SLI. Ullman's DP model assumes that the acquisition and use of the form-meaning–associated aspects of language (e.g., lexicon) are supported by the declarative memory system. Our results indicate that aspects of vocabulary learning are also supported by the implicit system, in the earliest stages in word learning where infants begin to discover word boundaries within the stream of speech around them. The findings from the current study also shed light on our understanding of the domain specificity of implicit learning and suggest that even when the statistical structure of the input is identical, differences in the features of the stimuli (e.g., speech vs. tones) result in different learning patterns in typically developing children. Finally, these results suggest that future studies need to consider implicit learning across the visual, auditory, and perceptual motor modalities in order to more carefully characterize the challenges facing learners with SLI. 