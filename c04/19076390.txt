Visual Skills and Cross-Modal Plasticity in Deaf Readers Possible Implications for Acquiring Meaning from Print Most research on reading skill acquisition in deaf individuals has been conducted from the perspective of a hearing child learning to read. This approach may limit our understanding of how a deaf child approaches the task of learning to read and successfully acquires reading skills. An alternative approach is to consider how the cognitive skills that a deaf child brings to the reading task may influence the route by which he or she achieves reading fluency. A review of the literature on visual spatial attention suggests that deaf individuals are more distracted by visual information in the parafovea and periphery. We discuss how this may have an influence upon the perceptual processing of written text in deaf students.  Introduction Communication in a Visual World The ability to read successfully requires extracting meaning from print. In hearing children, this is thought to involve the development of phonological awareness and the acquisition of grapheme–phoneme correspondences, both of which are related to the child’s preexisting acquisition of the spoken language that corresponds to the printed medium ( Brady & Shankweiler, 1991 ). For deaf children, this “typical” pattern of literacy acquisition is not available. Specifically, these children have little or no access to a spoken language. For many deaf children, their access to the world of shared meanings is through the visual sense. They rely upon visual communication strategies whether by speechreading, a manually coded form of the spoken language (such as Signed Exact English), or the use of a natural visual language such as American Sign Language (ASL). Can these deaf children then achieve literacy? The lack of linguistic structures corresponding to acoustic properties of spoken language, in particular phonology, would seem to inhibit this “typical” pattern of development. Indeed, many deaf children seem to have problems with literacy acquisition. Over the past 100 years, deaf high school graduates’ average reading levels have remained around the fourth-grade level ( Holt, Traxler, & Allen, 1997 ; Pintner & Patterson, 1916 ). Importantly, however, inter-individual variability in reading achievement is quite large and a significant number of deaf students do achieve age-appropriate or better reading skills. What distinguishes these individuals? A host of factors may contribute. Have they been deaf from birth? How much residual hearing is available? In what kind of program were they educated? Do they have good speech reception and intelligibility? Of particular interest in this regard are profoundly deaf individuals (those with hearing losses of 90 dB or greater within the speech range), educated within bilingual–bicultural programs that promote the use of ASL, who have little or no competence in the spoken language domain. For good readers from within this population, which cognitive skills are recruited or acquired in order to read succesfully? Heterogeneity of the Deaf Population It is important to note that deaf individuals in general vary greatly with regard to the etiology of their deafness, its severity, and the age of onset. According to the National Institute on Deafness and Other Communication Disorders, approximately 127 in 1,000 children under the age of 18 years in the United States, have some hearing loss. The etiology of hearing loss can be hereditary (~50%) or acquired by several causes which include prenatal or perinatal infections (cytomegalovirus, rubella, and herpes simplex), postnatal infections (meningitis), premature birth, anoxia, trauma, or it can occur as a result of ototoxic drugs administered during pregnancy. Many of these causes have been associated with other, sometimes severe, neurological sequelae that affect behavioral, cognitive, and psychosocial functioning (Hauser, Wills, & Isquith, 2006; King, Hauser, & Isquith, 2006 ). Hereditary deafness is associated with more than 350 genetic conditions ( Martini, Mazzoli, & Kimberling, 1997 ), and about a third of these genetic conditions are associated with syndromes ( Petit, 1996 ). Although not all hereditary cases of deafness are nonsyndromic, hereditarily deafened individuals are more likely to have unremarkable neurologic and psychiatric histories. In the United States, many individuals who have severe to profound hearing loss before the age of 3 years acquire ASL as their first language. This group relies on visual routes for learning and language access and has similar values, beliefs, and behaviors that reflect deaf culture. The community of ASL users is often referred to in the literature as a linguistic minority community because of the similarities it has with other minority communities in terms of language and culture ( Ladd, 2003 ; Padden & Humphries, 2005 ). The National Association of the Deaf estimates that there are 250,000 to 500,000 ASL users in the United States and Canada. The group often referred to as “deaf native signers” are those born deaf to at least one deaf parent from whom they acquired ASL as a first language in infancy. Such individuals were reported to represent only 4.4% of the 6–19-year-old deaf students in the United States in 1999–2000 ( Mitchell & Karchmer, 2004 ). Cognition and Literacy Acquisition A new approach to considering the development of literacy proposes a different way of thinking about the acquisition process that may suggest answers to this apparent conundrum. Usually, we think of children trying to link the printed word to their preexisting knowledge of spoken language. The problem is one of mapping from print-to-sound—dyslexic individuals are thought by some to have problems in this domain ( Rack, Snowling, & Olson, 1992 ). But what if this mapping is one of many possible mechanisms by which a child can achieve literacy? For example, a different approach for examining the acquisition of a written language is the study of a nonalphabetic writing system such as Chinese. Studies of how that logographic writing system is learned suggest that orthographic awareness may be of more importance ( Tan, Spinks, Eden, Perfetti, & Siok, 2005 ) and involve right hemisphere areas to a greater extent ( Tan et al ., 2001 ). This raises the possibility that deaf readers with little access to spoken phonology may have alternative routes available to them for the extraction of meaning from words. That is, for deaf readers, words may function similarly to logographs, bypassing the need for grapheme–phoneme conversion skills. What little data are available concerning the brain areas involved in reading in deaf individuals suggests that the right hemisphere also plays a role in English reading for deaf individuals, whereas the left hemisphere is predominant for hearing individuals ( Neville et al ., 1998 ). To better understand the routes by which a deaf child may achieve literacy in an alphabetic script such as English, one approach that has been advocated is to think of the printed word as the starting point ( Kuntze, 1998 ). The child’s task is to extract some meaning from this visual pattern. In order to do this, he or she can use a range of cognitive skills (memory, attention, pattern matching, etc.) and knowledge bases (such as metalinguistic knowledge of written English and contextual information that will help decode the text). The “typical” child may use print-to-sound mappings and a spoken language lexicon to perform the task. A deaf child may rely on visual grapheme recognition strategies and either conceptual knowledge or an ASL lexicon. When considering the development of literacy in deaf children from this perspective, the question changes. It becomes, “which cognitive skills and knowledge bases best allow deaf children to extract meaning from print in an automatic and fluent manner?” Importantly, these mechanisms may be very different from those employed by hearing children. It is only by reformulating the question in this way that we will be led to consider several different reading acquisition mechanisms rather than just one. Similarly, it does not make sense to talk of an “optimal” mechanism for reading acquisition. Which mechanism is optimal for any individual will depend upon the nature of the language being read, the cognitive skills and knowledge bases that the individual brings to the task of reading, and, crucially, the act of reading itself. Through experience with text and attempting to extract meaning from it with the resources at their disposal, a child will move toward the acquisition of fluent literacy. Whereas studies that determine the cognitive factors that lead to successful literacy acquisition in deaf students are still rare, much work has been conducted examining the perceptual and attentional processes of vision. A large body of work is now accumulating that focuses on the development of visual skills of deaf children, but their role with regards to achieving literacy has not been widely discussed. In this brief article, we will review that literature and make suggestions about the possible implications of this work for literacy in this population. Our emphasis will be on factors influencing adult reading skill, rather than the process of literacy acquisition per se. First, we will present what is known about the deployment of visual attention across space in deaf individuals. We will then suggest how differences in visual attention between deaf and hearing individuals may affect reading skill in the deaf learner. Finally, we will suggest what we believe to be fruitful avenues of future research that will help elucidate the mechanisms by which deaf individuals master literacy. More broadly, we hope to demonstrate that an understanding of reading skill in deaf individuals can be fostered by an understanding of the preexisting cognitive skills that these individuals bring to the task of reading. We believe this will complement more traditional approaches in which reading skill in deaf individuals is interpreted in terms of the mechanisms relied upon by hearing individuals. It is not our aim to provide a review of the literature on deafness and literacy acquisition (see Musselman, 2000 , for a recent such review). Rather, we will focus upon an aspect of cognition that deaf readers are likely to rely upon heavily—visual cognition, and visual attention in particular—and explore what implications that may have for their reading skills.  Communication in a Visual World The ability to read successfully requires extracting meaning from print. In hearing children, this is thought to involve the development of phonological awareness and the acquisition of grapheme–phoneme correspondences, both of which are related to the child’s preexisting acquisition of the spoken language that corresponds to the printed medium ( Brady & Shankweiler, 1991 ). For deaf children, this “typical” pattern of literacy acquisition is not available. Specifically, these children have little or no access to a spoken language. For many deaf children, their access to the world of shared meanings is through the visual sense. They rely upon visual communication strategies whether by speechreading, a manually coded form of the spoken language (such as Signed Exact English), or the use of a natural visual language such as American Sign Language (ASL). Can these deaf children then achieve literacy? The lack of linguistic structures corresponding to acoustic properties of spoken language, in particular phonology, would seem to inhibit this “typical” pattern of development. Indeed, many deaf children seem to have problems with literacy acquisition. Over the past 100 years, deaf high school graduates’ average reading levels have remained around the fourth-grade level ( Holt, Traxler, & Allen, 1997 ; Pintner & Patterson, 1916 ). Importantly, however, inter-individual variability in reading achievement is quite large and a significant number of deaf students do achieve age-appropriate or better reading skills. What distinguishes these individuals? A host of factors may contribute. Have they been deaf from birth? How much residual hearing is available? In what kind of program were they educated? Do they have good speech reception and intelligibility? Of particular interest in this regard are profoundly deaf individuals (those with hearing losses of 90 dB or greater within the speech range), educated within bilingual–bicultural programs that promote the use of ASL, who have little or no competence in the spoken language domain. For good readers from within this population, which cognitive skills are recruited or acquired in order to read succesfully?  Heterogeneity of the Deaf Population It is important to note that deaf individuals in general vary greatly with regard to the etiology of their deafness, its severity, and the age of onset. According to the National Institute on Deafness and Other Communication Disorders, approximately 127 in 1,000 children under the age of 18 years in the United States, have some hearing loss. The etiology of hearing loss can be hereditary (~50%) or acquired by several causes which include prenatal or perinatal infections (cytomegalovirus, rubella, and herpes simplex), postnatal infections (meningitis), premature birth, anoxia, trauma, or it can occur as a result of ototoxic drugs administered during pregnancy. Many of these causes have been associated with other, sometimes severe, neurological sequelae that affect behavioral, cognitive, and psychosocial functioning (Hauser, Wills, & Isquith, 2006; King, Hauser, & Isquith, 2006 ). Hereditary deafness is associated with more than 350 genetic conditions ( Martini, Mazzoli, & Kimberling, 1997 ), and about a third of these genetic conditions are associated with syndromes ( Petit, 1996 ). Although not all hereditary cases of deafness are nonsyndromic, hereditarily deafened individuals are more likely to have unremarkable neurologic and psychiatric histories. In the United States, many individuals who have severe to profound hearing loss before the age of 3 years acquire ASL as their first language. This group relies on visual routes for learning and language access and has similar values, beliefs, and behaviors that reflect deaf culture. The community of ASL users is often referred to in the literature as a linguistic minority community because of the similarities it has with other minority communities in terms of language and culture ( Ladd, 2003 ; Padden & Humphries, 2005 ). The National Association of the Deaf estimates that there are 250,000 to 500,000 ASL users in the United States and Canada. The group often referred to as “deaf native signers” are those born deaf to at least one deaf parent from whom they acquired ASL as a first language in infancy. Such individuals were reported to represent only 4.4% of the 6–19-year-old deaf students in the United States in 1999–2000 ( Mitchell & Karchmer, 2004 ).  Cognition and Literacy Acquisition A new approach to considering the development of literacy proposes a different way of thinking about the acquisition process that may suggest answers to this apparent conundrum. Usually, we think of children trying to link the printed word to their preexisting knowledge of spoken language. The problem is one of mapping from print-to-sound—dyslexic individuals are thought by some to have problems in this domain ( Rack, Snowling, & Olson, 1992 ). But what if this mapping is one of many possible mechanisms by which a child can achieve literacy? For example, a different approach for examining the acquisition of a written language is the study of a nonalphabetic writing system such as Chinese. Studies of how that logographic writing system is learned suggest that orthographic awareness may be of more importance ( Tan, Spinks, Eden, Perfetti, & Siok, 2005 ) and involve right hemisphere areas to a greater extent ( Tan et al ., 2001 ). This raises the possibility that deaf readers with little access to spoken phonology may have alternative routes available to them for the extraction of meaning from words. That is, for deaf readers, words may function similarly to logographs, bypassing the need for grapheme–phoneme conversion skills. What little data are available concerning the brain areas involved in reading in deaf individuals suggests that the right hemisphere also plays a role in English reading for deaf individuals, whereas the left hemisphere is predominant for hearing individuals ( Neville et al ., 1998 ). To better understand the routes by which a deaf child may achieve literacy in an alphabetic script such as English, one approach that has been advocated is to think of the printed word as the starting point ( Kuntze, 1998 ). The child’s task is to extract some meaning from this visual pattern. In order to do this, he or she can use a range of cognitive skills (memory, attention, pattern matching, etc.) and knowledge bases (such as metalinguistic knowledge of written English and contextual information that will help decode the text). The “typical” child may use print-to-sound mappings and a spoken language lexicon to perform the task. A deaf child may rely on visual grapheme recognition strategies and either conceptual knowledge or an ASL lexicon. When considering the development of literacy in deaf children from this perspective, the question changes. It becomes, “which cognitive skills and knowledge bases best allow deaf children to extract meaning from print in an automatic and fluent manner?” Importantly, these mechanisms may be very different from those employed by hearing children. It is only by reformulating the question in this way that we will be led to consider several different reading acquisition mechanisms rather than just one. Similarly, it does not make sense to talk of an “optimal” mechanism for reading acquisition. Which mechanism is optimal for any individual will depend upon the nature of the language being read, the cognitive skills and knowledge bases that the individual brings to the task of reading, and, crucially, the act of reading itself. Through experience with text and attempting to extract meaning from it with the resources at their disposal, a child will move toward the acquisition of fluent literacy. Whereas studies that determine the cognitive factors that lead to successful literacy acquisition in deaf students are still rare, much work has been conducted examining the perceptual and attentional processes of vision. A large body of work is now accumulating that focuses on the development of visual skills of deaf children, but their role with regards to achieving literacy has not been widely discussed. In this brief article, we will review that literature and make suggestions about the possible implications of this work for literacy in this population. Our emphasis will be on factors influencing adult reading skill, rather than the process of literacy acquisition per se. First, we will present what is known about the deployment of visual attention across space in deaf individuals. We will then suggest how differences in visual attention between deaf and hearing individuals may affect reading skill in the deaf learner. Finally, we will suggest what we believe to be fruitful avenues of future research that will help elucidate the mechanisms by which deaf individuals master literacy. More broadly, we hope to demonstrate that an understanding of reading skill in deaf individuals can be fostered by an understanding of the preexisting cognitive skills that these individuals bring to the task of reading. We believe this will complement more traditional approaches in which reading skill in deaf individuals is interpreted in terms of the mechanisms relied upon by hearing individuals. It is not our aim to provide a review of the literature on deafness and literacy acquisition (see Musselman, 2000 , for a recent such review). Rather, we will focus upon an aspect of cognition that deaf readers are likely to rely upon heavily—visual cognition, and visual attention in particular—and explore what implications that may have for their reading skills.  Visual Skills in Deaf Individuals Behavioral Studies of Visual Spatial Attention in Deaf Individuals Deficiencies The earliest work looking at the development of visual skills in deaf children suggested that the effect of early auditory deprivation was an associated deficiency in visual function. One early study ( Myklebust & Brutten, 1953 ) reported that deaf children had low-level visual deficits, as measured by the Keystone Visual Survey, as well as poor levels of performance on visual pattern-matching tasks such as the Marble Boards test. Deficits in a visual continuous performance task (CPT) have also been reported in deaf children ( Quittner, Leibach, & Marciel, 2004 ; Quittner, Smith, Osberger, Mitchell, & Katz, 1994 ; Smith, Quittner, Osberger, & Miyamoto, 1998 ). In this task, a rapid series of digits is presented, and children are required to make a response to a “9” only when it is preceded by a “1” but otherwise to withhold responding. They observed that deaf children were delayed in the development of this ability, never attaining the level of even the youngest hearing children tested. Furthermore, their data suggest that cochlear implantation (CI) enhances the development of this skill although, again, those children with CIs did not achieve the performance levels of hearing controls. The authors suggest that this represents a deficit in visual selective attention, although it could also represent difficulties integrating visual information over time or just a problem dealing with numerals. Taken together, these findings have been used in support of the deficiency hypothesis. Generally stated, this hypothesis states that integration of information from the different senses is an essential component to the development of normal function in each individual sense. For the deaf child, then, the lack of audition impairs the development of multisensory integration and therefore the development of typical visual skills. It is important to note some of the shortcomings of these studies and to acknowledge the populations from which the data were drawn. For example, the results that Myklebust obtained using the Marble Boards test have been difficult to replicate ( Hayes, 1955 ; Larr, 1956 ), suggesting either experimenter error or small effect sizes in the original published work. Also, differences between deaf and hearing children have not always been observed using CPT tasks ( Tharpe, Ashmead, & Rothpletz, 2002 ). So there are issues of replicability that need to be considered when interpreting these data. In addition, much of the work that has suggested visual deficits in deaf children has used extremely heterogeneous samples, bringing into question the role that deafness per se has in the effect reported and questioning the generalizability of those results to all deaf children. For example, an examination of the demographics of the deaf children used in the CPT studies suggests differences between those who had CIs and those who did not. The CI group was more likely to have received an education using oral methods as opposed to Total Communication (a combination of auditory and visual communication modes), and less likely to have viral meningitis as a cause of their deafness. Moreover, the cause of deafness for most children in those studies was unknown. Benefits In contrast to those studies reporting visual deficits, different results are obtained when homogenous samples of deaf participants are used. Those born to deaf parents with mostly genetic etiologies who learn a signed language from an early age have demonstrated differences in visual function compared to hearing controls that could be considered adaptive by showing a compensation in the visual modality for the lack of auditory input. Using deaf native signers such as these, a selective enhancement in deaf individuals for stimuli that are peripheral or in motion and require attentional selection has been demonstrated using a variety of paradigms. In a task employing a flanker compatibility paradigm, enhanced processing has been reported of peripheral distractors located at 4.2 degrees of visual angle from a concurrent target combined with decreased processing of central distractors located at 0.5 degrees ( Proksch & Bavelier, 2002 ). Subsequently, another study demonstrated that the responses of deaf individuals were more influenced by distractor letters positioned at ~1.5 degrees from a letter target than were responses of hearing controls ( Sladen, Tharpe, Ashmead, Wesley Grantham, & Chun, 2005 ). Most recently, some researchers have shown that as nonletter distractors (arrows) are positioned at increasing eccentricities (1.0, 2.0 and 3.0 degrees), their effect on deaf individuals increases relative to how these distractors affect hearing individuals ( Dye, Baril, & Bavelier, 2007 ). Finally, using peripheral kinetic and foveal static perimetry, deaf individuals were reported to be better than hearing controls at detecting moving lights in the periphery (manifested as a difference in field of view) and not different in their sensitivity to points of light presented foveally ( Stevens & Neville, 2006 ). What all of these “compensation” studies have in common is that they focus upon visual attention skills, that is, how deaf individuals allocate limited processing resources to the visual scene. In terms of adaptation to the environment, the change observed in deaf individuals makes intuitive sense: a redistribution of visual attention to the periphery in order to compensate for the lack of peripheral auditory cues provided by the environment, such as the sound of an approaching vehicle or the creak of an opening door. In contrast to these changes in visual attention in which the onset and location of stimuli are unknown, attempts to demonstrate changes in basic visual skills using psychophysical methods (and where target location and onset are known a priori ) have been unsuccessful ( Bosworth & Dobkins, 1999 , 2002a , 2002b ; Bross, 1979 ; Bross & Sauerwein, 1980 ; Brozinsky & Bavelier, 2004 ; Finney & Dobkins, 2001 ; Mills, 1985 ; Poizner & Tallal, 1987 ). Thus it appears that low-level visual processing is unaffected by early auditory impairment. One working hypothesis is that a sensory loss leads to changes in higher-level attentional processing, especially in domains in which information from multiple senses is integrated ( Bavelier, Dye, & Hauser, 2006 ; Bavelier & Neville, 2002 ). Multisensory integration is most important in situations where no one sense dominates; accordingly, the largest behavioral differences between deaf and hearing persons have been observed during the processing of the visual periphery. In particular, early deafness results in a redistribution of attentional resources to the periphery, most commonly observed when input from peripheral and central space competes for privileged access to processing resources ( Bavelier et al ., 2006 ). Studies of the Functional Anatomy of Cross-Modal Plasticity in Deaf Individuals Given these changes in visual function that have been observed behaviorally, it makes sense to ask whether we can observe associated neuronal changes. There is now a substantial body of work looking at compensatory changes in brain activation following early auditory deprivation. One well-studied area is MT/MST, an area of visual cortex involved in the detection and analysis of movement whose activity is known to be modulated by attentional processes ( O’Craven, Rosen, Kwong, Treisman, & Savoy, 1997 ). When viewing unattended moving stimuli, deaf and hearing participants do not differ in their recruitment of MT/MST cortex. However, when required to attend to peripheral movement and ignore concurrent central motion, enhanced recruitment of MT/MST is observed relative to hearing controls ( Bavelier et al ., 2001 ; Fine, Finney, Boynton, & Dobkins, 2005 ). This pattern echoes a general trend in the literature, whereby the greatest population differences have been reported for motion stimuli in the visual periphery under conditions that engage selective attention, such as when the location or time of arrival of the stimulus is unknown or when the stimulus has to be selected from among distractors ( Bavelier et al ., 2006 ). There are several potential ways in which cross-modal reorganization could support the changes observed in the spatial distribution of visual attention in deaf individuals. One possibility is that there is an expansion in the representation of the peripheral visual field in early visual cortex. However, there is currently little data to support this hypothesis ( Fine et al ., 2005 ). Recent studies in the macaque ( Falchier, Clavagnier, Barone, & Kennedy, 2002 ; Rockland & Ojima, 2003 ) have highlighted projections from auditory cortex to early visual areas (V1 and V2). This raises the possibility that in the absence of auditory input these pathways are susceptible to the attentional modulations observed in deaf individuals, although this remains an open question. Another possibility is that the multimodal associative cortex may display a greater sensitivity to input from remaining modalities such as vision and touch. Evidence for this hypothesis comes from studies reporting changes in the posterior parietal cortex of deaf individuals ( Bavelier et al ., 2001 ), an area known to be involved in the integration of information from different sensory modalities. Finally, it is possible that in deaf individuals, the lack of input from audition causes the auditory cortex—which is multimodal in nature—to reorganize and process visual information. Indeed, there is some evidence that auditory areas in the superior temporal sulcus show greater recruitment in deaf than in hearing individuals for visual, tactile, and signed input ( Bavelier et al ., 2001 ; Fine et al ., 2005 ; Finney, Clementz, Hickok, & Dobkins, 2003 ; Levanen, Jousmaki, & Hari, 1998 ; Neville et al ., 1998 ; Pettito et al ., 2000 ). This may or may not be the case for primary auditory cortex (A1) with brain averaging studies (where data from several individuals are combined and analyzed as a group), suggesting recruitment of areas adjacent to and overlapping the posterior part of A1 ( Fine et a l., 2005 ; Finney, Fine, & Dobkins, 2001 ; Lambertz, Gizewski, de Greiff, & Forsting, 2005 ; Levanen et al ., 1998 ), and studies in which A1 is delineated on a subject-by-subject basis (without averaging across individuals in a group), suggesting little functional change except in the adjacent secondary auditory region ( Bavelier et al ., 2001 ; Kral, Hartmann, Tillein, Heid, & Klinke, 2001 ; Nishimura et al ., 1999 ). To summarize, behavioral studies suggest that there is redistribution of attentional resources in deaf individuals with an enhancement of representations from peripheral space. This behavioral difference appears to be accompanied by neural changes suggesting cross-modal reorganization in areas that integrate information from different modalities and possible recruitment of multimodal cortex in auditory regions for the processing of visual information.  Behavioral Studies of Visual Spatial Attention in Deaf Individuals Deficiencies The earliest work looking at the development of visual skills in deaf children suggested that the effect of early auditory deprivation was an associated deficiency in visual function. One early study ( Myklebust & Brutten, 1953 ) reported that deaf children had low-level visual deficits, as measured by the Keystone Visual Survey, as well as poor levels of performance on visual pattern-matching tasks such as the Marble Boards test. Deficits in a visual continuous performance task (CPT) have also been reported in deaf children ( Quittner, Leibach, & Marciel, 2004 ; Quittner, Smith, Osberger, Mitchell, & Katz, 1994 ; Smith, Quittner, Osberger, & Miyamoto, 1998 ). In this task, a rapid series of digits is presented, and children are required to make a response to a “9” only when it is preceded by a “1” but otherwise to withhold responding. They observed that deaf children were delayed in the development of this ability, never attaining the level of even the youngest hearing children tested. Furthermore, their data suggest that cochlear implantation (CI) enhances the development of this skill although, again, those children with CIs did not achieve the performance levels of hearing controls. The authors suggest that this represents a deficit in visual selective attention, although it could also represent difficulties integrating visual information over time or just a problem dealing with numerals. Taken together, these findings have been used in support of the deficiency hypothesis. Generally stated, this hypothesis states that integration of information from the different senses is an essential component to the development of normal function in each individual sense. For the deaf child, then, the lack of audition impairs the development of multisensory integration and therefore the development of typical visual skills. It is important to note some of the shortcomings of these studies and to acknowledge the populations from which the data were drawn. For example, the results that Myklebust obtained using the Marble Boards test have been difficult to replicate ( Hayes, 1955 ; Larr, 1956 ), suggesting either experimenter error or small effect sizes in the original published work. Also, differences between deaf and hearing children have not always been observed using CPT tasks ( Tharpe, Ashmead, & Rothpletz, 2002 ). So there are issues of replicability that need to be considered when interpreting these data. In addition, much of the work that has suggested visual deficits in deaf children has used extremely heterogeneous samples, bringing into question the role that deafness per se has in the effect reported and questioning the generalizability of those results to all deaf children. For example, an examination of the demographics of the deaf children used in the CPT studies suggests differences between those who had CIs and those who did not. The CI group was more likely to have received an education using oral methods as opposed to Total Communication (a combination of auditory and visual communication modes), and less likely to have viral meningitis as a cause of their deafness. Moreover, the cause of deafness for most children in those studies was unknown. Benefits In contrast to those studies reporting visual deficits, different results are obtained when homogenous samples of deaf participants are used. Those born to deaf parents with mostly genetic etiologies who learn a signed language from an early age have demonstrated differences in visual function compared to hearing controls that could be considered adaptive by showing a compensation in the visual modality for the lack of auditory input. Using deaf native signers such as these, a selective enhancement in deaf individuals for stimuli that are peripheral or in motion and require attentional selection has been demonstrated using a variety of paradigms. In a task employing a flanker compatibility paradigm, enhanced processing has been reported of peripheral distractors located at 4.2 degrees of visual angle from a concurrent target combined with decreased processing of central distractors located at 0.5 degrees ( Proksch & Bavelier, 2002 ). Subsequently, another study demonstrated that the responses of deaf individuals were more influenced by distractor letters positioned at ~1.5 degrees from a letter target than were responses of hearing controls ( Sladen, Tharpe, Ashmead, Wesley Grantham, & Chun, 2005 ). Most recently, some researchers have shown that as nonletter distractors (arrows) are positioned at increasing eccentricities (1.0, 2.0 and 3.0 degrees), their effect on deaf individuals increases relative to how these distractors affect hearing individuals ( Dye, Baril, & Bavelier, 2007 ). Finally, using peripheral kinetic and foveal static perimetry, deaf individuals were reported to be better than hearing controls at detecting moving lights in the periphery (manifested as a difference in field of view) and not different in their sensitivity to points of light presented foveally ( Stevens & Neville, 2006 ). What all of these “compensation” studies have in common is that they focus upon visual attention skills, that is, how deaf individuals allocate limited processing resources to the visual scene. In terms of adaptation to the environment, the change observed in deaf individuals makes intuitive sense: a redistribution of visual attention to the periphery in order to compensate for the lack of peripheral auditory cues provided by the environment, such as the sound of an approaching vehicle or the creak of an opening door. In contrast to these changes in visual attention in which the onset and location of stimuli are unknown, attempts to demonstrate changes in basic visual skills using psychophysical methods (and where target location and onset are known a priori ) have been unsuccessful ( Bosworth & Dobkins, 1999 , 2002a , 2002b ; Bross, 1979 ; Bross & Sauerwein, 1980 ; Brozinsky & Bavelier, 2004 ; Finney & Dobkins, 2001 ; Mills, 1985 ; Poizner & Tallal, 1987 ). Thus it appears that low-level visual processing is unaffected by early auditory impairment. One working hypothesis is that a sensory loss leads to changes in higher-level attentional processing, especially in domains in which information from multiple senses is integrated ( Bavelier, Dye, & Hauser, 2006 ; Bavelier & Neville, 2002 ). Multisensory integration is most important in situations where no one sense dominates; accordingly, the largest behavioral differences between deaf and hearing persons have been observed during the processing of the visual periphery. In particular, early deafness results in a redistribution of attentional resources to the periphery, most commonly observed when input from peripheral and central space competes for privileged access to processing resources ( Bavelier et al ., 2006 ).  Deficiencies The earliest work looking at the development of visual skills in deaf children suggested that the effect of early auditory deprivation was an associated deficiency in visual function. One early study ( Myklebust & Brutten, 1953 ) reported that deaf children had low-level visual deficits, as measured by the Keystone Visual Survey, as well as poor levels of performance on visual pattern-matching tasks such as the Marble Boards test. Deficits in a visual continuous performance task (CPT) have also been reported in deaf children ( Quittner, Leibach, & Marciel, 2004 ; Quittner, Smith, Osberger, Mitchell, & Katz, 1994 ; Smith, Quittner, Osberger, & Miyamoto, 1998 ). In this task, a rapid series of digits is presented, and children are required to make a response to a “9” only when it is preceded by a “1” but otherwise to withhold responding. They observed that deaf children were delayed in the development of this ability, never attaining the level of even the youngest hearing children tested. Furthermore, their data suggest that cochlear implantation (CI) enhances the development of this skill although, again, those children with CIs did not achieve the performance levels of hearing controls. The authors suggest that this represents a deficit in visual selective attention, although it could also represent difficulties integrating visual information over time or just a problem dealing with numerals. Taken together, these findings have been used in support of the deficiency hypothesis. Generally stated, this hypothesis states that integration of information from the different senses is an essential component to the development of normal function in each individual sense. For the deaf child, then, the lack of audition impairs the development of multisensory integration and therefore the development of typical visual skills. It is important to note some of the shortcomings of these studies and to acknowledge the populations from which the data were drawn. For example, the results that Myklebust obtained using the Marble Boards test have been difficult to replicate ( Hayes, 1955 ; Larr, 1956 ), suggesting either experimenter error or small effect sizes in the original published work. Also, differences between deaf and hearing children have not always been observed using CPT tasks ( Tharpe, Ashmead, & Rothpletz, 2002 ). So there are issues of replicability that need to be considered when interpreting these data. In addition, much of the work that has suggested visual deficits in deaf children has used extremely heterogeneous samples, bringing into question the role that deafness per se has in the effect reported and questioning the generalizability of those results to all deaf children. For example, an examination of the demographics of the deaf children used in the CPT studies suggests differences between those who had CIs and those who did not. The CI group was more likely to have received an education using oral methods as opposed to Total Communication (a combination of auditory and visual communication modes), and less likely to have viral meningitis as a cause of their deafness. Moreover, the cause of deafness for most children in those studies was unknown.  Benefits In contrast to those studies reporting visual deficits, different results are obtained when homogenous samples of deaf participants are used. Those born to deaf parents with mostly genetic etiologies who learn a signed language from an early age have demonstrated differences in visual function compared to hearing controls that could be considered adaptive by showing a compensation in the visual modality for the lack of auditory input. Using deaf native signers such as these, a selective enhancement in deaf individuals for stimuli that are peripheral or in motion and require attentional selection has been demonstrated using a variety of paradigms. In a task employing a flanker compatibility paradigm, enhanced processing has been reported of peripheral distractors located at 4.2 degrees of visual angle from a concurrent target combined with decreased processing of central distractors located at 0.5 degrees ( Proksch & Bavelier, 2002 ). Subsequently, another study demonstrated that the responses of deaf individuals were more influenced by distractor letters positioned at ~1.5 degrees from a letter target than were responses of hearing controls ( Sladen, Tharpe, Ashmead, Wesley Grantham, & Chun, 2005 ). Most recently, some researchers have shown that as nonletter distractors (arrows) are positioned at increasing eccentricities (1.0, 2.0 and 3.0 degrees), their effect on deaf individuals increases relative to how these distractors affect hearing individuals ( Dye, Baril, & Bavelier, 2007 ). Finally, using peripheral kinetic and foveal static perimetry, deaf individuals were reported to be better than hearing controls at detecting moving lights in the periphery (manifested as a difference in field of view) and not different in their sensitivity to points of light presented foveally ( Stevens & Neville, 2006 ). What all of these “compensation” studies have in common is that they focus upon visual attention skills, that is, how deaf individuals allocate limited processing resources to the visual scene. In terms of adaptation to the environment, the change observed in deaf individuals makes intuitive sense: a redistribution of visual attention to the periphery in order to compensate for the lack of peripheral auditory cues provided by the environment, such as the sound of an approaching vehicle or the creak of an opening door. In contrast to these changes in visual attention in which the onset and location of stimuli are unknown, attempts to demonstrate changes in basic visual skills using psychophysical methods (and where target location and onset are known a priori ) have been unsuccessful ( Bosworth & Dobkins, 1999 , 2002a , 2002b ; Bross, 1979 ; Bross & Sauerwein, 1980 ; Brozinsky & Bavelier, 2004 ; Finney & Dobkins, 2001 ; Mills, 1985 ; Poizner & Tallal, 1987 ). Thus it appears that low-level visual processing is unaffected by early auditory impairment. One working hypothesis is that a sensory loss leads to changes in higher-level attentional processing, especially in domains in which information from multiple senses is integrated ( Bavelier, Dye, & Hauser, 2006 ; Bavelier & Neville, 2002 ). Multisensory integration is most important in situations where no one sense dominates; accordingly, the largest behavioral differences between deaf and hearing persons have been observed during the processing of the visual periphery. In particular, early deafness results in a redistribution of attentional resources to the periphery, most commonly observed when input from peripheral and central space competes for privileged access to processing resources ( Bavelier et al ., 2006 ).  Studies of the Functional Anatomy of Cross-Modal Plasticity in Deaf Individuals Given these changes in visual function that have been observed behaviorally, it makes sense to ask whether we can observe associated neuronal changes. There is now a substantial body of work looking at compensatory changes in brain activation following early auditory deprivation. One well-studied area is MT/MST, an area of visual cortex involved in the detection and analysis of movement whose activity is known to be modulated by attentional processes ( O’Craven, Rosen, Kwong, Treisman, & Savoy, 1997 ). When viewing unattended moving stimuli, deaf and hearing participants do not differ in their recruitment of MT/MST cortex. However, when required to attend to peripheral movement and ignore concurrent central motion, enhanced recruitment of MT/MST is observed relative to hearing controls ( Bavelier et al ., 2001 ; Fine, Finney, Boynton, & Dobkins, 2005 ). This pattern echoes a general trend in the literature, whereby the greatest population differences have been reported for motion stimuli in the visual periphery under conditions that engage selective attention, such as when the location or time of arrival of the stimulus is unknown or when the stimulus has to be selected from among distractors ( Bavelier et al ., 2006 ). There are several potential ways in which cross-modal reorganization could support the changes observed in the spatial distribution of visual attention in deaf individuals. One possibility is that there is an expansion in the representation of the peripheral visual field in early visual cortex. However, there is currently little data to support this hypothesis ( Fine et al ., 2005 ). Recent studies in the macaque ( Falchier, Clavagnier, Barone, & Kennedy, 2002 ; Rockland & Ojima, 2003 ) have highlighted projections from auditory cortex to early visual areas (V1 and V2). This raises the possibility that in the absence of auditory input these pathways are susceptible to the attentional modulations observed in deaf individuals, although this remains an open question. Another possibility is that the multimodal associative cortex may display a greater sensitivity to input from remaining modalities such as vision and touch. Evidence for this hypothesis comes from studies reporting changes in the posterior parietal cortex of deaf individuals ( Bavelier et al ., 2001 ), an area known to be involved in the integration of information from different sensory modalities. Finally, it is possible that in deaf individuals, the lack of input from audition causes the auditory cortex—which is multimodal in nature—to reorganize and process visual information. Indeed, there is some evidence that auditory areas in the superior temporal sulcus show greater recruitment in deaf than in hearing individuals for visual, tactile, and signed input ( Bavelier et al ., 2001 ; Fine et al ., 2005 ; Finney, Clementz, Hickok, & Dobkins, 2003 ; Levanen, Jousmaki, & Hari, 1998 ; Neville et al ., 1998 ; Pettito et al ., 2000 ). This may or may not be the case for primary auditory cortex (A1) with brain averaging studies (where data from several individuals are combined and analyzed as a group), suggesting recruitment of areas adjacent to and overlapping the posterior part of A1 ( Fine et a l., 2005 ; Finney, Fine, & Dobkins, 2001 ; Lambertz, Gizewski, de Greiff, & Forsting, 2005 ; Levanen et al ., 1998 ), and studies in which A1 is delineated on a subject-by-subject basis (without averaging across individuals in a group), suggesting little functional change except in the adjacent secondary auditory region ( Bavelier et al ., 2001 ; Kral, Hartmann, Tillein, Heid, & Klinke, 2001 ; Nishimura et al ., 1999 ). To summarize, behavioral studies suggest that there is redistribution of attentional resources in deaf individuals with an enhancement of representations from peripheral space. This behavioral difference appears to be accompanied by neural changes suggesting cross-modal reorganization in areas that integrate information from different modalities and possible recruitment of multimodal cortex in auditory regions for the processing of visual information.  Deafness, Visual Cognition, and Reading We noted in the introduction that literacy can be regarded as the reader’s attempt to acquire meaning from the printed word. Insight from deaf readers ( Hofsteater, 1959 ; Kuntze, 1998 ) suggests that for many deaf individuals this acquisition is a predominantly visual process, building upon their world knowledge and linguistic skills in English and/or ASL. If this is the case (and it may be for some if not all deaf readers), then it is important to investigate the visual skills that the deaf individual brings to the task if we are to understand how literacy can be acquired exclusively through the visual domain. Differences in visual processing in the deaf reader may result in different perceptual processes involved in reading as compared to those of hearing readers. Below we discuss how visual skill differences between deaf and hearing readers may have an impact on reading skills. Visual Attention and Perceptual Processes in Reading The proposal that changes in visual skills are likely to alter reading strategies is not new. A recent review by Boden and Giaschi (2007) discusses various ways in which changes in the magnocellular stream may be implicated in the reading problems experienced by those with developmental dyslexia. While the focus of their review is not upon reading in deaf populations, two aspects of visual processing they discuss have implications for individuals with a different spatial distribution of visual attention: parafoveal-on-foveal interactions and covert spatial attention. We begin by observing that a reader must fixate upon and pay attention to printed words in order to extract meaning from a text. Much is now known about the perceptual processes involved in reading, especially about how eye movements (saccades) and fixations on text are planned and executed, to the extent that there exist computational models that provide good fits to the data (e.g., the E-Z Reader model; Reichle, Rayner, & Pollatsek, 2003 ). It is becoming clear that low-level visual properties of words exert a large influence upon where readers look in a text and how long they fixate upon a word ( Radach, Kennedy, & Rayner, 2004 ). One of the properties that influences where a reader will fixate in a word is the length of that word and of neighboring words (to the right of the fixated word in a left-to-right language like English). These “parafoveal-on-foveal” effects can be defined as the effect of a not-yet fixated word on the processing of a currently fixated word ( Kennedy & Pynte, 2005 ). If deaf readers have a spatial distribution of attention which biases them toward processing parafoveal input, then parafoveal-on-foveal effects may be stronger in deaf than in hearing readers, resulting in qualitatively different scanning patterns over written texts and differences in the amount and type of information extracted from the parafoveal region. Greater availability of parafoveal information may slow down foveal processing, resulting in longer fixations and slowing down the reading process. One knock-on effect of these changes in how text is processed at a perceptual level may be a greater demand on memory on account of longer processing times, causing problems in interpreting complex syntactic structures or making appropriate references within a sentence or passage. Interestingly, a case study of a hearing individual (S.J.) has been reported in which reading problems were attributed to an inability to selectively attend to the fixated word and suppress processing of information in the parafovea ( Rayner, Murphy, Henderson, & Pollatsek, 1989 ), resulting in reasonable word recognition performance, but poor comprehension of passages of text. It is possible that deaf readers may consistently demonstrate this pattern and benefit from a “windowed reading” remediation program, which was successful for S.J., whereby only limited amounts of text are made available at any one time, limiting the amount of distracting information that occupies the parafovea. Another aspect of visual attention likely to affect reading skills is visual selective attention. For example, Facoetti and colleagues ( Facoetti & Molteni, 2001 ; Lorusso et al ., 2004 ) suggest that as the reader makes a series of successive saccades across written text, it is important that he or she both spatially disambiguate proximal letters and temporally integrate that spatial arrangement of letters over the series of saccades. Thus an alteration in how visual selective attention is deployed will alter how a series of visual events is integrated over time and may lead to confusions both in identifying the letters of a word and in creating representations that preserve both the correct letters and their correct spatial arrangements. Facoetti has proposed that such deficits in visual selective attention, possibly resulting from deficits in posterior parietal cortex, may play a role in some of the difficulties experienced by dyslexic readers ( Facoetti, 2005 ). In the case of deaf readers, this may be instantiated as enhanced processing of parafoveal letters at the expense of the fixated letters. In addition, given possible problems in temporally integrating rapid serial visual presentations ( Quittner et al ., 1994 , 2004 ; Smith et al ., 1998 ), further difficulties in constructing representations on the basis of successive saccades across written text are also possible. In support of this, recent work by Valdois and colleagues has suggested that problems in selective visual attention (a narrower attentional window in which graphemes are available for processing) play a functional role in reading problems observed in some developmental dyslexics, separately from problems that are phonological in nature ( Bosse, Tainturier, & Valdois, 2006 ; Valdois, Bosse, & Tainturier, 2004 ). We are not suggesting, however, that deaf readers should be considered a priori as dyslexics. Not only is the selective attention account of dyslexia controversial, but there is also evidence that magnocellular visual functions differ between deaf and dyslexic individuals ( Stevens & Neville, 2006 ). However, considering this line of investigation provides a way to theorize about how the visual cognitive skills of deaf readers may interact with the integration of visual information during the reading process. Indeed, differences in the deployment of visual attention may be just one of several factors that influence the acquisition pathway of literacy in deaf readers.  Visual Attention and Perceptual Processes in Reading The proposal that changes in visual skills are likely to alter reading strategies is not new. A recent review by Boden and Giaschi (2007) discusses various ways in which changes in the magnocellular stream may be implicated in the reading problems experienced by those with developmental dyslexia. While the focus of their review is not upon reading in deaf populations, two aspects of visual processing they discuss have implications for individuals with a different spatial distribution of visual attention: parafoveal-on-foveal interactions and covert spatial attention. We begin by observing that a reader must fixate upon and pay attention to printed words in order to extract meaning from a text. Much is now known about the perceptual processes involved in reading, especially about how eye movements (saccades) and fixations on text are planned and executed, to the extent that there exist computational models that provide good fits to the data (e.g., the E-Z Reader model; Reichle, Rayner, & Pollatsek, 2003 ). It is becoming clear that low-level visual properties of words exert a large influence upon where readers look in a text and how long they fixate upon a word ( Radach, Kennedy, & Rayner, 2004 ). One of the properties that influences where a reader will fixate in a word is the length of that word and of neighboring words (to the right of the fixated word in a left-to-right language like English). These “parafoveal-on-foveal” effects can be defined as the effect of a not-yet fixated word on the processing of a currently fixated word ( Kennedy & Pynte, 2005 ). If deaf readers have a spatial distribution of attention which biases them toward processing parafoveal input, then parafoveal-on-foveal effects may be stronger in deaf than in hearing readers, resulting in qualitatively different scanning patterns over written texts and differences in the amount and type of information extracted from the parafoveal region. Greater availability of parafoveal information may slow down foveal processing, resulting in longer fixations and slowing down the reading process. One knock-on effect of these changes in how text is processed at a perceptual level may be a greater demand on memory on account of longer processing times, causing problems in interpreting complex syntactic structures or making appropriate references within a sentence or passage. Interestingly, a case study of a hearing individual (S.J.) has been reported in which reading problems were attributed to an inability to selectively attend to the fixated word and suppress processing of information in the parafovea ( Rayner, Murphy, Henderson, & Pollatsek, 1989 ), resulting in reasonable word recognition performance, but poor comprehension of passages of text. It is possible that deaf readers may consistently demonstrate this pattern and benefit from a “windowed reading” remediation program, which was successful for S.J., whereby only limited amounts of text are made available at any one time, limiting the amount of distracting information that occupies the parafovea. Another aspect of visual attention likely to affect reading skills is visual selective attention. For example, Facoetti and colleagues ( Facoetti & Molteni, 2001 ; Lorusso et al ., 2004 ) suggest that as the reader makes a series of successive saccades across written text, it is important that he or she both spatially disambiguate proximal letters and temporally integrate that spatial arrangement of letters over the series of saccades. Thus an alteration in how visual selective attention is deployed will alter how a series of visual events is integrated over time and may lead to confusions both in identifying the letters of a word and in creating representations that preserve both the correct letters and their correct spatial arrangements. Facoetti has proposed that such deficits in visual selective attention, possibly resulting from deficits in posterior parietal cortex, may play a role in some of the difficulties experienced by dyslexic readers ( Facoetti, 2005 ). In the case of deaf readers, this may be instantiated as enhanced processing of parafoveal letters at the expense of the fixated letters. In addition, given possible problems in temporally integrating rapid serial visual presentations ( Quittner et al ., 1994 , 2004 ; Smith et al ., 1998 ), further difficulties in constructing representations on the basis of successive saccades across written text are also possible. In support of this, recent work by Valdois and colleagues has suggested that problems in selective visual attention (a narrower attentional window in which graphemes are available for processing) play a functional role in reading problems observed in some developmental dyslexics, separately from problems that are phonological in nature ( Bosse, Tainturier, & Valdois, 2006 ; Valdois, Bosse, & Tainturier, 2004 ). We are not suggesting, however, that deaf readers should be considered a priori as dyslexics. Not only is the selective attention account of dyslexia controversial, but there is also evidence that magnocellular visual functions differ between deaf and dyslexic individuals ( Stevens & Neville, 2006 ). However, considering this line of investigation provides a way to theorize about how the visual cognitive skills of deaf readers may interact with the integration of visual information during the reading process. Indeed, differences in the deployment of visual attention may be just one of several factors that influence the acquisition pathway of literacy in deaf readers.  Conclusions and Avenues for Future Research Although the literature on literacy in deaf individuals is extensive, there is still much that we do not know. What are the mechanisms by which deaf individuals can learn to read, and how are these influenced by changes in visual cognition? Studies are needed that explore the neuroanatomical underpinnings of fluent and dysfluent reading in deaf readers (as well as in “typical” readers) with assessments of how deafness, language history, and educational methods influence the development of reading networks in deaf brains. The question of whether or not deaf individuals differ in their perceptual processing of text remains open and is susceptible to empirical inquiry. The knowledge gained by such studies will allow us to begin to understand how the peculiar cognitive skills of deaf children influence their acquisition of reading skills and will, it is hoped, lead to remediation techniques and instructional protocols that will allow more deaf children to excel and become literate. To our knowledge, no work has yet looked at saccades and fixations of deaf readers in a rigorous or systematic manner. Some work has looked at viewing position effects (VPE; O’Regan, 1981 ), whereby the ability to correctly identify a word varies as a function of where in a word the reader fixates. Aghababian and colleagues report that the VPE curves for a young deaf girl (A.H.) were flat, indicating that her ability to identify a word did not vary as a function of the fixated letter within the word ( Aghababian, Nazir, Lançon, & Tardy, 2001 ). They report that training in grapheme–phoneme correspondence skills resulted in A.H.’s exhibiting more “normal” VPE curves, such as those typically acquired by hearing children after only 7–8 months of reading instruction ( Aghababian & Nazir, 2000 ). Given our knowledge of how textual information in the periphery of the reading window influences the programming of saccades during reading ( Kennedy & Pynte, 2005 ; Rayner et al ., 1989 ), it makes sense to ask whether a redistribution of attention in deaf readers actually results in qualitatively different scanning of text. That is, the target of a saccade by deaf readers may have quantitatively different determinants, resulting in a qualitatively different pattern of saccades and fixations. The frameworks provided by Facoetti (2005) and Bosse et al . (2006) provide a means by which studies can investigate the possible interaction between the deployment of spatial attention in deaf readers and the acquisition of reading skill. It also remains possible, however, that a strategic allocation of attention by deaf readers allows them to overcome these attentional constraints. Studies on the automaticity of attentional distribution across space in deaf individuals will help elucidate this question. As well as behavioral explorations of reading performance in deaf readers, more studies are needed that examine the neuroanatomical underpinnings of fluent reading. Some work has suggested that the right hemisphere may have a greater involvement than it does for hearing readers ( Neville et al ., 1998 ). These studies will need to dissociate carefully the effects of hearing loss, language background, education, and reading skill in determining which neural pathways are available to support fluent reading skill. In conclusion, we have reported on a range of studies that suggest a different distribution of attentional resources in deaf individuals associated with cross-modal plasticity in higher visual and attentional areas of cortex. These modulations of visual processing may hold one key to understanding the difficulties faced by deaf readers beyond access to the phonology of the spoken language being expressed in written form. We acknowledge that the amount of residual hearing available to a deaf individual will be a major predictor of reading skill among other important factors ( Perfetti & Sandak, 2000 ). Our consideration here is for the deaf child for whom this is not a viable option. While some deaf children will be able to acquire literacy via the traditional route and demonstrate good phonological awareness and grapheme–phoneme correspondence skills, there are many others who will not be able to do so. If an approach focusing upon cognitive skills and knowledge bases, rather than print-to-sound mapping per se, is successful in explaining literacy acquisition in these deaf children, it may help in the development of appropriate instructional strategies that can be tailored to the needs of an individual deaf child. It may also, by extension, help us to understand the issues faced by other children who have difficulties in this most crucial of skills. We propose that trying to understand reading skill acquisition in a deaf child from the perspective of what works for hearing children may at best provide a limited understanding and at worst be misleading. In contrast, we argue that understanding reading skill acquisition from the perspective of the visual cognitive skills that a deaf child brings to the task may provide fruitful insights that both guide our understanding of the human capacity for learning and provide concrete and research-grounded strategies for the teaching of literacy to deaf children. 