The Link Between Form and Meaning in American Sign Language: Lexical Processing Effects Signed languages exploit iconicity (the transparent relationship between meaning and form) to a greater extent than spoken languages. where it is largely limited to onomatopoeia. In a picture–sign matching experiment measuring reaction times, the authors examined the potential advantage of iconicity both for 1st- and 2nd-language learners of American Sign Language (ASL). The results show that native ASL signers are faster to respond when a specific property iconically represented in a sign is made salient in the corresponding picture, thus providing evidence that a closer mapping between meaning and form can aid in lexical retrieval. While late 2nd-language learners appear to use iconicity as an aid to learning sign, they did not show the same facilitation effect as native ASL signers, suggesting that the task tapped into more automatic language processes. Overall, the findings suggest that completely arbitrary mappings between meaning and form may not be more advantageous in language and that, rather, arbitrariness may simply be an accident of modality.  Method Participants Fourteen Deaf 1 ASL signers, 17 hearing proficient ASL signers, and 17 hearing nonsigners participated in the study. Five Deaf participants were exposed to ASL from birth, and 9 acquired ASL at an early age ( M = 3.2; range = 18 months to 5 years old). Hearing signers began signing after age 16 ( M = 20.6; range = 16–28) and had been signing for over 8 years ( M = 17.3; range = 8–35). All were working as interpreters at the time of testing. Hearing nonsigners were monolingual English speakers with no previous knowledge of ASL other than the finger spelled alphabet. Stimuli Materials for the experiment were a set of ASL signs and English words referring to the same concrete objects. Signs (both experimental items and fillers) were normed for iconicity and familiarity using a 7-point scale in which 1 was completely arbitrary and 7 was completely iconic (13 Deaf, 14 hearing signers; norming participants did not take part in the experiment). Average ratings for Deaf and hearing signers were highly correlated ( r = .837). Experimental signs ( N = 50) were all rated highly iconic by both groups (3.7 or above, M = 5.1, SD = 1.82). Filler signs ( N = 100) were a mix of iconic and arbitrary items ( M = 2.72, SD = 1.75). Familiarity was matched across experimental items. Each of the iconic experimental items (see Appendix A ) was paired with two black and white line drawings, some taken from existing sources ( Snodgrass & Vanderwart, 1980 ; Szekely et al., 2004 ) and others specifically prepared for the purpose (see Appendix B ). In one picture, the iconic property of the sign was made salient (e.g., a picture of a hearing aid held behind the ear to match the ASL sign; see Figure 1 ); in the second, the iconic property was not made salient (e.g., a smaller hearing aid worn solely inside of the ear). Procedure Participants’ task was to decide whether a picture and an ASL sign refer to the same object. Participants first saw the picture followed by a sign video, and participants were instructed to respond yes or no (by pressing a computer key) if the picture and the sign referred to the same thing. As a control, nonsigning hearing English speakers carried out a similar task in which the same pictures were followed by a video of someone saying the English words. If iconicity facilitates language processing, we reasoned that signers should be faster at responding yes when the iconic property is salient in the picture than when it is not, while no such difference should be observed for English speakers responding to words. For experimental items, the picture and sign or word always matched, while filler items included both matching and mismatching pairs (always using different pictures and signs or words from the experimental items). The experiment included two blocks, each containing 50 experimental items and 90 filler items 2 (70 mismatching and 20 matching). No pictures were paired with the same sign or word in the second block as in the first. For experimental items, half (randomly determined) were paired with a salient picture in the first block and a nonsalient picture in the second. This order was reversed for half of the participants and for block (first vs. second), and was taken into account in the analysis. Order of presentation of items was randomized within a block for each participant. The experiment started with 10 practice items, followed by the actual experiment. Each trial began with a fixation cross (400 ms), then the picture display (500 ms), a blank screen (300 ms), and then the sign or word video (RTs were measured from the start of the video) during which participants could make their responses (blank screen after the video completed, until 3,000-ms timeout), followed by 300-ms blank screen before the fixation for the next trial. We presented stimuli and collected data using E-Prime Version 1.1. ( Schneider, Eschman, & Zuccolotto, 2002 ).  Participants Fourteen Deaf 1 ASL signers, 17 hearing proficient ASL signers, and 17 hearing nonsigners participated in the study. Five Deaf participants were exposed to ASL from birth, and 9 acquired ASL at an early age ( M = 3.2; range = 18 months to 5 years old). Hearing signers began signing after age 16 ( M = 20.6; range = 16–28) and had been signing for over 8 years ( M = 17.3; range = 8–35). All were working as interpreters at the time of testing. Hearing nonsigners were monolingual English speakers with no previous knowledge of ASL other than the finger spelled alphabet.  Stimuli Materials for the experiment were a set of ASL signs and English words referring to the same concrete objects. Signs (both experimental items and fillers) were normed for iconicity and familiarity using a 7-point scale in which 1 was completely arbitrary and 7 was completely iconic (13 Deaf, 14 hearing signers; norming participants did not take part in the experiment). Average ratings for Deaf and hearing signers were highly correlated ( r = .837). Experimental signs ( N = 50) were all rated highly iconic by both groups (3.7 or above, M = 5.1, SD = 1.82). Filler signs ( N = 100) were a mix of iconic and arbitrary items ( M = 2.72, SD = 1.75). Familiarity was matched across experimental items. Each of the iconic experimental items (see Appendix A ) was paired with two black and white line drawings, some taken from existing sources ( Snodgrass & Vanderwart, 1980 ; Szekely et al., 2004 ) and others specifically prepared for the purpose (see Appendix B ). In one picture, the iconic property of the sign was made salient (e.g., a picture of a hearing aid held behind the ear to match the ASL sign; see Figure 1 ); in the second, the iconic property was not made salient (e.g., a smaller hearing aid worn solely inside of the ear).  Procedure Participants’ task was to decide whether a picture and an ASL sign refer to the same object. Participants first saw the picture followed by a sign video, and participants were instructed to respond yes or no (by pressing a computer key) if the picture and the sign referred to the same thing. As a control, nonsigning hearing English speakers carried out a similar task in which the same pictures were followed by a video of someone saying the English words. If iconicity facilitates language processing, we reasoned that signers should be faster at responding yes when the iconic property is salient in the picture than when it is not, while no such difference should be observed for English speakers responding to words. For experimental items, the picture and sign or word always matched, while filler items included both matching and mismatching pairs (always using different pictures and signs or words from the experimental items). The experiment included two blocks, each containing 50 experimental items and 90 filler items 2 (70 mismatching and 20 matching). No pictures were paired with the same sign or word in the second block as in the first. For experimental items, half (randomly determined) were paired with a salient picture in the first block and a nonsalient picture in the second. This order was reversed for half of the participants and for block (first vs. second), and was taken into account in the analysis. Order of presentation of items was randomized within a block for each participant. The experiment started with 10 practice items, followed by the actual experiment. Each trial began with a fixation cross (400 ms), then the picture display (500 ms), a blank screen (300 ms), and then the sign or word video (RTs were measured from the start of the video) during which participants could make their responses (blank screen after the video completed, until 3,000-ms timeout), followed by 300-ms blank screen before the fixation for the next trial. We presented stimuli and collected data using E-Prime Version 1.1. ( Schneider, Eschman, & Zuccolotto, 2002 ).  Results After excluding those trials in which participants made incorrect responses, we averaged correct RTs by participants and by items for each of the experimental conditions (see Table 1 ). We conducted separate 3 × 2 × 2 analyses of variance, using participants ( F 1) and items ( F 2) as random factors, upon correct response latencies. 3 Using analyses of variance, we tested the factorial combination of group (native ASL, L2 ASL, English monolingual; between participants and within items), picture salience (whether the iconic feature was made salient in the picture or not), and block (whether the sign or word appeared for the first or second time). The main effect of group was significant, F 1(2, 45) = 5.528, p = .007, and F 2(2, 98) = 39.010, p < .001; English monolinguals responded faster (763 ms) than either ASL group (native: 931; L2: 867; not significantly different from each other). This unexpected finding in overall RTs between English speakers and ASL signers (both L1 and L2; i.e., signers were significantly slower than English- speaking controls) is likely due to the fact that signs take longer to produce than spoken words. (The average mean length for ASL video clips was 1,809 ms, while English video clips were on average 1,074 ms.) The main effect of picture salience was significant only by participants but not items, F 1(1, 45) = 5.018, p = .030, and F 2(1, 49) = 1.614, p = .210; this reflected a tendency toward faster responses for salient pictures overall. There was also a significant main effect of block, F 1(1, 45) = 59.779, p < .001, and F 2(1, 49) = 123,761, p < .001, such that participants were faster to respond to the second presentation of a sign or word. Crucially, these main effects were qualified by two significant interactions. First, group interacted with picture salience, F 1(2, 45) = 6.954, p = .002, and F 2(2, 98) = 3.642, p = .030. Analysis of simple interactions revealed a clear difference between native ASL signers and English monolinguals (Group × Picture Salience interaction comparing these two groups: F 1[1, 29] = 15.301, p = .001, and F 2[1, 49] = 6.021, p = .018). Native ASL signers were faster to respond to whether the sign matched the picture after seeing a salient picture than after a nonsalient picture, while English speakers had no response advantage for the same pictures (see Figure 2 ). Responses by L2 ASL signers patterned more like the L1 ASL signers (the Group × Picture Salience interaction between Deaf and L2 ASL signers was nonsignificant with both p s > .20). However, the same interaction between L2 ASL signers and monolingual English speakers missed significance by items, F 1(1, 32) = 5.772, p = .022, and F 2(1, 49) = 2.838, p = .098, making L2 ASL signers not significantly different from either native ASL signers or English-speaking nonsigners. There was also an interaction between group and block, F 1(2, 45) = 3.568, p = .036, and F 2(2, 98) = 10.760, p < .001. While all three groups responded more quickly to the second presentation of a sign or word, this tendency was more pronounced for L2 ASL participants than the other two groups; L2 ASL participants were, on average, 111 ms faster for the second block than for the first versus 72 ms for native ASL participants and 48 ms for English monolinguals (these latter two groups did not differ from each other). None of the remaining interactions were significant (all F s < 1). It could be argued that the relatively longer latencies for ASL participants compared to English-speaking participants is due to iconicity effects arising because of slower overall comprehension for signers. If so, then the magnitude of the iconicity effect should decrease when ASL participants are faster to respond. To test this hypothesis, we calculated the correlation between each participant's iconicity effect and their overall RT. Across all Deaf L1 participants, the correlation was not significant ( r = .0524, p = .82) and when both L1 and L2 ASL participants were calculated together, the correlation remained not significant ( r = –.0577, p = .74). Therefore, the iconicity effect is not explained by the relatively greater time available to sign perceivers because of slower sign production times. We also investigated whether the iconicity effect might have been influenced by prototypicality, either from prototypical features highlighted in the salient pictures or prototypical features expressed iconically in ASL signs. To assess the prototypicality of target sign properties, we turned to a database of semantic features ( McRae, Cree, Seidenberg, & McNorgan, 2005 ). Highly prototypical properties were defined as those that are well represented in the semantic features (named by at least 40% of McRae et al.'s, 2005 , English-speaking participants). For example, the iconic property of the sign ELEPHANT (its trunk) would be considered highly prototypical (77% of participants produced the feature trunk while listing important features of elephants), while the iconic property of the sign MOTORCYCLE (gripping–turning handlebar) would not be considered prototypical, as no features related to grasping or handlebars occur in the database. We classified all set items found in McRae et al.'s (2005) database ( N = 30) into high or low prototypicality (high = 13, low = 17). An analysis of native ASL signers and English monolinguals, using prototypicality as a factor along with salience of picture and block, showed no main effect of prototypicality or significant interactions of prototypicality (the Group × Prototypicality and Picture Salience × Prototypicality interactions were nonsignificant with both p s > .9). Thus, Deaf ASL signers were not faster to respond to signs incorporating prototypical features, nor was either group significantly faster to respond to the salient picture when it highlighted more highly prototypical features.  Results After excluding those trials in which participants made incorrect responses, we averaged correct RTs by participants and by items for each of the experimental conditions (see Table 1 ). We conducted separate 3 × 2 × 2 analyses of variance, using participants ( F 1) and items ( F 2) as random factors, upon correct response latencies. 3 Using analyses of variance, we tested the factorial combination of group (native ASL, L2 ASL, English monolingual; between participants and within items), picture salience (whether the iconic feature was made salient in the picture or not), and block (whether the sign or word appeared for the first or second time). The main effect of group was significant, F 1(2, 45) = 5.528, p = .007, and F 2(2, 98) = 39.010, p < .001; English monolinguals responded faster (763 ms) than either ASL group (native: 931; L2: 867; not significantly different from each other). This unexpected finding in overall RTs between English speakers and ASL signers (both L1 and L2; i.e., signers were significantly slower than English- speaking controls) is likely due to the fact that signs take longer to produce than spoken words. (The average mean length for ASL video clips was 1,809 ms, while English video clips were on average 1,074 ms.) The main effect of picture salience was significant only by participants but not items, F 1(1, 45) = 5.018, p = .030, and F 2(1, 49) = 1.614, p = .210; this reflected a tendency toward faster responses for salient pictures overall. There was also a significant main effect of block, F 1(1, 45) = 59.779, p < .001, and F 2(1, 49) = 123,761, p < .001, such that participants were faster to respond to the second presentation of a sign or word. Crucially, these main effects were qualified by two significant interactions. First, group interacted with picture salience, F 1(2, 45) = 6.954, p = .002, and F 2(2, 98) = 3.642, p = .030. Analysis of simple interactions revealed a clear difference between native ASL signers and English monolinguals (Group × Picture Salience interaction comparing these two groups: F 1[1, 29] = 15.301, p = .001, and F 2[1, 49] = 6.021, p = .018). Native ASL signers were faster to respond to whether the sign matched the picture after seeing a salient picture than after a nonsalient picture, while English speakers had no response advantage for the same pictures (see Figure 2 ). Responses by L2 ASL signers patterned more like the L1 ASL signers (the Group × Picture Salience interaction between Deaf and L2 ASL signers was nonsignificant with both p s > .20). However, the same interaction between L2 ASL signers and monolingual English speakers missed significance by items, F 1(1, 32) = 5.772, p = .022, and F 2(1, 49) = 2.838, p = .098, making L2 ASL signers not significantly different from either native ASL signers or English-speaking nonsigners. There was also an interaction between group and block, F 1(2, 45) = 3.568, p = .036, and F 2(2, 98) = 10.760, p < .001. While all three groups responded more quickly to the second presentation of a sign or word, this tendency was more pronounced for L2 ASL participants than the other two groups; L2 ASL participants were, on average, 111 ms faster for the second block than for the first versus 72 ms for native ASL participants and 48 ms for English monolinguals (these latter two groups did not differ from each other). None of the remaining interactions were significant (all F s < 1). It could be argued that the relatively longer latencies for ASL participants compared to English-speaking participants is due to iconicity effects arising because of slower overall comprehension for signers. If so, then the magnitude of the iconicity effect should decrease when ASL participants are faster to respond. To test this hypothesis, we calculated the correlation between each participant's iconicity effect and their overall RT. Across all Deaf L1 participants, the correlation was not significant ( r = .0524, p = .82) and when both L1 and L2 ASL participants were calculated together, the correlation remained not significant ( r = –.0577, p = .74). Therefore, the iconicity effect is not explained by the relatively greater time available to sign perceivers because of slower sign production times. We also investigated whether the iconicity effect might have been influenced by prototypicality, either from prototypical features highlighted in the salient pictures or prototypical features expressed iconically in ASL signs. To assess the prototypicality of target sign properties, we turned to a database of semantic features ( McRae, Cree, Seidenberg, & McNorgan, 2005 ). Highly prototypical properties were defined as those that are well represented in the semantic features (named by at least 40% of McRae et al.'s, 2005 , English-speaking participants). For example, the iconic property of the sign ELEPHANT (its trunk) would be considered highly prototypical (77% of participants produced the feature trunk while listing important features of elephants), while the iconic property of the sign MOTORCYCLE (gripping–turning handlebar) would not be considered prototypical, as no features related to grasping or handlebars occur in the database. We classified all set items found in McRae et al.'s (2005) database ( N = 30) into high or low prototypicality (high = 13, low = 17). An analysis of native ASL signers and English monolinguals, using prototypicality as a factor along with salience of picture and block, showed no main effect of prototypicality or significant interactions of prototypicality (the Group × Prototypicality and Picture Salience × Prototypicality interactions were nonsignificant with both p s > .9). Thus, Deaf ASL signers were not faster to respond to signs incorporating prototypical features, nor was either group significantly faster to respond to the salient picture when it highlighted more highly prototypical features.  Discussion Overall, the data show a processing advantage for iconicity in native signers: Native signers were faster at the matching task when iconic properties of the sign were made salient in the picture, while this was not the case for nonsigning participants matching the same pictures to English words. This finding follows naturally if one assumes language is not random but rather an emergent property of natural influences both within and outside of the language itself. Specifically, the incorporation of iconicity appears to be a basic principle across signed languages, and the experimental results suggest that this principle may emerge because of the benefits derived. Moreover, the overall suggestion is that there is nothing inherently better in wholly arbitrary mappings between form and meaning (at least in terms of lexical access), and thus past assertions that the extent of arbitrariness in language likely depends on language modality are supported ( Fischer, 1979 ; Meir, 2003 ). As described in the introduction, arbitrariness has been claimed to be necessary in order to allow for large lexica (maximizing the number of possible phonological contrasts allows for representation of far greater numbers of different words). However, this claim is based on a specific model in which there is an exact one-to-one mapping between meaning and form ( Gasser, 2004 ): a situation very different from how iconicity is actually realized in sign forms. Specifically, iconicity in signed languages is created from the representation of only certain salient element(s) of real-world objects, actions, and so forth and there can be several choices of how to iconically represent any one concept. This is evidenced by the fact that the same concept is not always represented in the same way across sign languages (e.g., the ASL sign for LION iconically represents the mane, while in BSL LION is iconically represented with pouncing paws and claws). Further, while different signed languages often represent real-world objects, actions, and so forth by highlighting the same salient property, rarely is the exact phonological form of the sign the same. This was first discussed in Klima and Bellugi (1979) , who provide the example of the sign TREE in ASL, Danish Sign Language, and Chinese Sign Language. All three of these sign languages represent the shape of a prototypical tree, but they are still all phonologically quite different from each other (see Figure 3 ). This example points out the many phonological choices available for the representation of any one iconic meaning. Further, as discussed above, iconicity may be represented in some aspects of the phonological representation of any one sign, while other features remain arbitrary. For example, the sign HEAR in ASL is produced by tapping the ear with an index finger. While the location of the ear is clearly iconic, the remaining features appear arbitrary (i.e., the pinky or index and middle fingers together could easily be used for the hand shape, and rubbing or flicking in place of the existing tapping movement). Because not all features of a sign need be iconic and because there are many ways to map salient features onto phonological features, as well as a choice of salient features that can be mapped, signed languages can incorporate a high degree of iconicity for individual form–meaning mappings while still maintaining arbitrariness both in some features of individual phonological forms, and at a more global level across signs that share meanings. Perhaps the most surprising results were from proficient L2 signers. While all groups were faster in the second block than the first, L2 signers were much better at capitalizing on sign repetition, showing significantly more gain on RTs in Block 2 (110 ms) than the Deaf signers (72.5 ms) or the hearing non-signers (48 ms). The L2 signers in this study all work as simultaneous interpreters who are necessarily highly proficient in the L2 but also appear to possess superior memory resources relative to other language users likely needed specifically for the complex task of simultaneously interpreting between two languages ( Christoffels, deGroot, & Kroll, 2006 ). The exact nature of these resources has been previously attributed to better working memory capacity ( Christoffels et al., 2006 ; Padilla, Bajo, Cañas, & Padilla, 1995 ). However, Köpke and Nespoulos (2006) conducted a large-scale study using a battery of memory tasks and memory tasks coupled with articulatory suppression tasks (thought to tap into executive control) and found that while professional interpreters resisted articulatory suppression better than other groups, they did not perform differently from noninterpreters on working memory tasks. These results challenge the idea that working memory capacity increases in experts and suggests that perhaps experienced interpreters (the participants included in our study) develop skills that do not depend on working memory storage capacity. In line with this finding, and directly relevant to our study, Bajo, Padilla, and Padilla (2000) found that simultaneous interpreters were faster to respond on atypical exemplars of categories in a semantic categorization task and were faster on nonwords in a lexical decision task than trainees learning to interpret, bilinguals without interpreting experience, and importantly monolinguals. Thus, our findings support a growing body of research in which simultaneous interpreters outperform other groups for certain tasks relevant to their skills developed as interpreters. Crucially, in our study, the gain in RTs did not differ between the two conditions (salient and nonsalient pictures) or as an overall significantly faster response rate than Deaf signers, and therefore this effect cannot be attributed to iconicity effects but might stem from L2 interpreters’ greater proficiency at accessing previously introduced information (such as already-seen signs). Also surprising and relevant to our experimental questions, iconicity effects were no greater for L2 signers then for L1 signers. L2 signers did not show a significant difference from native Deaf signers, however they also did not show a significant difference from the nonsigning group (thus, straddling the fence between the two groups). Iconicity in L2 learning has been explained in terms of the conscious use of iconic cues as a memory aid, and we hypothesized that there might be an even greater effect of iconicity for late L2 learners of ASL who appear to be more aware of iconic properties of a sign during the acquisition stage. However, that this was not the case suggests that the experimental task was able to tap into more automatic on-line processes that are not affected by conscious learning strategies or awareness. Developmental studies have suggested that children do not make use of iconic properties of signs during L1 acquisition ( Bellugi & Klima, 1976 ; Emmorey, 2002 ; Taub, 2001 ) or during L1 acquisition of iconically motivated agreement (e.g., for signs such as GIVE that move from source to goal; Meier, 1982 ) and that most first signs are not iconic ( Orlansky & Bonvillian, 1984 ). 4 On the basis of this developmental work, one might predict that iconicity would not play a role in adult language processing. However, regardless of whether ASL signers make use of iconicity during L1 learning or not, they appear to have an awareness of iconicity, as evidenced by their ability to give iconicity rating for signs in our study. Further, there was high agreement between native L1 signers and late L2 signers about which signs are iconic and which are not. Participants’ postexperiment iconicity ratings 5 were very highly correlated across the groups: Pearson's r (172) = .842. This indicates while L2 signers may have a greater awareness of iconic properties of signs during L2 acquisition, both groups end up similarly aware of iconic properties of signs. Crucially, when considering the L1 acquisition literature, there is no reason to assume that the iconic relationship between form and meaning, which we showed to have processing benefits in adults, would necessarily aid in earlier acquisition of these forms. It is an open question whether or not similar effects of iconicity on processing might be found for children performing similar kinds of on-line tasks. Recently, iconicity effects were found for deaf children using Sign Language of the Netherlands (in a picture–sign matching task, responses were significantly faster for highly iconic signs than for less iconic signs; Ormel, 2008 ). Iconicity has further been claimed to play a role in other cognitive processes for children such as abstract categorization and the ability to recognize and describe the function of objects ( Courtin, 1997 ; Markham & Justice, 2004 ). Thus, while iconicity may not play a role in language acquisition, children nonetheless appear able to take advantage of iconic aspects of signs for different conceptual tasks including lexical access, as we found with Deaf adults. The finding that L2 interpreters do not show larger iconicity effects than L1 signers provides evidence that our task elicited automatic effects. But what automatic process is driving the iconicity effect? One view is that the iconicity effect arises from more direct mappings resulting from the nonarbitrary link between phonology and semantics. In lexical decision tasks, there is facilitation when participants are primed with like morphemes embedded in semantically unrelated words (see Drews, 1996 , for review) or like phonoaesthemes (i.e., clusters of sounds representing specific meanings as in the gl - of glitter, glaze , and glare to encode the meaning of light; Bergen, 2004 ). Facilitation is greater than for phonologically or semantically related words alone, indicating a processing advantage for regularized, although arbitrary, form–meaning mappings. The iconicity effect may, in a similar fashion, be driven by regular form–meaning mappings. Under this analysis, our results would arise from general processing benefits of more regular mappings. One consideration then is whether or not there are neighborhoods of iconic features that tend to get mapped onto signs (e.g., round shapes as represented by a curved hand shape in the signs CUP, BINOCULARS, BRACELET, etc.) and whether the iconicity effect is driven by more dense–sparse neighborhoods of meaning. We leave these possibilities open to further research. In conclusion, a facilitatory effect of sign iconicity suggests that iconic properties of a sign are more salient to signers than noniconic properties. One way to think about the overall results is in terms of current theories of embodied language in which word meanings are understood via mental simulations of past perception and action ( Barsalou, 1999 ; Gallese & Lakoff, 2005 ). This more direct, less arbitrary connection between the real-world and word meanings could be predicted to extend, where possible, into all areas of language (including form–meaning mappings). This would be particularly true for signed languages, which by their very nature are more directly anchored to the body. The once received but now changing view in language studies was that form and meaning are only arbitrarily linked and that imagistic information must be translated into abstract linguistic information when using language. Finding effects of iconicity in ASL supports a revision of this view under which arbitrariness may be only one of a number of competing principles that drive the shape of language. True arbitrariness, therefore, may be the result of language modality, rather than a stand-alone feature of language.  Discussion Overall, the data show a processing advantage for iconicity in native signers: Native signers were faster at the matching task when iconic properties of the sign were made salient in the picture, while this was not the case for nonsigning participants matching the same pictures to English words. This finding follows naturally if one assumes language is not random but rather an emergent property of natural influences both within and outside of the language itself. Specifically, the incorporation of iconicity appears to be a basic principle across signed languages, and the experimental results suggest that this principle may emerge because of the benefits derived. Moreover, the overall suggestion is that there is nothing inherently better in wholly arbitrary mappings between form and meaning (at least in terms of lexical access), and thus past assertions that the extent of arbitrariness in language likely depends on language modality are supported ( Fischer, 1979 ; Meir, 2003 ). As described in the introduction, arbitrariness has been claimed to be necessary in order to allow for large lexica (maximizing the number of possible phonological contrasts allows for representation of far greater numbers of different words). However, this claim is based on a specific model in which there is an exact one-to-one mapping between meaning and form ( Gasser, 2004 ): a situation very different from how iconicity is actually realized in sign forms. Specifically, iconicity in signed languages is created from the representation of only certain salient element(s) of real-world objects, actions, and so forth and there can be several choices of how to iconically represent any one concept. This is evidenced by the fact that the same concept is not always represented in the same way across sign languages (e.g., the ASL sign for LION iconically represents the mane, while in BSL LION is iconically represented with pouncing paws and claws). Further, while different signed languages often represent real-world objects, actions, and so forth by highlighting the same salient property, rarely is the exact phonological form of the sign the same. This was first discussed in Klima and Bellugi (1979) , who provide the example of the sign TREE in ASL, Danish Sign Language, and Chinese Sign Language. All three of these sign languages represent the shape of a prototypical tree, but they are still all phonologically quite different from each other (see Figure 3 ). This example points out the many phonological choices available for the representation of any one iconic meaning. Further, as discussed above, iconicity may be represented in some aspects of the phonological representation of any one sign, while other features remain arbitrary. For example, the sign HEAR in ASL is produced by tapping the ear with an index finger. While the location of the ear is clearly iconic, the remaining features appear arbitrary (i.e., the pinky or index and middle fingers together could easily be used for the hand shape, and rubbing or flicking in place of the existing tapping movement). Because not all features of a sign need be iconic and because there are many ways to map salient features onto phonological features, as well as a choice of salient features that can be mapped, signed languages can incorporate a high degree of iconicity for individual form–meaning mappings while still maintaining arbitrariness both in some features of individual phonological forms, and at a more global level across signs that share meanings. Perhaps the most surprising results were from proficient L2 signers. While all groups were faster in the second block than the first, L2 signers were much better at capitalizing on sign repetition, showing significantly more gain on RTs in Block 2 (110 ms) than the Deaf signers (72.5 ms) or the hearing non-signers (48 ms). The L2 signers in this study all work as simultaneous interpreters who are necessarily highly proficient in the L2 but also appear to possess superior memory resources relative to other language users likely needed specifically for the complex task of simultaneously interpreting between two languages ( Christoffels, deGroot, & Kroll, 2006 ). The exact nature of these resources has been previously attributed to better working memory capacity ( Christoffels et al., 2006 ; Padilla, Bajo, Cañas, & Padilla, 1995 ). However, Köpke and Nespoulos (2006) conducted a large-scale study using a battery of memory tasks and memory tasks coupled with articulatory suppression tasks (thought to tap into executive control) and found that while professional interpreters resisted articulatory suppression better than other groups, they did not perform differently from noninterpreters on working memory tasks. These results challenge the idea that working memory capacity increases in experts and suggests that perhaps experienced interpreters (the participants included in our study) develop skills that do not depend on working memory storage capacity. In line with this finding, and directly relevant to our study, Bajo, Padilla, and Padilla (2000) found that simultaneous interpreters were faster to respond on atypical exemplars of categories in a semantic categorization task and were faster on nonwords in a lexical decision task than trainees learning to interpret, bilinguals without interpreting experience, and importantly monolinguals. Thus, our findings support a growing body of research in which simultaneous interpreters outperform other groups for certain tasks relevant to their skills developed as interpreters. Crucially, in our study, the gain in RTs did not differ between the two conditions (salient and nonsalient pictures) or as an overall significantly faster response rate than Deaf signers, and therefore this effect cannot be attributed to iconicity effects but might stem from L2 interpreters’ greater proficiency at accessing previously introduced information (such as already-seen signs). Also surprising and relevant to our experimental questions, iconicity effects were no greater for L2 signers then for L1 signers. L2 signers did not show a significant difference from native Deaf signers, however they also did not show a significant difference from the nonsigning group (thus, straddling the fence between the two groups). Iconicity in L2 learning has been explained in terms of the conscious use of iconic cues as a memory aid, and we hypothesized that there might be an even greater effect of iconicity for late L2 learners of ASL who appear to be more aware of iconic properties of a sign during the acquisition stage. However, that this was not the case suggests that the experimental task was able to tap into more automatic on-line processes that are not affected by conscious learning strategies or awareness. Developmental studies have suggested that children do not make use of iconic properties of signs during L1 acquisition ( Bellugi & Klima, 1976 ; Emmorey, 2002 ; Taub, 2001 ) or during L1 acquisition of iconically motivated agreement (e.g., for signs such as GIVE that move from source to goal; Meier, 1982 ) and that most first signs are not iconic ( Orlansky & Bonvillian, 1984 ). 4 On the basis of this developmental work, one might predict that iconicity would not play a role in adult language processing. However, regardless of whether ASL signers make use of iconicity during L1 learning or not, they appear to have an awareness of iconicity, as evidenced by their ability to give iconicity rating for signs in our study. Further, there was high agreement between native L1 signers and late L2 signers about which signs are iconic and which are not. Participants’ postexperiment iconicity ratings 5 were very highly correlated across the groups: Pearson's r (172) = .842. This indicates while L2 signers may have a greater awareness of iconic properties of signs during L2 acquisition, both groups end up similarly aware of iconic properties of signs. Crucially, when considering the L1 acquisition literature, there is no reason to assume that the iconic relationship between form and meaning, which we showed to have processing benefits in adults, would necessarily aid in earlier acquisition of these forms. It is an open question whether or not similar effects of iconicity on processing might be found for children performing similar kinds of on-line tasks. Recently, iconicity effects were found for deaf children using Sign Language of the Netherlands (in a picture–sign matching task, responses were significantly faster for highly iconic signs than for less iconic signs; Ormel, 2008 ). Iconicity has further been claimed to play a role in other cognitive processes for children such as abstract categorization and the ability to recognize and describe the function of objects ( Courtin, 1997 ; Markham & Justice, 2004 ). Thus, while iconicity may not play a role in language acquisition, children nonetheless appear able to take advantage of iconic aspects of signs for different conceptual tasks including lexical access, as we found with Deaf adults. The finding that L2 interpreters do not show larger iconicity effects than L1 signers provides evidence that our task elicited automatic effects. But what automatic process is driving the iconicity effect? One view is that the iconicity effect arises from more direct mappings resulting from the nonarbitrary link between phonology and semantics. In lexical decision tasks, there is facilitation when participants are primed with like morphemes embedded in semantically unrelated words (see Drews, 1996 , for review) or like phonoaesthemes (i.e., clusters of sounds representing specific meanings as in the gl - of glitter, glaze , and glare to encode the meaning of light; Bergen, 2004 ). Facilitation is greater than for phonologically or semantically related words alone, indicating a processing advantage for regularized, although arbitrary, form–meaning mappings. The iconicity effect may, in a similar fashion, be driven by regular form–meaning mappings. Under this analysis, our results would arise from general processing benefits of more regular mappings. One consideration then is whether or not there are neighborhoods of iconic features that tend to get mapped onto signs (e.g., round shapes as represented by a curved hand shape in the signs CUP, BINOCULARS, BRACELET, etc.) and whether the iconicity effect is driven by more dense–sparse neighborhoods of meaning. We leave these possibilities open to further research. In conclusion, a facilitatory effect of sign iconicity suggests that iconic properties of a sign are more salient to signers than noniconic properties. One way to think about the overall results is in terms of current theories of embodied language in which word meanings are understood via mental simulations of past perception and action ( Barsalou, 1999 ; Gallese & Lakoff, 2005 ). This more direct, less arbitrary connection between the real-world and word meanings could be predicted to extend, where possible, into all areas of language (including form–meaning mappings). This would be particularly true for signed languages, which by their very nature are more directly anchored to the body. The once received but now changing view in language studies was that form and meaning are only arbitrarily linked and that imagistic information must be translated into abstract linguistic information when using language. Finding effects of iconicity in ASL supports a revision of this view under which arbitrariness may be only one of a number of competing principles that drive the shape of language. True arbitrariness, therefore, may be the result of language modality, rather than a stand-alone feature of language. 